{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第六周(机器学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月16日至3月18日期间完成，最晚提交时间本周日（3月18日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam6后，进行作答。例如wangwei-exam6\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/4/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:王玺\n",
    "- 批改人： David\n",
    "- 最终得分:100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题(共4题，每题5分，共计20分)\n",
    "- note: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 请写出你了解的机器学习特征工程操作，以及它的意义（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "特征工程是指从原始数据中提取出一系列能够良好表达数据集特点和分布的特征集，来组成更好的训练数据使模型和算法能达到最好性能和效果。     \n",
    "特征工程包括特征使用方案，特征获取方案，特征处理和特征监控四个部分。    \n",
    "其中特征处理是特征工程的核心部分，当数据预处理完成后，要选择有意义的特征输入机器学习的算法和模型进行训练。通常来说，从两个方面考虑来选择特征：    \n",
    "&emsp;&emsp;1.特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。      \n",
    "&emsp;&emsp;2.特征与目标的相关性：与目标相关性高的特征，应当优先选择。  \n",
    "根据特征选择的形式又可以将特征选择方法分为3种：   \n",
    "&emsp;&emsp;Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。   \n",
    "&emsp;&emsp;Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。   \n",
    "&emsp;&emsp;Embedded：嵌入法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是是通过训练来确定特征的优劣。    \n",
    "sklearn提供了较为完整的特征处理方法，包括数据预处理，数据变换，特征选择，降维等。           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.请写出上述特征工程操作的sklearn或者pandas实现方式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.在数据预处理阶段sklearn提供了preproccessing库。   其中的StandardScaler类可以对数据进行标准化，MinMaxScaler类可以对数据进行区间缩放，Normalizer类可以对数据进行归一化，还可以用Binarizer类&emsp;对数据进行二值化，Imputer类可以对数据进行缺失值计算，PolynomialFeatures类可以对数据进行多项式转换。          \n",
    "2.完成数据预处理后接下来sklearn提供了feature_selection库来进行特征选择。      \n",
    "&emsp;1）过滤法（Filter）：VarianceThreshold类可以用方差选择特征，SelectKBest类可以结合相关系数来选择特征，SelectKBest类结合卡方检验来选择特征，SelectKBest类结合最大信息系数法来选择特征。   \n",
    "&emsp;2）包装法（Wrapper）：RFE类可以进行迭代特征消除。RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)     \n",
    "&emsp;3）嵌入法（Ebedded）：使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。使用feature_selection库的SelectFromModel类结合带L1惩罚项的逻辑回归模型可以来选择特征比如：SelectFromModel(LR(threshold=0.5, C=0.1)).fit_transform(iris.data, iris.target)。使用SelectFromModel类结&emsp;合带L1以及L2惩罚项的逻辑回归模型来做的正选择为：SelectFromModel(LR(threshold=0.5, C=0.1)).fit_transform(iris.data, iris.target)    \n",
    "3.当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的，在降维方面sklearn提供了decomposition库的PCA类来用主成分分析法降维；还有lda库的LDA类也可以用来降维。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.模型评估中的留一法，留出法，交叉验证分别是什么操作？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1）留出法(hold-out)：将数据集D划分为两个互斥的集合，其中一个集合用作训练集S，另一个作为测试集T，即D=SUT，S∩T=∅。在S上训练出的模型，用T来评估其测试误差，作为对泛化误差的近似估计。这种方法用起来简单但是最后验证准确性的高低受原始数据分类影响很大，不是很有说服力。    \n",
    "2）交叉验证法(crossvalidation)：将数据集D划分为k个大小相似的互斥子集，即D=D1UD2U…UDk，Di∩Dj=∅（i≠j）；每个子集Di都尽可能保持数据分布的一致性，即从D中通过分层采样所得。训练时，每次用k-1个子集的并集作为训练集，余下的一个子集作为测试集；如此，可获得k组训练集和测试集，从而进行k次训练和测试，最终返回k次测试结果的均值。k值决定了交叉验证法评估结果的稳定性和保真性，因此也称为k折交叉验证或k倍交叉验证。   \n",
    "3）留一法：假设样本数据集中有N个样本数据。将每个样本单独作为测试集，其余N-1个样本作为训练集，这样得到了N个分类器或模型，用这N个分类器或模型的分类准确率的平均数作为此分类器的性能指标。这个方法优点是每一个模型都是用几乎所有的样本来训练模型，最接近样本，这样评估所得的结果比较可靠。实验没有随机因素，整个过程是可重复的。缺点是计算成本高，当N非常大时，计算很耗时。   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.如何理解模型的过拟合与欠拟合，以及如何解决？（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "欠拟合就是模型没有很好地捕捉到数据特征，不能够很好地拟合数据。解决方法：   \n",
    "1）添加其他特征项，特征项不够导致的，可以添加其他特征项来很好地解决。比如可以通过已有特征的一些计算或者组合产生新的特征。    \n",
    "2）添加多项式特征，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型更能刻画数据特征。   \n",
    "3）减少正则化参数，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。   \n",
    "过拟合就是就是模型把训练集数据学习的太彻底，以至于把噪声数据的特征也学习到了，这样就会导致在后期测试的时候不能够很好地识别测试集数据，模型泛化能力太差。解决方法：   \n",
    "1）重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。   \n",
    "2）增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。   \n",
    "3）添加正则化项。     \n",
    "4）采用dropout方法。这个方法在神经网络里面很常用。dropout方法是ImageNet中提出的一种方法，它可以在训练的时候让神经元以一定的概率不工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 操作题(共1题，共计80分)\n",
    "- note:80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信用卡欺诈项目(共7项，前5项每题10分，6，7题每题15分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 前期数据导入,预览及处理(此部分勿修改，涉及的数据文件无需复制移动)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0                 1                              0.766127  45.0   \n",
       "1                 0                              0.957151  40.0   \n",
       "2                 0                              0.658180  38.0   \n",
       "3                 0                              0.233810  30.0   \n",
       "4                 0                              0.907239  49.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                   2.0   0.802982         9120.0   \n",
       "1                                   0.0   0.121876         2600.0   \n",
       "2                                   1.0   0.085113         3042.0   \n",
       "3                                   0.0   0.036050         3300.0   \n",
       "4                                   1.0   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                             13.0                      0.0   \n",
       "1                              4.0                      0.0   \n",
       "2                              2.0                      1.0   \n",
       "3                              5.0                      0.0   \n",
       "4                              7.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           6.0                                   0.0   \n",
       "1                           0.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           1.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import zipfile\n",
    "with zipfile.ZipFile('/home/sxy-s3/0.Teacher/Exam/KaggleCredit2.csv.zip', 'r') as z:\n",
    "    f = z.open('KaggleCredit2.csv')\n",
    "    data = pd.read_csv(f, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112915, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112915, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum(axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(108648, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shapey = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108648, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)\n",
    "y.mean()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 1.把数据切分成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 各种导包\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 标准化 StandardScaler类可以保存训练集中的参数（均值、方差）直接使用其对象转换测试集数据。\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.使用logistic regression建模，并且输出一下系数，分析重要度。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)\n",
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfTime30-59DaysPastDueNotWorse 1.728691\n",
      "NumberOfTimes90DaysLate              1.689949\n",
      "DebtRatio                            0.312079\n",
      "NumberOfDependents                   0.116384\n",
      "RevolvingUtilizationOfUnsecuredLines -0.014273\n",
      "NumberOfOpenCreditLinesAndLoans      -0.091872\n",
      "MonthlyIncome                        -0.115345\n",
      "NumberRealEstateLoansOrLines         -0.196397\n",
      "age                                  -0.364292\n",
      "NumberOfTime60-89DaysPastDueNotWorse -3.248708\n"
     ]
    }
   ],
   "source": [
    "feat_labels=data.columns[1:]\n",
    "coefs=lr.coef_\n",
    "indices=np.argsort(coefs[0])[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print ('%-*s %f'%(36,feat_labels[indices[f]],coefs[0,indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上所示exp（系数）的大小反应了这个变量对分类结果的影响程度。系数的正负则反映了这个影响是正向的还是反向的。比如，NumberOfTimes90DaysLate的系数为1.689949，exp（1.689949）是大于1的，这表示自变量x每增加一个单位，y发生的几率是原来的exp（1.689949）倍；相反age的系数为-0.3248708，exp（-0.3248708）小于1，表示自变量x每增加一个单位，y发生的几率缩小为原来的exp（-0.3248708）。绝对值大的参数对应的特征也许会比较重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3.使用决策树/SVM/KNN...等sklearn分类算法进行分类，尝试了解参数含义，调整不同的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n",
      "准确度：0.934217\n"
     ]
    }
   ],
   "source": [
    "# 决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "print(tree.fit(X_train_std, y_train))\n",
    "print('准确度：%f'%tree.score(X_train_std,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criterion：表示在基于特征划分数据集合时，选择特征的标准。默认是gini，即'Gini impurity'(Gini不纯度)，还可以是criterion='entropy'。Gini不纯度表示该Gini度量是指随机选择集合中的元素，根据集合中label的分布将该元素赋予分类，该元素分类错误的几率。entropy则表示采用信息增益来选择特征。\n",
    "\n",
    "splitter：表示在构造树时，选择结点的原则，默认是splitter='best'，即选择最好的特征点分类，比如基于信息增益分类时，则选择信息增益最大的特征点，还可以是'random'随机的。\n",
    "\n",
    "max_features：这个参数表示在划分数据集时考虑的最多的特征值数量，根据数据类型表示的意义也不同（默认为None）：    \n",
    "&#8195;&emsp;&emsp;&emsp;&emsp;&emsp;1. int，在每次分类是都要考虑max_features个特征。    \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;2. float,那么max_features是一个百分率并且分类时需要考虑的特征数是int(max_feature*n_features,其中n_features是训练完成时发特征数)。     \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;3. auto,max_features=sqrt(n_features)    \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;4. sqrt,max_features=sqrt(n_features)    \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;5. log2,max_features=log2(n_features)    \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;6. None，max_features=n_features    \n",
    "  \n",
    "\n",
    "max_depth：表示树的最大深度,如果是\"None\",则节点会一直扩展直到所有的叶子都是纯的或者所有的叶子节点都包含少于min_samples_split个样本点。忽视max_leaf_nodes是不是为None。\n",
    "\n",
    "min_samples_split：表示在分解内部结点时最少的样本数,默认为2。如果是float，min_samples_split是一个百分率并且ceil(min_samples_split*n_samples)是每个分类需要的样本数。\n",
    "\n",
    "min_samples_leaf：表示每个叶结点最小的样本数目，默认为1。如果是float，则它是一个百分率并且ceil(min_samples_leaf*n_samples)是每个节点所需的样本数。\n",
    "    \n",
    "min_weight_fraction_leaf：一个叶节点的输入样本所需要的最小的加权分数，默认为0。\n",
    "\n",
    "max_leaf_nodes:int,None 可选（默认为None），在最优方法中使用max_leaf_nodes构建一个树。最好的节点是在杂质相对减少。如果是None则对叶节点的数目没有限制。如果不是None则不考虑max_depth.\n",
    "class_weight：一个字典列表，'balanced'，None，optional(default=None)，主要是考虑每个类的权重{class_label: weight}\n",
    "\n",
    "min_impurity_split：树增长停止阈值，仅仅当他的impurity超过阈值时才会继续向下分解，否则会成为叶结点\n",
    "\n",
    "class_weight:可以是字典列表,\"Banlanced\" 或者 None,（默认为None）。表示在表{class_label:weight}中的类的关联权值。如果没有指定，所有类的权值都为1。对于多输出问题，一列字典的顺序可以与一列y的次序相同。值为\"balanced\"时模型使用y的值去自动适应权值，并且是以输入数据中类的频率的反比例。\n",
    "\n",
    "random_state:取值为int,RandomState instance 或者 None。如果是int,random_state 是随机数字发生器的种子；如果是RandomState，random_state是随机数字发生器，如果是None，随机数字发生器是np.random使用的RandomState instance.\n",
    "\n",
    "persort:bool,可选（默认为False）。表示在进行拟合前，是否预分数据来加快数的构建。对于数据集非常庞大的分类，presort=true将导致整个分类变的缓慢；当数据集较小，且数的深度有限制，presort=true才会加速分类\n",
    "\n",
    "剩下的就是该模型的一些属性，比如classes_，feature_importances_，max_features_，n_classes_，n_features_， n_outputs_，tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "准确度：0.934348\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "X_train_std=pd.DataFrame(X_train_std,columns=feat_labels)\n",
    "X_test_std=pd.DataFrame(X_test_std,columns=feat_labels)\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "print(svm.fit(X_train_std, y_train))\n",
    "print('准确度：%f'%svm.score(X_train_std,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C：C-SVC的惩罚参数C默认值是1.0。C越大，相当于惩罚松弛变量，希望松弛变量接近0，即对误分类的惩罚增大，趋向于对训练集全分对的情况，这样对训练集测试时准确率很高，但泛化能力弱。C值小，对误分类的惩罚减小，允许容错，将他们当成噪声点，泛化能力较强。也是一种正则化。\n",
    "\n",
    "kernel：核函数，默认是rbf，可以是‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’     \n",
    "&emsp;&emsp;&emsp;&emsp;线性：u'v;   \n",
    "&emsp;&emsp;&emsp;&emsp;多项式：(gamma*u'*v + coef0)^degree;   \n",
    "&emsp;&emsp;&emsp;&emsp;RBF函数：exp(-gamma|u-v|^2);   \n",
    "&emsp;&emsp;&emsp;&emsp;sigmoid：tanh(gamma*u'*v + coef0);   \n",
    "degree ：多项式poly函数的维度，默认是3，选择其他核函数时会被忽略。           \n",
    "\n",
    "gamma ：'rbf','poly'和'sigmoid'的核函数参数。默认是'auto'，则会选择1/n_features       \n",
    "  \n",
    "coef0 ：float类型，可选，默认为0.0 在核函数中是独立的，是'poly','sigmoid’函数中的 r 。       \n",
    "\n",
    "probability ：布尔类型，默认为False ,决定是否启用概率估计。需要在训练fit()模型时加上这个参数，之后才能用相关的方法：predict_proba和predict_log_proba。    \n",
    "\n",
    "shrinking ：是否采用shrinking heuristic方法，默认为true    \n",
    "\n",
    "tol ：停止训练的误差值大小，默认为1e-3   \n",
    "\n",
    "cache_size ：核函数cache缓存大小，默认为200   \n",
    "\n",
    "class_weight ：类别的权重，字典形式传递。设置第几类的参数C为weight*C(C-SVC中的C)   \n",
    "\n",
    "verbose ：允许冗余输出   \n",
    "\n",
    "max_iter ：求解器中的迭代次数限制，如果是-1表示没有限制。   \n",
    "\n",
    "decision_function_shape ：‘ovo’, ‘ovr’ or None, default=None。决策函数的类型。多分类情况使用可以选择“ovo”(one vs one 的缩写)，“ovr”(one vs rest的缩写)，否则默认是None。    \n",
    "\n",
    "random_state ：数据洗牌时的种子值，int值   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "准确度：0.932218\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski',n_jobs=-1)\n",
    "print(knn.fit(X_train, y_train))\n",
    "print('准确度：%f'%knn.score(X_train_std,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithm：对于这个参数，一共有4种可选输入，'brute'对应蛮力算法，'kd_tree'对应KD树算法，'ball_tree'对应球树算法，'auto'则会在上面三种算法中做权衡，选择一个拟合最好的最优算法。如果输入样本特征是稀疏的时候，无论我们选择哪种算法，最后scikit-learn都会去用蛮力实现‘brute’。   \n",
    "\n",
    "leaf_size:这个值控制了使用KD树或者球树时， 停止建子树的叶子节点数量的阈值。这个值越小，则生成的KD树或者球树就越大，层数越深，建树时间越长，反之，则生成的KD树或者球树会小，层数较浅，建树时间较短。默认是30.    \n",
    "\n",
    "metric: 距离度量,默认的是欧式距离（即p=2的闵可夫斯基距离）可以使用的距离度量参数有：   \n",
    "a) 欧式距离 “euclidean”    \n",
    "b) 曼哈顿距离 “manhattan”    \n",
    "c) 切比雪夫距离“chebyshev”    \n",
    "d) 闵可夫斯基距离 “minkowski”    \n",
    "e) 带权重闵可夫斯基距离 “wminkowski”    \n",
    "f) 标准化欧式距离 “seuclidean”    \n",
    "g) 马氏距离“mahalanobis”    \n",
    "\n",
    "p:p是使用距离度量参数 metric 附属参数，只用于闵可夫斯基距离和带权重闵可夫斯基距离中p值的选择，p=1为曼哈顿距离， p=2为欧式距离。默认为2\n",
    "\n",
    "n_jobs：主要用于多核CPU时的并行处理，加快建立KNN树和预测搜索的速度。一般用默认的-1就可以了，即所有的CPU核都参与计算。\n",
    "\n",
    "n_neighbors：K值的选择与样本分布有关，一般选择一个较小的K值，可以通过交叉验证来选择一个比较优的K值，默认值是5。如果数据是三维或者三维以下的，可以通过可视化观察来调参。   \n",
    "\n",
    "weights：主要用于标识每个样本的K个近邻样本的权重。可以选择\"uniform\",\"distance\" 或者自定义权重。选择默认的\"uniform\"，意味着所有最近邻样本权重都一样，在做预测时一视同仁。如果是\"distance\"，则权重和距离成反比例，即距离预测目标更近的近邻具有更高的权重，这样在预测类别时，更近的近邻所占的影响因子会更加大。还有可以自定义权重，即自定义一个函数，输入是距离值，输出是权重值。可以自己控制不同的距离所对应的权重。      \n",
    "如果样本的分布是比较成簇的，即各类样本都在相对分开的簇中时，用默认的\"uniform\"就可以了，如果样本的分布比较乱，规律不好寻找，选择\"distance\"会好些。如果用\"distance\"发现预测的效果的还是不好，可以考虑自定义距离权重来调优这个参数。   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4.在测试集上进行预测，计算准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误分类数: 2171\n",
      "测试集准确度：0.933886\n"
     ]
    }
   ],
   "source": [
    "# LR\n",
    "y_pred_lr=lr.predict(X_test)\n",
    "print('错误分类数: %d' % (y_test != y_pred_lr).sum())\n",
    "print ('测试集准确度：%f'%lr.score(X_test_std,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误分类数: 2498\n",
      "测试集准确度：0.935021\n"
     ]
    }
   ],
   "source": [
    "# 决策树\n",
    "y_pred_tree=tree.predict(X_test)\n",
    "print('错误分类数: %d' % (y_test != y_pred_tree).sum())\n",
    "print('测试集准确度：%f'%tree.score(X_test_std,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误分类数: 2171\n",
      "准确度：0.934714\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "y_pred_svm=svm.predict(X_test)\n",
    "print('错误分类数: %d' % (y_test != y_pred_svm).sum())\n",
    "print('测试集准确度：%f'%svm.score(X_test_std,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误分类数: 2213\n",
      "测试集准确度：0.932106\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "y_pred_knn=knn.predict(X_test)\n",
    "print('错误分类数: %d' % (y_test != y_pred_knn).sum())\n",
    "print('测试集准确度：%f'%knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5.查看sklearn的官方说明，了解混淆矩阵等评估标准，并对此例进行评估。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "混淆矩阵的形式如下所示：   \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Predicted   \n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Negative&emsp;&emsp;&emsp;Positive    \n",
    "Actual&emsp;Negative&emsp;&emsp;&emsp;a&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;b    \n",
    "&emsp;&emsp;&emsp;&emsp;Positive&emsp;&emsp;&emsp; c&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;d   \n",
    "\n",
    "a 是真实负样本被正确分类为负样本的数目   \n",
    "b 是真实负样本被错误分类为正样本的数目   \n",
    "c 是真实正样本被错误分类为负样本的数目   \n",
    "d 是真实正样本被正确分类为正样本的数目  \n",
    "\n",
    "1.准确率：  \n",
    "准确率=正确预测的正反例数/总数   \n",
    "Accuracy=true positive and true negative/total cases= a+d/a+b+c+d  \n",
    "\n",
    "2误分类率:     \n",
    "误分类率=错误预测的正反例数/总数   \n",
    "Error rate=false positive and false negative/total cases=b+c/a+b+c+d=1-Accuracy\n",
    "\n",
    "3.覆盖率(正例)：   \n",
    "覆盖率=正确预测到的正例数/实际正例总数   \n",
    "Recall(True Positive Rate，or Sensitivity)=true positive/total actual positive=d/c+d\n",
    "\n",
    "4.命中率：     \n",
    "命中率=正确预测到的正例数/预测正例总数    \n",
    "Precision(Positive Predicted Value,PV+)=true positive/ total predicted positive=d/b+d\n",
    "\n",
    "5.Specificity(负覆盖率)：  \n",
    "负例的覆盖率=正确预测到的负例个数/实际负例总数   \n",
    "Specificity(True Negative Rate)=true negative/total actual negative=a/a+b\n",
    "\n",
    "6.PV-:   \n",
    "负例的命中率=正确预测到的负例个数/预测负例总数   \n",
    "Negative predicted value(PV-)=true negative/total predicted negative=a/a+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30424,     0],\n",
       "       [ 2171,     0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR模型\n",
    "import pylab as pl\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix_lr=confusion_matrix(y_test, y_pred_lr)\n",
    "cnf_matrix_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上所示，准确率为30424/（30424+2171）= 0.933886  模型在预测实际未违约的人未违约（negative-negative）方面表现良好，在预测实际违约的人违约方面表现较差差，出现了2171个违约的人被当做了未违约。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30424     0]\n",
      " [ 2171     0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAENCAYAAAA2ZaOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60063edd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix_lr=confusion_matrix(y_test, y_pred_lr)\n",
    "labels = ['No SeriousDlqin2yrs', 'Yes SeriousDlqin2yrs']\n",
    "print(cnf_matrix_lr)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cnf_matrix_lr)\n",
    "plt.title('Confusion matrix of the classifier')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29346,  1078],\n",
       "       [ 1420,   751]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "cnf_matrix_tree=confusion_matrix(y_test, y_pred_tree)\n",
    "cnf_matrix_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上所示这个模型在给违约人分类为违约人方面比LR模型表现要好些。但是覆盖率还是不太高751/(1420+751)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30424,     0],\n",
       "       [ 2171,     0]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm\n",
    "cnf_matrix_svm=confusion_matrix(y_test, y_pred_svm)\n",
    "cnf_matrix_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30351,    73],\n",
       "       [ 2140,    31]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "cnf_matrix_knn=confusion_matrix(y_test, y_pred_knn)\n",
    "cnf_matrix_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6.银行通常会有更严格的要求，因为fraud带来的后果通常比较严重，一般我们会调整模型的标准。   \n",
    "比如在logistic regression当中，一般我们的概率判定边界为0.5，但是我们可以把阈值设定低一些，来提高模型的“敏感度”   \n",
    "试试看把阈值设定为0.3，再看看这个时候的混淆矩阵等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "错误分类数: 2169\n",
      "准确度：0.933456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30410,    14],\n",
       "       [ 2155,    16]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2',C=1000.0, random_state=0,class_weight={1:0.3,0:0.7})\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr=lr.predict(X_test)\n",
    "print('错误分类数: %d' % (y_test != y_pred_lr).sum())\n",
    "print( '准确度：%f'%lr.score(X_test,y_test))\n",
    "cnf_matrix_lr=confusion_matrix(y_test, y_pred_lr)\n",
    "cnf_matrix_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一次预测可能违约的人明显多了一些，确实检测出了更多的违约的人，但是也有一部分未违约的人被预测违约了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 7.尝试对不同特征的重要度进行排序，通过特征选择的方式，对特征进行筛选。并重新建模，观察此时的模型准确率等评估指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1）尝试用随机森林算法可以计算每一个属性的重要性。根据这个值对各个特征排序，然后选出4个特征重新建模。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0) RevolvingUtilizationOfUnsecuredLines 0.187480\n",
      " 1) DebtRatio                      0.172384\n",
      " 2) MonthlyIncome                  0.166640\n",
      " 3) age                            0.122597\n",
      " 4) NumberOfOpenCreditLinesAndLoans 0.089066\n",
      " 5) NumberOfTimes90DaysLate        0.088948\n",
      " 6) NumberOfTime30-59DaysPastDueNotWorse 0.051642\n",
      " 7) NumberOfDependents             0.046203\n",
      " 8) NumberOfTime60-89DaysPastDueNotWorse 0.043248\n",
      " 9) NumberRealEstateLoansOrLines   0.031794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = data.columns[1:]\n",
    "forest=RandomForestClassifier(n_estimators=100,random_state=0,n_jobs=-1)\n",
    "forest.fit(X_train,y_train)\n",
    "importances=forest.feature_importances_\n",
    "import numpy as np\n",
    "feat_labels=data.columns[1:]\n",
    "indices=np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print ('%2d) %-*s %f'%(f,30,feat_labels[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度：0.932218\n",
      "错误分类数: 2171\n",
      "测试集准确度：0.933395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30424,     0],\n",
       "       [ 2171,     0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX_train=X_train_std[['RevolvingUtilizationOfUnsecuredLines','DebtRatio','MonthlyIncome','age']]\n",
    "newX_test=X_test_std[['RevolvingUtilizationOfUnsecuredLines','DebtRatio','MonthlyIncome','age']]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2',C=1000.0, random_state=0)\n",
    "lr.fit(newX_train, y_train)\n",
    "\n",
    "print('训练集准确度：%f'%lr.score(newX_train,y_train))\n",
    "\n",
    "y_pred_lr=lr.predict(newX_test)\n",
    "print('错误分类数: %d' % (y_test != y_pred_lr).sum())\n",
    "\n",
    "print ('测试集准确度：%f'%lr.score(newX_test,y_test))\n",
    "cnf_matrix_lr=confusion_matrix(y_test, y_pred_lr)\n",
    "cnf_matrix_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跟本来的结果比没什么变化，看来几个重要的特征确实可以很大程度上主导模型的训练结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2）下面试试循环特征消减法(Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True False False False  True False  True False]\n",
      " 0) RevolvingUtilizationOfUnsecuredLines 0.000000\n",
      " 1) DebtRatio                            1.000000\n",
      " 2) MonthlyIncome                        1.000000\n",
      " 3) age                                  0.000000\n",
      " 4) NumberOfOpenCreditLinesAndLoans      0.000000\n",
      " 5) NumberOfTimes90DaysLate              0.000000\n",
      " 6) NumberOfTime30-59DaysPastDueNotWorse 1.000000\n",
      " 7) NumberOfDependents                   0.000000\n",
      " 8) NumberOfTime60-89DaysPastDueNotWorse 1.000000\n",
      " 9) NumberRealEstateLoansOrLines         0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "lr = LogisticRegression()\n",
    "rfe = RFE(lr, n_features_to_select=4)\n",
    "rfe.fit(X_train_std,y_train)\n",
    "print(rfe.support_) \n",
    "for f in range(X_train.shape[1]):\n",
    "    print('%2d) %-*s %f'%(f,36,feat_labels[indices[f]],rfe.support_[f]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集准确度：0.932376\n",
      "错误分类数: 2172\n",
      "测试集准确度：0.933364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30376,    48],\n",
       "       [ 2124,    47]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newX_train=X_train_std[['DebtRatio','MonthlyIncome','NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse']]\n",
    "newX_test=X_test_std[['DebtRatio','MonthlyIncome','NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse']]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2',C=1000.0, random_state=0)\n",
    "lr.fit(newX_train, y_train)\n",
    "\n",
    "print('训练集准确度：%f'%lr.score(newX_train,y_train))\n",
    "\n",
    "y_pred_lr=lr.predict(newX_test)\n",
    "print('错误分类数: %d' % (y_test != y_pred_lr).sum())\n",
    "\n",
    "print ('测试集准确度：%f'%lr.score(newX_test,y_test))\n",
    "cnf_matrix_lr=confusion_matrix(y_test, y_pred_lr)\n",
    "cnf_matrix_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确度几乎一样，混淆矩阵有一点点不同,这一批特征使得模型在预测违约方面敏感了一点点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(5分送分项，非必答)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
