{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第六周(机器学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月16日至3月18日期间完成，最晚提交时间本周日（3月18日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam6后，进行作答。例如wangwei-exam6\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/4/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>钱峰</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题(共4题，每题5分，共计20分)\n",
    "\n",
    "- note:20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 请写出你了解的机器学习特征工程操作，以及它的意义（面试题）\n",
    "- note: 还可以更全面一些，因为特征不仅仅是数据的处理，还会涉及到业务理解，也会体现在这里，这也里是影响以后模型表现的关键."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " #### 特征工程是一项工程活动，目的是最大限度地从原始数据中提取特征以供算法和模型使用, 特征处理是特征工程的核心部分.包括:\n",
    "* 数据预处理, 修改数据格式.操作有: 无量纲化,对定量特征二值化, 对定性特征哑编码, 缺失值计算,  数据变换.\n",
    "* 当数据预处理完成后，选择有意义的特征输入机器学习的算法和模型进行训练。\n",
    "* 降维.当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.请写出上述特征工程操作的sklearn或者pandas实现方式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.在数据预处理阶段sklearn提供了preproccessing库。   其中的StandardScaler类可以对数据进行标准化，MinMaxScaler类可以对数据进行区间缩放，Normalizer类可以对数据进行归一化，还可以用Binarizer类;对数据进行二值化，Imputer类可以对数据进行缺失值计算，PolynomialFeatures类可以对数据进行多项式转换。          \n",
    "2.完成数据预处理后接下来sklearn提供了feature_selection库来进行特征选择。      \n",
    "1）过滤法（Filter）：VarianceThreshold类可以用方差选择特征，SelectKBest类可以结合相关系数来选择特征，SelectKBest类结合卡方检验来选择特征，SelectKBest类结合最大信息系数法来选择特征。   \n",
    "2）包装法（Wrapper）：RFE类可以进行迭代特征消除。RFE(estimator=LogisticRegression(), n_features_to_select=2).fit_transform(iris.data, iris.target)     \n",
    "3）嵌入法（Ebedded）：使用带惩罚项的基模型，除了筛选出特征外，同时也进行了降维。使用feature_selection库的SelectFromModel类结合带L1惩罚项的逻辑回归模型可以来选择特征比如：SelectFromModel(LR(threshold=0.5, C=0.1)).fit_transform(iris.data, iris.target)。使用SelectFromModel类结&emsp;合带L1以及L2惩罚项的逻辑回归模型来做的正选择为：SelectFromModel(LR(threshold=0.5, C=0.1)).fit_transform(iris.data, iris.target)    \n",
    "3.当特征选择完成后，可以直接训练模型了，但是可能由于特征矩阵过大，导致计算量大，训练时间长的问题，因此降低特征矩阵维度也是必不可少的，在降维方面sklearn提供了decomposition库的PCA类来用主成分分析法降维；还有lda库的LDA类也可以用来降维。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.模型评估中的留一法，留出法，交叉验证分别是什么操作？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 留一法: 假设样本数据集中有N个样本数据。将每个样本单独作为测试集，其余N-1个样本作为训练集，这样得到了N个分类器或模型，用这N个分类器或模型的分类准确率的平均数作为此分类器的性能指标。\n",
    "* 留出法: 将数据集划划分成两个互斥的集合, 其中一个是训练集, 另外一个是测试集\n",
    "* 交叉验证法: 将数据集分成k个子集, 每个子集保证数据分布大体相同, 每次选择k-1个子集的并集作为训练集, 剩下的一个作为测试集."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.如何理解模型的过拟合与欠拟合，以及如何解决？（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 欠拟合: 欠拟合就是模型没有很好地捕捉到数据特征，不能够很好地拟合数据.  <br>\n",
    "* 解决方法: <br>\n",
    "   1）添加其他特征项，有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果。除上面的特征之外，“上下文特征”、“平台特征”等等，都可以作为特征添加的首选项。\n",
    "   2）添加多项式特征，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。例如上面的图片的例子。\n",
    "   3）减少正则化参数，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。\n",
    "* 过拟合: 模型把数据学习的太彻底，以至于把噪声数据的特征也学习到了, 泛化能力差.<br>\n",
    "* 解决方法: <br>\n",
    "    1）重新清洗数据，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。\n",
    "    2）增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。\n",
    "    3）采用正则化方法。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 操作题(共1题，共计80分)\n",
    "\n",
    "- note: 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信用卡欺诈项目(共7项，前5项每题10分，6，7题每题15分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 前期数据导入,预览及处理(此部分勿修改，涉及的数据文件无需复制移动)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0                 1                              0.766127  45.0   \n",
       "1                 0                              0.957151  40.0   \n",
       "2                 0                              0.658180  38.0   \n",
       "3                 0                              0.233810  30.0   \n",
       "4                 0                              0.907239  49.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                   2.0   0.802982         9120.0   \n",
       "1                                   0.0   0.121876         2600.0   \n",
       "2                                   1.0   0.085113         3042.0   \n",
       "3                                   0.0   0.036050         3300.0   \n",
       "4                                   1.0   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                             13.0                      0.0   \n",
       "1                              4.0                      0.0   \n",
       "2                              2.0                      1.0   \n",
       "3                              5.0                      0.0   \n",
       "4                              7.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           6.0                                   0.0   \n",
       "1                           0.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           1.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import zipfile\n",
    "\n",
    "# with zipfile.ZipFile('/home/sxy-s3/0.Teacher/Exam/KaggleCredit2.csv.zip', 'r') as z:\n",
    "# this is my local environment\n",
    "with zipfile.ZipFile('KaggleCredit2.csv.zip', 'r') as z:    \n",
    "    f = z.open('KaggleCredit2.csv')\n",
    "    data = pd.read_csv(f, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112915, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeriousDlqin2yrs                           0\n",
       "RevolvingUtilizationOfUnsecuredLines       0\n",
       "age                                     4267\n",
       "NumberOfTime30-59DaysPastDueNotWorse       0\n",
       "DebtRatio                                  0\n",
       "MonthlyIncome                              0\n",
       "NumberOfOpenCreditLinesAndLoans            0\n",
       "NumberOfTimes90DaysLate                    0\n",
       "NumberRealEstateLoansOrLines               0\n",
       "NumberOfTime60-89DaysPastDueNotWorse       0\n",
       "NumberOfDependents                      4267\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shapey = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06742876076872101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['SeriousDlqin2yrs']\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 1.把数据切分成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Added version check for recent scikit-learn 0.18 checks\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if Version(sklearn_version) < '0.18':\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "else:\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "# last_column_index = data.columns.size   # 总列数\n",
    "# df_info = data.iloc[:, 1: last_column_index]\n",
    "# df_label = data.SeriousDlqin2yrs\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.使用logistic regression建模，并且输出一下系数，分析重要度。   \n",
    "- note: 解释很好呀~   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1)特征标准化\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef_:  [[-0.01427294 -0.36429202  1.72869067  0.31207913 -0.11534462 -0.09187206\n",
      "   1.68994946 -0.19639706 -3.2487085   0.11638382]]\n",
      "intercept_ : [-2.85903863]\n"
     ]
    }
   ],
   "source": [
    "# 2) 逻辑回归建模\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1000.0, random_state=0)\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "print('coef_: ' , lr.coef_)\n",
    "print('intercept_ :' ,lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumberOfTime30-59DaysPastDueNotWorse 1.728691\n",
      "NumberOfTimes90DaysLate              1.689949\n",
      "DebtRatio                            0.312079\n",
      "NumberOfDependents                   0.116384\n",
      "RevolvingUtilizationOfUnsecuredLines -0.014273\n",
      "NumberOfOpenCreditLinesAndLoans      -0.091872\n",
      "MonthlyIncome                        -0.115345\n",
      "NumberRealEstateLoansOrLines         -0.196397\n",
      "age                                  -0.364292\n",
      "NumberOfTime60-89DaysPastDueNotWorse -3.248708\n"
     ]
    }
   ],
   "source": [
    "feat_labels=data.columns[1:]\n",
    "coefs=lr.coef_\n",
    "indices=np.argsort(coefs[0])[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print ('%-*s %f'%(36,feat_labels[indices[f]],coefs[0,indices[f]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重要度分析\n",
    "\n",
    "\n",
    "* 可以看到正系数偏大的有: NumberOfTime30-59DaysPastDueNotWorse NumberOfTimes90DaysLate<br>\n",
    "  即30-59逾期不糟糕, 90天逾期次数. 两个特征对label影响较大, 容易造成超过90天或者更糟糕的逾期.\n",
    "* 负系数偏大的有NumberOfTime60-89DaysPastDueNotWorse, 60-89逾期不糟糕的次数, 次数越多, 最后的超过90天或者更糟糕的逾期的概率越小."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3.使用决策树/SVM/KNN...等sklearn分类算法进行分类，尝试了解参数含义，调整不同的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) 决策树\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* criterion: 可以使用\"gini\"或者\"entropy\"，前者代表基尼系数，后者代表信息增益。\n",
    "* max_depth: 决策树的最大深度\n",
    "* random_state: 随机数生成器种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "svm.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kernel: 核函数，默认是rbf，可以是linear poly rbf sigmoid precomputed\n",
    "* C: 惩罚系数\n",
    "* random_state: 随机数生成器种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5, p=2, metric='minkowski')\n",
    "knn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* n_neighbors: 选取问题点最近的多少个最近邻\n",
    "* metric, p: 距离函数的选项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4.在测试集上进行预测，计算准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_y_pred = lr.predict(X_test_std)       # lr\n",
    "tree_y_pred = tree.predict(X_test_std)   # dt\n",
    "svm_y_pred = svm.predict(X_test_std)     # svm\n",
    "knn_y_pred = knn.predict(X_test_std)     # knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr Accuracy: 0.93\n",
      "dt Accuracy: 0.93\n",
      "svm Accuracy: 0.93\n",
      "knn Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('lr Accuracy: %.2f' % accuracy_score(y_test, lr_y_pred))\n",
    "print('dt Accuracy: %.2f' % accuracy_score(y_test, tree_y_pred))\n",
    "print('svm Accuracy: %.2f' % accuracy_score(y_test, svm_y_pred))\n",
    "print('knn Accuracy: %.2f' % accuracy_score(y_test, knn_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5.查看sklearn的官方说明，了解混淆矩阵等评估标准，并对此例进行评估。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30349,    75],\n",
       "       [ 2080,    91]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逻辑回归\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion = confusion_matrix(y_test, lr_y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灵敏度: 0.00279\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp, tn = confusion.ravel()\n",
    "# tn/(tn+fn+fp+tp)\n",
    "print(\"灵敏度: %.5f\" % (tn/(tn+fn+fp+tp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30387,    37],\n",
       "       [ 2128,    43]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树\n",
    "confusion = confusion_matrix(y_test, tree_y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灵敏度: 0.00132\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp, tn = confusion.ravel()\n",
    "# tn/(tn+fn+fp+tp)\n",
    "print(\"灵敏度: %.5f\" % (tn/(tn+fn+fp+tp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30406,    18],\n",
       "       [ 2151,    20]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm\n",
    "confusion = confusion_matrix(y_test, svm_y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灵敏度: 0.00061\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp, tn = confusion.ravel()\n",
    "# tn/(tn+fn+fp+tp)\n",
    "print(\"灵敏度: %.5f\" % (tn/(tn+fn+fp+tp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30141,   283],\n",
       "       [ 1922,   249]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# knn\n",
    "confusion = confusion_matrix(y_test, knn_y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灵敏度: 0.00764\n"
     ]
    }
   ],
   "source": [
    "tp, fn, fp, tn = confusion.ravel()\n",
    "# tn/(tn+fn+fp+tp)\n",
    "print(\"灵敏度: %.5f\" % (tn/(tn+fn+fp+tp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估:\n",
    "**金融领域对欺诈比较敏感, 优先考虑灵敏性（Sensitivity）, svm模型对欺诈行为灵敏度稍微高一点点.同时误判率也很高**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6.银行通常会有更严格的要求，因为fraud带来的后果通常比较严重，一般我们会调整模型的标准。   \n",
    "比如在logistic regression当中，一般我们的概率判定边界为0.5，但是我们可以把阈值设定低一些，来提高模型的“敏感度”   \n",
    "试试看把阈值设定为0.3，再看看这个时候的混淆矩阵等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight={1: 0.7, 0: 0.3}, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LogisticRegression(C=1000.0, random_state=0, class_weight={1:0.7, 0:0.3})\n",
    "lr2.fit(X_train_std, y_train)\n",
    "\n",
    "# print('coef_: ' , lr2.coef_)\n",
    "# print('intercept_ :' ,lr2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30220,   204],\n",
       "       [ 1967,   204]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2_y_pred = lr2.predict(X_test_std)\n",
    "confusion = confusion_matrix(y_test, lr2_y_pred)\n",
    "confusion\n",
    "\n",
    "# before: 阈值0.5\n",
    "# array([[30349,    75],\n",
    "#        [ 2080,    91]])\n",
    "# 灵敏度: 0.00279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "灵敏度: 0.00626\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tp, fn, fp, tn = confusion.ravel()\n",
    "# tn/(tn+fn+fp+tp)\n",
    "print(\"灵敏度: %.5f\" % (tn/(tn+fn+fp+tp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估:\n",
    "**灵敏度提升了将近三倍, 误判率也提升了三倍**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 7.尝试对不同特征的重要度进行排序，通过特征选择的方式，对特征进行筛选。并重新建模，观察此时的模型准确率等评估指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) RevolvingUtilizationOfUnsecuredLines 0.188171\n",
      " 2) DebtRatio                      0.172726\n",
      " 3) MonthlyIncome                  0.165907\n",
      " 4) age                            0.122350\n",
      " 5) NumberOfOpenCreditLinesAndLoans 0.089341\n",
      " 6) NumberOfTimes90DaysLate        0.087473\n",
      " 7) NumberOfTime30-59DaysPastDueNotWorse 0.051683\n",
      " 8) NumberOfDependents             0.046091\n",
      " 9) NumberOfTime60-89DaysPastDueNotWorse 0.044425\n",
      "10) NumberRealEstateLoansOrLines   0.031835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "all_columns = data.columns[1:]\n",
    "# all_columns\n",
    "\n",
    "# 吓人的内存以及cpu使用率\n",
    "forest = RandomForestClassifier(n_estimators=500,\n",
    "                                random_state=0,\n",
    "                                n_jobs=-1)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "sorted_columns = np.argsort(importances)[::-1]\n",
    "\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, \n",
    "                            all_columns[sorted_columns[f]], \n",
    "                            importances[sorted_columns[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if Version(sklearn_version) < '0.18':\n",
    "    X_train_std_select = forest.transform(X_train_std, threshold=0.1)\n",
    "    X_test_std_select = forest.transform(X_test_std, threshold=0.1)\n",
    "else:\n",
    "    from sklearn.feature_selection import SelectFromModel\n",
    "    sfm = SelectFromModel(forest, threshold=0.1, prefit=True)\n",
    "    X_train_std_select = sfm.transform(X_train_std)\n",
    "    X_test_std_select = sfm.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30424,     0],\n",
       "       [ 2171,     0]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_select = LogisticRegression(C=1000.0, random_state=0, class_weight={1:0.7, 0:0.3})\n",
    "lr_select.fit(X_train_std_select, y_train)\n",
    "\n",
    "lr_y_select_pred = lr_select.predict(X_test_std_select)\n",
    "confusion = confusion_matrix(y_test, lr_y_select_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估\n",
    "* 反例敏感性急剧下降, 反例全部被当做正例."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(5分送分项，非必答)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**本周对模型, 以及机器学习流程有了大概的了解. 前者理论还不够深入, 后者因为时间比较紧没有通过实际操作加深理解.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "虽然是个小白, 但是能够感受到老师的覆盖面很广, 需要自己去深入学习. <br>\n",
    "这个阶段主要困难跨度有点大, 面比较多, 老师讲的还是很容易懂的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
