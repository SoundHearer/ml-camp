{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第八周(深度学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月30日至4月1日期间完成，最晚提交时间本周日（4月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam8后，进行作答。例如wangwei-exam8\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/8/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>_廖莹____</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简答题(共10题，1-8题每题5分，最后两题每题10分。共计60分)\n",
    "\n",
    "- note: 58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.试写您对深度学习的理解，以及它与传统机器学习的关系，相同与不同之处。\n",
    "\n",
    "- note:是自己写的，可以再补充一些，如可解释性的差别等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 深度学习是利用深度神经网络来补充和解决机器学习现有算法对某些场景问题无法很好解决的一种方法。深度学习范畴的人工神经网络算法，如DNN,RNN,CNN等，由于其多层次的网络结构，可以在特别复杂的场景上有着效果惊人的应用。例如计算机视觉领域，深度学习的方法对于图像特征的抽取、识别有着广泛的应用。同时，深度学习是一种实现机器学习的技术，传统机器学习无法解决的关于时序数据的判断问题，深度学习可以解决。\n",
    "* 两者的相同之处：都需要大量数据的训练，都是对未来数据的预测和判断，不同之处在于深度学习有着复杂的网络层次结构，对硬件性能的要求比机器学习更高。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.简要介绍下您了解的keras框架? 以及进行一个任务的基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Keras是一个高层神经网络API，Keras由纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把想法迅速转换为结果。<br>\n",
    " Keras的核心数据结构是“模型”，模型是一种组织网络层的方式。Keras中主要的模型是Sequential模型，Sequential是一系列网络层按顺序构成的栈。<br>\n",
    "进行任务的基本流程：<br>\n",
    "1.导入Sequential模型：<br>\n",
    "from keras.models import Sequential<br>\n",
    "model = Sequential()<br>\n",
    "2.将一些网络层通过.add()堆叠起来，就构成了一个模型：<br>\n",
    "from keras.layers import Dense, Activation<br>\n",
    "model.add(Dense(units=64, input_dim=100))<br>\n",
    "model.add(Activation(\"relu\"))<br>\n",
    "model.add(Dense(units=10))<br>\n",
    "model.add(Activation(\"softmax\"))<br>\n",
    "3.完成模型的搭建后，使用compile()方法来编译模型,同时指明损失函数和优化器：<br>\n",
    "from keras.optimizers import SGD<br>\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))<br>\n",
    "4.完成模型编译后，开始训练网络模型：<br>\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)<br>\n",
    "5.模型评估：<br>\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)<br>\n",
    "6.模型预测：<br>\n",
    "classes = model.predict(x_test, batch_size=128)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.工业界在训练深度学习模型时，采用训练方式多为SGD（mini-batch），请简述这种方式较其它方式的优点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "SGD训练速度快,对于很大的数据集,也能够以较快的速度收敛，容易收敛到局部最优，其基于梯度优化的在线学习算法，一个重要的性质是每一步更新的计算时间不依赖训练样本数目的大小。即时训练样本数据非常大时，它们也能收敛。对于足够大的数据集，SGD可能会在处理整个训练集之前就收敛到最终测试集误差的某个固定容差范围内。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  请简述神经风格中的BP模型的信号正向传播与误差反向传播的过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "BP的核心思想就是：将输出误差以某种形式通过隐层向输入层逐层反传<br>\n",
    "正向传播：<br>\n",
    "输入样本—>输入层—>各个隐层—>输出层<br>\n",
    "判断是否转入反向传播阶段：<br>\n",
    "若输出层的实际输出与期望的输出不符<br>\n",
    "误差反转：<br>\n",
    "误差以某种形式在各层表示—>修正各层单元的权值<br>\n",
    "网络输出的误差减少到可接受的程度 进行到预先设定的学习次数为止<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  在什么情况下，会使用到早停法earyly stoping? 使用早停法可以防止什么情况发生？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "当模型training error在降，但是validation error已经开始升了的情况下，会使用Early stopping，在迭代收敛之前停止迭代来防止过拟合\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  训练多层神经网络时可以采用哪些方式防止过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " <br>\n",
    "1.引入正则化 <br>\n",
    "由于模型过拟合极有可能是因为我们的模型过于复杂。因此，我们需要让我们的模型在训练的时候，在对损失函数进行最小化的同时，也需要让对参数添加限制，这个限制也就是正则化惩罚项\n",
    "2.Dropout<br>\n",
    "在神经网络进行训练的时候，让部分神经元失活，阻断了部分神经元之间的协同作用，从而强制要求一个神经元和随机挑选出的神经元共同进行工作，减轻了部分神经元之间的联合适应性。<br> \n",
    "3.提前终止训练<br>\n",
    "模型在验证集上的误差在一开始是随着训练集的误差的下降而下降的。当超过一定训练步数后，模型在训练集上的误差虽然还在下降，但是在验证集上的误差却不在下降了。此时模型就可能过拟合了。因此可以观察训练模型在验证集上的误差，一旦当验证集的误差不再下降时，就可以提前终止训练的模型。<br>\n",
    "4.增加样本量<br>\n",
    "深度学习模型学习能力非常强，以至于由于训练数据太少的话，很容易一下子就过拟合了。所以增大数据量，可以有效地解决过拟合。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  进行深度学习任务时，使用激活函数是为了解决什么问题？ 常用的激活函数有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "当线性分类器无法对复杂的场景进行分类的时候，期望引入一些非线性的因素，来更好地解决复杂的问题。而激活函数恰好能够帮助我们引入非线性因素，它使得神经网络能够更好地解决较为复杂的问题。<br>\n",
    "常用的激活函数有Sigmoid函数(输出在[0,1]之间)、tanh函数(输出在[-1,1]之间)、ReLU函数(当x≤0,输出为0；当x>0,输出x)等。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 . 请简要说明CNN网络的框架结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "典型的CNN结构：<br>\n",
    "输入→卷积→ReLU→卷积→ReLU→池化→ReLU→卷积→ReLU→池化→全连接<br>\n",
    "1.卷积（Convolution）特征提取<br>\n",
    "卷积核（Convolution Kernel），也叫过滤器filter，由对应的权值W和偏置b体现<br>\n",
    "卷积特征提取利用了自然图像的统计平稳性，对于这个图像上的所有位置，都能使用同样的学习特征。当有多个filter时，我们就可以学到多个特征，例如：轮廓、颜色等<br>\n",
    "2.池化（Pooling）<br>\n",
    "也叫做下采样，Pooling过程 就是把提取之后的特征看做一个矩阵，并在这个矩阵上划分出几个不重合的区域，然后在每个区域上计算该区域内特征的均值或最大值，然后用这些均值或最大值参与后续的训练 <br>\n",
    "3.激活层<br>\n",
    "在每次卷积操作之后一般都会经过一个非线性层，也是激活层<br>\n",
    "4.全连接层 Fully connected layer<br>\n",
    "将多次卷积和池化后的矩阵展开进行全连接<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请简述应当从哪些方向上思考和解决深度学习中出现的的over fitting问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "1.数据集大小。当数据集过小，以深度学习模型的强学习能力，很容易就会导致过拟合。此时应该增大数据集来防止过拟合<br>\n",
    "2.模型复杂度。当模型过于复杂，层次过多，会导致模型学习能力太强，以至于把训练集所有的特征都学习下来。此时可以考虑采用drop out方法，防止模型过拟合。<br>\n",
    "3.迁移学习的思想。用已有的训练完的网络参数作为初始化，在这个基础上继续训练。这个方法可以节省很多计算时间和资源，并且也是个防止过拟合的方法。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 谈谈您对深度学习中的自适应学习率的了解\n",
    "\n",
    "- note:如果再列出几个常用的学习率的选项和说明就更棒了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "为了能够使得梯度下降法有较好的性能，需要把学习率的值设定在合适的范围内。太大的学习速率导致学习的不稳定，太小值又导致极长的训练时间。自适应学习速率通过保证稳定训练的前提下，达到了合理的高速率，可以减少训练时间。在每次迭代中去调整学习率的值是一种很好的学习率自适应方法。此类方法的基本思路是当离最优值越远，则需要朝最优值移动的就越多，即学习率就应该越大；反之亦反。例如：如果相对于上一次迭代，错误率减少了，就可以增大学习率；如果相对于上一次迭代，错误率增大了（意味着跳过了最优值），那么应该重新设置上一轮迭代的值，并且减少学习率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计40分)\n",
    "\n",
    "- note:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''tf或th为后端，采取不同参数顺序'''\n",
    "from keras import backend as K\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape_ord = (1, img_rows, img_cols)\n",
    "else:  # channel_last\n",
    "    shape_ord = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],) + shape_ord)\n",
    "X_test = X_test.reshape((X_test.shape[0],) + shape_ord)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# 归一化\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "# 标签转换为独热码\n",
    "Y_train = keras.utils.to_categorical(y_train, 10)\n",
    "Y_test = keras.utils.to_categorical(y_test, 10)\n",
    "# from keras.utils import np_utils  \n",
    "# Y_train = np_utils.to_categorical(y_train,10)  \n",
    "# Y_test = np_utils.to_categorical(y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''构建模型'''\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''编译模型''''\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 350s - loss: 0.1199 - acc: 0.9630 - val_loss: 0.0451 - val_acc: 0.9851\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 353s - loss: 0.0432 - acc: 0.9872 - val_loss: 0.0353 - val_acc: 0.9873\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 305s - loss: 0.0302 - acc: 0.9910 - val_loss: 0.0333 - val_acc: 0.9885\n"
     ]
    }
   ],
   "source": [
    "'''模型训练'''\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, epochs=3, verbose=1,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.03331531282831565\n",
      "Test Accuracy: 0.9885\n"
     ]
    }
   ],
   "source": [
    "'''模型评估'''\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''模型预测'''\n",
    "predicted = model.predict(X_test[:10]).argmax(-1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "觉得深度学习很难，很多知识点需要去慢慢消化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "学了很多模型，但不知道对于找工作而言，应该重点掌握哪些模型，还是所有都要掌握"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
