{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第八周(深度学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月30日至4月1日期间完成，最晚提交时间本周日（4月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam8后，进行作答。例如wangwei-exam8\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/8/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>胡宝银</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简答题(共10题，1-8题每题5分，最后两题每题10分。共计60分)\n",
    "\n",
    "- note:60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.试写您对深度学习的理解，以及它与传统机器学习的关系，相同与不同之处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "\n",
    "```\n",
    "深度学习是利用深度神经网络来对大批量数据进行学习，并得到数据内在的模式，深度神经网络包含多个隐层和激活层，能够学习非常复杂的数据模式表达。神经网络的每一个神经元都为上一层的输入分配权重，这个权重的准确与否对其执行的任务会产生直接的影响，神经网络的学习需要大批量的数据，以使得各层权重调整得比较合理。典型的神经网络包括DNN、CNN、RNN等。深度学习是一种实现机器学习的技术，相同点：都是计算机利用给定的训练数据，学习得到数据中的内在模式，从而能够在测试数据给出比较准确的预测；不同点：深度学习模型复杂度远高于传统的机器学习算法；深度学习一般需要海量的数据才能得到较好的效果，而传统的机器学习不然；传统的机器学习简单、高效、可解释性强，而深度学习不然。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.简要介绍下您了解的keras框架? 以及进行一个任务的基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "Keras是一种使用python编写、抽象层次较高的神经网络框架，后端支持Tensorflow、Theano以及CNTK，使用Keras搭建网络快速而高效。Keras具有层次化和模块化的设计理念，使用它能够简易和快速的设计网络原型，Keras支持序简单易懂贯模型和功能强大而灵活函数式模型。\n",
    "基本流程：构造数据->定义网络结构->编译模型->训练模型->对测试集数据进行预测->保存模型。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.工业界在训练深度学习模型时，采用训练方式多为SGD（mini-batch），请简述这种方式较其它方式的优点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "\n",
    "```\n",
    "梯度下降算法分为BGD（Batch Gradient Descent）、SGD（Stochastic Gradient Descent）、MBGD(Min-batch Gradient Descent)，\n",
    "BGD每次迭代利用所有样本计算梯度，当样本量特别大的时候迭代速度非常慢；\n",
    "SGD每次迭代选取一个样本计算梯度，每次迭代计算很快，但是准确性较差，训练波动较大；\n",
    "MBGD每次迭代选取小批量的样本来计算梯度，算法的训练过程比较快，而且也要保证最终参数训练的准确率。\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  请简述神经风格中的BP模型的信号正向传播与误差反向传播的过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "正向传播：模型根据输入，经过隐层、权重参数、激活函数，最终获得模型输出；\n",
    "反向传播：根据模型输出，经过预测值和目标值对比，根据选定的优化算法，计算从输出到输入各层权重更新值，最终来修改权值使预测值和目标值的差距变到最小。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  在什么情况下，会使用到早停法earyly stoping? 使用早停法可以防止什么情况发生？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "使用场景：对比训练集、验证集预测结果，训练集误差（或者损失）持续下降，但是验证集停止下降或者上升，则停止训练；\n",
    "作用：早停法可以防止过拟合发生。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  训练多层神经网络时可以采用哪些方式防止过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "1.当验证集损失停止下降时停止迭代（Early Stopping）；\n",
    "2.考虑增加或者增强正则化；\n",
    "3.Dropout：（训练集dropout，测试集nodropout），之所以有效是因为：\n",
    "\t1）丢弃一部分神经元，不让他学习太多东西，防止把噪音学到，防止过拟合；\n",
    "\t2）dropout可以看做是一种ensemble\n",
    "4.网络结构调整:选择合适的网络结构，如图像问题选择CNN，时序问题选择RNN/LSTM\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  进行深度学习任务时，使用激活函数是为了解决什么问题？ 常用的激活函数有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "作用：激活函数是用来给模型加入非线性因素的,以提高模型的表达能力；\n",
    "常用的激活函数：\n",
    "1.sigmoid\n",
    "2.tanh\n",
    "3.ReLu\n",
    "4.Leaky ReLu\n",
    "5.Maxout\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 . 请简要说明CNN网络的框架结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "1.数据输入层/ Input layer：数据预处理：去均值、归一化、PCA、白化\n",
    "2.卷积计算层/ CONV layer：每个神经元看做一个filter，滑窗大小称为卷积核，每个神经元连接数据窗的权重是固定的，一组固定的权重和不同窗口内数据做内积；\n",
    "3.激励层 / Activation layer：把卷积层输出结果做非线性映射；\n",
    "4.池化层 / Pooling layer：夹在连续的卷积层中间，压缩数据和参数的量，减小过拟合，主要有MaxPooling和AveragePooling；\n",
    "5.全连接层 / FC layer：两层之间所有神经元都有权重连接，通常全连接层在卷积神经网络尾部；\n",
    "6.Batch Normalization层(可能有)：加速训练收敛速度\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请简述应当从哪些方向上思考和解决深度学习中出现的的over fitting问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "考虑方向：\n",
    "1.数据本省的考量，是否有噪声，把模型带偏了；\n",
    "2.训练集和测试集样本分布是否一致；\n",
    "3.样本量是否足够，样本量不够考虑搜集更多的数据。\n",
    "解决：\n",
    "1.当验证集损失停止下降时停止迭代（Early Stopping）；\n",
    "2.考虑增加或者增强正则化；\n",
    "3.Dropout：（训练集dropout，测试集nodropout），之所以有效是因为：\n",
    "\t1）丢弃一部分神经元，不让他学习太多东西，防止把噪音学到，防止过拟合；\n",
    "\t2）dropout可以看做是一种ensemble\n",
    "4.网络结构调整:选择合适的网络结构，如图像问题选择CNN，时序问题选择RNN/LSTM\n",
    "5.考虑增加样本量。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 谈谈您对深度学习中的自适应学习率的了解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 答：\n",
    "```\n",
    "在模型训练过程中常使用梯度下降算法，选择一个合理的学习速率很难，学习率过小，则会导致收敛速度很慢；学习率过大，那么其会阻碍收敛，即在极值点附近会振荡。在传统的梯度下降算法中，模型所有的参数每次更新都是使用相同的学习速率。如果数据特征是稀疏的或者每个特征有着不同的取值统计特征与空间，那么便不能在每次更新中每个参数使用相同的学习速率，那些很少出现的特征应该使用一个相对较大的学习速率。对于神经网络这样有非凸目标函数的模型，容易陷入那些次优的局部极值点（或者鞍点）中。为了解决这些问题，可以选择自适应学习率方法，快速找到参数更新的正确目标方向，加快模型收敛速度。常见的自适应学习率算法有Adagrad、Adadelta、Adam等。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计40分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测\n",
    "- note:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* step1.导入必要的库、模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* step2.超参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "img_rows, img_cols = 28, 28\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* step3.数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000,)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* step4.建模及预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.4707 - acc: 0.8632 - val_loss: 0.1670 - val_acc: 0.9518\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.2149 - acc: 0.9370 - val_loss: 0.1161 - val_acc: 0.9664\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.1664 - acc: 0.9523 - val_loss: 0.0878 - val_acc: 0.9748\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.1355 - acc: 0.9606 - val_loss: 0.0741 - val_acc: 0.9767\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.1182 - acc: 0.9654 - val_loss: 0.0644 - val_acc: 0.9800\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.1067 - acc: 0.9691 - val_loss: 0.0587 - val_acc: 0.9809\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.0962 - acc: 0.9721 - val_loss: 0.0561 - val_acc: 0.9813\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.0901 - acc: 0.9743 - val_loss: 0.0518 - val_acc: 0.9827\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 15s - loss: 0.0835 - acc: 0.9750 - val_loss: 0.0485 - val_acc: 0.9836\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 15s - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0472 - val_acc: 0.9837\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 16s - loss: 0.0761 - acc: 0.9778 - val_loss: 0.0444 - val_acc: 0.9847\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 15s - loss: 0.0724 - acc: 0.9785 - val_loss: 0.0423 - val_acc: 0.9853\n",
      "Test loss: 0.04231992830154486\n",
      "Test accuracy: 0.9853\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* step5.总结：经过评估，实验CNN模型在测试集预测准确率为98.53%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```暂无```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
