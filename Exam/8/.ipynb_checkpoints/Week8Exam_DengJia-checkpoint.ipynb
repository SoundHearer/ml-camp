{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第八周(深度学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月30日至4月1日期间完成，最晚提交时间本周日（4月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam8后，进行作答。例如wangwei-exam8\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/8/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>_邓嘉____</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简答题(共10题，1-8题每题5分，最后两题每题10分。共计60分)\n",
    "\n",
    "- NOTE:45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.试写您对深度学习的理解，以及它与传统机器学习的关系，相同与不同之处。\n",
    "\n",
    "- note:这个，还可以继续补充。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "深度学习是机器学习的一种方法，和传统机器学习一样也分为有监督和无监督，不同之处在于深度学习是用过网络自动抽取特征，而传统的机器学习是需要我们手动的去抽取特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.简要介绍下您了解的keras框架? 以及进行一个任务的基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "keras 是一个基于tensonflow基础之上的一个框架\n",
    "它的基本流程是\n",
    "1 可以创建一个模型\n",
    "2 向模型中添加神经网络，集中可以添加全链接层，卷积层，激励层，池化层等\n",
    "3 编译模型，在编译模型的时候可以指定损失函数，指定训练轮数，优化项，用于选择合适的梯度下降算法等\n",
    "4 训练模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "dims = X_train.shape[1]\n",
    "print(dims, 'dims')\n",
    "print(\"Building model...\")\n",
    "\n",
    "nb_classes = Y_train.shape[1]\n",
    "print(nb_classes, 'classes')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(nb_classes, input_shape=(dims,), activation='sigmoid'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.工业界在训练深度学习模型时，采用训练方式多为SGD（mini-batch），请简述这种方式较其它方式的优点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "sdg是随机梯度下降算法，随机多个初始点用语梯度下降，大大提高了获取全局最优解的概率,mini-batch 可以使其更加快速的收敛\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  请简述神经风格中的BP模型的信号正向传播与误差反向传播的过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "正向传播的过程是\n",
    "通过对输入先做线性映射以后再通过激活函数进行非线性变换以后，再到输出得到一个预测的结果。\n",
    "误差反响传播是指的是误差不断向前传递，也就是说最后一层的误差可以通过预测的结果和实际结果得到，倒数第二层的结果可以有最后一层的误差和激活函数的\n",
    "倒数以及神经元之间的连线的权重w相乘得到，一次由后向前传递，同时神经元之间连线的权重w更新的方向dw也可以通过误差和a相乘的得到，从而一步步更新参数，使的损失函数最小化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  在什么情况下，会使用到早停法earyly stoping? 使用早停法可以防止什么情况发生？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "当验证集上的错误率由下降开始上升，而训练集依然下降的时候，停止继续迭代。这种方式可以防止过拟合的发生"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  训练多层神经网络时可以采用哪些方式防止过拟合？\n",
    "\n",
    "- note:BN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1 添加正则项\n",
    "2 可以使用dropout的方式随机失活部分神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  进行深度学习任务时，使用激活函数是为了解决什么问题？ 常用的激活函数有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "激活函数是用于非线性映射，使得神经网络不会变成一个线性的累加，\n",
    "激活函数有\n",
    "1.relu\n",
    "2.sigmoid\n",
    "3.tanh\n",
    "3.leaky relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 . 请简要说明CNN网络的框架结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " cnn又名卷积神经网络\n",
    " \n",
    " CNN网络由输入层，卷积层，激励层，池化层，全链接层构成。\n",
    " \n",
    " 1输入层\n",
    " 数据输入层，需要指明数据的维度\n",
    " \n",
    " 2卷积层 \n",
    " 每一个神经元对应有一个filter窗口，可以极大的简化调参\n",
    " \n",
    " 3激励层\n",
    " 对输入的值做一个非线性映射\n",
    " \n",
    " 4池化层\n",
    " 降维的操作，降低维度\n",
    " \n",
    " 5全链接层\n",
    " 对前面卷积层抽取出来的特征做一个划分\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请简述应当从哪些方向上思考和解决深度学习中出现的的over fitting问题？\n",
    "- note???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "如果训练集和验证集上的正确率相差比较大的话，模型测试应该是处于over fitting的状态\n",
    "如何解决"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 谈谈您对深度学习中的自适应学习率的了解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1启发式模拟退火，在优化过程中，Weight逐渐变大，因而需要逐渐减小学习率，保证更新平稳\n",
    "2动量法\n",
    "3ada\n",
    "1 思路基本是借鉴L2 Regularizer，训练前期，梯度较小，使得Regularizer项很大，放大梯度。[激励阶段]\n",
    "\n",
    "训练后期，梯度较大，使得Regularizer项很小，缩小梯度。[惩罚阶段]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计40分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测\n",
    "\n",
    "- NOTE:40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_orig = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape_ord = (1, img_rows, img_cols)\n",
    "else:  # channel_last\n",
    "    shape_ord = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_ord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],) + shape_ord)\n",
    "X_test = X_test.reshape((X_test.shape[0],) + shape_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1338)  # for reproducibilty!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the classes to its binary categorical form\n",
    "nb_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Initializing the values for the convolution neural network\n",
    "\n",
    "nb_epoch = 20  # kept very low! Please increase if you have GPU\n",
    "\n",
    "batch_size = 512\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "# Vanilla SGD\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), padding='valid', \n",
    "                 input_shape=shape_ord))  # note: the very first layer **must** always specify the input_shape\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(nb_filters, (nb_conv, nb_conv), padding='valid'))  # note: the very first layer **must** always specify the input_shape\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 1.0921 - acc: 0.6941 - val_loss: 0.3309 - val_acc: 0.9066\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.3118 - acc: 0.9114 - val_loss: 0.2516 - val_acc: 0.9272\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 85s 1ms/step - loss: 0.1829 - acc: 0.9470 - val_loss: 0.1338 - val_acc: 0.9600\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1376 - acc: 0.9597 - val_loss: 0.1373 - val_acc: 0.9569\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 102s 2ms/step - loss: 0.1210 - acc: 0.9653 - val_loss: 0.1174 - val_acc: 0.9633\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.1111 - acc: 0.9671 - val_loss: 0.1339 - val_acc: 0.9581\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.1052 - acc: 0.9693 - val_loss: 0.1112 - val_acc: 0.9673\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 89s 1ms/step - loss: 0.0996 - acc: 0.9700 - val_loss: 0.1264 - val_acc: 0.9609\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.0939 - acc: 0.9721 - val_loss: 0.0988 - val_acc: 0.9697\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.0878 - acc: 0.9743 - val_loss: 0.1123 - val_acc: 0.9651\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 88s 1ms/step - loss: 0.0832 - acc: 0.9749 - val_loss: 0.1052 - val_acc: 0.9684\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 87s 1ms/step - loss: 0.0805 - acc: 0.9758 - val_loss: 0.1021 - val_acc: 0.9679\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.0757 - acc: 0.9771 - val_loss: 0.1071 - val_acc: 0.9687\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 78s 1ms/step - loss: 0.0710 - acc: 0.9791 - val_loss: 0.1070 - val_acc: 0.9676\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0681 - acc: 0.9792 - val_loss: 0.1074 - val_acc: 0.9675\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0656 - acc: 0.9799 - val_loss: 0.1273 - val_acc: 0.9608\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0619 - acc: 0.9811 - val_loss: 0.1113 - val_acc: 0.9681\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0592 - acc: 0.9815 - val_loss: 0.1287 - val_acc: 0.9615\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0547 - acc: 0.9836 - val_loss: 0.1160 - val_acc: 0.9692\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0502 - acc: 0.9844 - val_loss: 0.0999 - val_acc: 0.9716\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train, batch_size=batch_size, \n",
    "                 epochs=nb_epoch, verbose=1, \n",
    "                 validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
