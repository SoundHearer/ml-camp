{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第八周(深度学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月30日至4月1日期间完成，最晚提交时间本周日（4月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam8后，进行作答。例如wangwei-exam8\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/8/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>_陈益梦_</u>  \n",
    "- 批改人： David\n",
    "- 最终得分: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简答题(共10题，1-8题每题5分，最后两题每题10分。共计60分)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.试写您对深度学习的理解，以及它与传统机器学习的关系，相同与不同之处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "深度学习：深度学习是一个框架，在图片和多媒体资源表现更突出，是一种端到端的学习方法。<br>\n",
    "与机器学习关系：深度学习是机器学习的一种。<br>\n",
    "相同之处：使用算法来解析数据、从中学习，然后对真实世界中的事件做出预测。训练过程包括表达，评估和调优。<br>\n",
    "不同之处：在传统机器学习中，手工设计特征对学习效果很重要，但是特征工程非常繁琐。而深度学习能够从大数据中自动学习特征，这也是深度学习在大数据时代受欢迎的一大原因。<br>\n",
    "![](AL_ML_DL.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.简要介绍下您了解的keras框架? 以及进行一个任务的基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras 是易用的神经网络框架，搭建神经网络像搭积木一样简单，后端可以用不同的DL框架支撑，比如theano，Tensorflow，微软的CNTK等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "基本流程：以鸢尾化数据集作为测试数据集<br>\n",
    "(1)引入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequentialquential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)初始化“模型架子” 并通过add添加层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=2, input_dim=4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=3))\n",
    "# model.add(Activation('sigmoid'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)通过compile 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 19\n",
      "Trainable params: 19\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4)灌入数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.9474 - acc: 0.3810\n",
      "Epoch 2/20\n",
      "105/105 [==============================] - 0s 76us/step - loss: 0.8569 - acc: 0.4476\n",
      "Epoch 3/20\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.8193 - acc: 0.5333\n",
      "Epoch 4/20\n",
      "105/105 [==============================] - 0s 86us/step - loss: 0.7967 - acc: 0.6286\n",
      "Epoch 5/20\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.7907 - acc: 0.6476\n",
      "Epoch 6/20\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.7871 - acc: 0.6571\n",
      "Epoch 7/20\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.7834 - acc: 0.6667\n",
      "Epoch 8/20\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.7793 - acc: 0.6667\n",
      "Epoch 9/20\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.7766 - acc: 0.6667\n",
      "Epoch 10/20\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.7744 - acc: 0.6857\n",
      "Epoch 11/20\n",
      "105/105 [==============================] - 0s 57us/step - loss: 0.7714 - acc: 0.6857\n",
      "Epoch 12/20\n",
      "105/105 [==============================] - 0s 48us/step - loss: 0.7688 - acc: 0.6857\n",
      "Epoch 13/20\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.7659 - acc: 0.6857\n",
      "Epoch 14/20\n",
      "105/105 [==============================] - 0s 63us/step - loss: 0.7635 - acc: 0.6857\n",
      "Epoch 15/20\n",
      "105/105 [==============================] - 0s 67us/step - loss: 0.7620 - acc: 0.6857\n",
      "Epoch 16/20\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.7593 - acc: 0.6857\n",
      "Epoch 17/20\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.7563 - acc: 0.6857\n",
      "Epoch 18/20\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.7544 - acc: 0.6857\n",
      "Epoch 19/20\n",
      "105/105 [==============================] - 0s 95us/step - loss: 0.7519 - acc: 0.6857\n",
      "Epoch 20/20\n",
      "105/105 [==============================] - 0s 105us/step - loss: 0.7497 - acc: 0.6857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbcdd5588>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.74741793, 0.6857143]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_on_batch(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5)在测试集上评估效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 978us/step\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.81844032870398631, 0.60000000529819064]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_and_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6)实际预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0104317 ,  0.33325481,  0.65631348],\n",
       "       [ 0.0269481 ,  0.36996248,  0.60308945],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.00518768,  0.30533478,  0.68947756],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.00846328,  0.32487497,  0.66666168],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.02400967,  0.36574122,  0.61024904],\n",
       "       [ 0.01712265,  0.35287651,  0.63000083],\n",
       "       [ 0.03799694,  0.38173598,  0.58026707],\n",
       "       [ 0.0134499 ,  0.34338555,  0.64316452],\n",
       "       [ 0.03396257,  0.37804273,  0.58799469],\n",
       "       [ 0.03005403,  0.37384257,  0.59610343],\n",
       "       [ 0.02004129,  0.35894468,  0.62101406],\n",
       "       [ 0.02829953,  0.3717171 ,  0.59998333],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.02994994,  0.37372091,  0.59632909],\n",
       "       [ 0.0372864 ,  0.38112691,  0.58158666],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.01785322,  0.35449848,  0.62764829],\n",
       "       [ 0.04051011,  0.38376316,  0.57572663],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.01643109,  0.35126933,  0.63229954],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.03515054,  0.37919176,  0.58565772],\n",
       "       [ 0.06641973,  0.39675102,  0.53682923],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.01490911,  0.34745625,  0.63763463],\n",
       "       [ 0.04462105,  0.38669798,  0.568681  ],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.02051807,  0.35984051,  0.61964142],\n",
       "       [ 0.00722569,  0.31854081,  0.67423356],\n",
       "       [ 0.05083393,  0.3903864 ,  0.55877972],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.01679339,  0.35212037,  0.63108623],\n",
       "       [ 0.04009511,  0.38344145,  0.5764634 ],\n",
       "       [ 0.03860839,  0.38224709,  0.5791446 ],\n",
       "       [ 0.00842188,  0.32467833,  0.66689974],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.00908517,  0.32771778,  0.6631971 ],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ],\n",
       "       [ 0.40413627,  0.32021269,  0.2756511 ]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到的是概率\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.工业界在训练深度学习模型时，采用训练方式多为SGD（mini-batch），请简述这种方式较其它方式的优点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "常用优化算法：SGD,RMSprop,Adagrad,Adadelta,Adam<br>\n",
    "SGD(mini-batch)优点：<br>\n",
    "(1) 当训练数据太多时，利用整个数据集更新往往时间上不显示。batch的方法可以减少机器的压力，并且可以更快地收敛。<br>\n",
    "(2) 当训练集有很多冗余时（类似的样本出现多次），batch方法收敛更快。以一个极端情况为例，若训练集前一半和后一半梯度相同。那么如果前一半作为一个batch，后一半作为另一个batch，那么在一次遍历训练集时，batch的方法向最优解前进两个step，而整体的方法只前进一个step。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  请简述神经风格中的BP模型的信号正向传播与误差反向传播的过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "BP算法的基本思想是，学习过程由信号的正向传播与误差的反向传播两个过程组成。<br>\n",
    "　　1）正向传播：输入样本－>输入层－>各隐层（处理）－>输出层<br>\n",
    "　　注1：若输出层实际输出与期望输出（教师信号）不符，则转入2）（误差反向传播过程）。<br>\n",
    "　　2）误差反向传播：输出误差（某种形式）－>隐层（逐层）－>输入层 <br>\n",
    "　　反向传播主要目的是通过将输出误差反传，将误差分摊给各层所有单元，从而获得各层单元的误差信号，进而修正各单元的权值（其过程，是一个权值调整的过程）。<br>\n",
    "　　注2：权值调整的过程，也就是网络的学习训练过程（学习也就是这么的由来，权值调整）。<br>\n",
    "　　1）初始化<br>\n",
    "　　2）输入训练样本对，计算各层输出<br>\n",
    "　　3）计算网络输出误差<br>\n",
    "　　4）计算各层误差信号<br>\n",
    "　　5）调整各层权值<br>\n",
    "　　6）检查网络总误差是否达到精度要求<br>\n",
    "　　满足，则训练结束；不满足，则返回步骤2。<br>\n",
    "　　1）易形成局部极小（属贪婪算法，局部最优)而得不到全局最优；<br>\n",
    "　　2）训练次数多使得学习效率低下，收敛速度慢（需做大量运算）；<br>\n",
    "　　3）隐节点的选取缺乏理论支持；<br>\n",
    "　　4）训练时学习新样本有遗忘旧样本趋势。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  在什么情况下，会使用到早停法earyly stoping? 使用早停法可以防止什么情况发生？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "原因：继续训练会导致测试集上准确率下降<br>\n",
    "作用：防止过拟合和不收敛的现象，加快学习速度，提高调参效率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  训练多层神经网络时可以采用哪些方式防止过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "防止过拟合的方法：<br>\n",
    "1.early stop（及早停止） <br>\n",
    "在模型训练过程中，在训练数据集上，代价函数会一直降低，但是训练出来的模型在测试集上的结果是先升高，在过了一定的训练轮数后，结果会在最高值附近波动甚至减低，这是因为模型学习到了训练数据集的一些独有特性，而这些特性是测试集不具有的，也就是说，这些特性不具有普遍性。 <br>\n",
    "一般来说，训练数据集划分为训练基、验证集、测试集，在训练过程中，每经过一个epoch，就在验证集上进行测试，当测试结果经过几轮不再提高时，就停止训练。 <br>\n",
    "2.data expending（扩大训练数据） <br>\n",
    "在前面提到，过拟合是因为模型学习到了训练集的独有特性，那么如果我们的训练集能够涵盖所有样本空间，那么它就会学习到样本特征空间的普遍特性，而独特性将不复存在，因为测试集不会超出样本的特征空间，所以结果和训练集应该一致。 <br>\n",
    "3、L1和L2正则化加权<br>\n",
    "因为L1约束每次都向权重为零的方向移动，所以导致最后的参数比较稀疏。而L2约束控制了权重的大小，所以权重的幅度较小且比较均匀。<br> \n",
    "4、dropout<br>\n",
    "在每一个batch的训练过程中，先根据删去后的网络预测结果，然后用BP算法更新网络参数。训练很多epochs后，相当于得到了非常多的神经网络（可以说无穷多个），所以drop out会非常有效防止过拟合。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  进行深度学习任务时，使用激活函数是为了解决什么问题？ 常用的激活函数有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "解决问题：假设一个示例神经网络中仅包含线性卷积和全连接运算，那么该网络仅能够表达线性映射，即便增加网络的深度也依旧还是线性映射，难以有效建模实际环境中非线性分布的数据。加入（非线性）激活函数之后，深度神经网络才具备了分层的非线性映射学习能力。<br>\n",
    "常用的激活函数：Sigmoid，tanh，ReLU（变种LReLU、PReLU与RReLU），ELU，Maxout，Softmax<br>\n",
    "- Sigmoid<br>\n",
    "一个平滑函数，并且具有连续性和可微性。与线性函数相比，它的最大优点就是非线性。这意味着多个神经元使用S（Sigmoid简称）形函数作为激活函数时，输出也是非线性的。但是Sigmod 只有在[-3, 3]之间梯度高，容易造成梯度弥散。<br>\n",
    "- tanh<br>\n",
    "sigmoid函数的另一个问题是，y轴取值范围[0，1]。这个函数在原点周围不对称，得到的值都是正的。我们不希望下一个神经元得到的值在任何时候都是正值，不过可以通过缩放sigmoid函数来解决这个问题，缩放之后得到tanh。与Sigmoid函数相比，tanh函数的梯度更陡。 使用sigmoid函数还是tanh函数取决于问题陈述中对梯度的要求。 但是tanh函数出现了Sigmoid函数类似的问题，梯度渐趋平坦，并且值非常低。<br>\n",
    "- ReLU<br>\n",
    "ReLU函数优于其他激活函数的一大优点是它不会同时激活所有的神经元。如果输入值是负的，ReLU函数会转换为0，而神经元不被激活。这意味着，在一段时间内，只有少量的神经元被激活，神经网络的这种稀疏性使其变得高效且易于计算。<br>\n",
    "- LReLU<br>\n",
    "当aiai比较小而且固定的时候，我们称之为LReLU。LReLU最初的目的是为了避免梯度消失。但在一些实验中，我们发现LReLU对准确率并没有太大的影响。很多时候，当我们想要应用LReLU时，我们必须要非常小心谨慎地重复训练，选取出合适的aa，LReLU的表现出的结果才比ReLU好。因此有人提出了一种自适应地从数据中学习参数的PReLU。<br>\n",
    "- PReLU<br>\n",
    "PReLU是LReLU的改进，可以自适应地从数据中学习参数。PReLU具有收敛速度快、错误率低的特点。PReLU可以用于反向传播的训练，可以与其他层同时优化。<br>\n",
    "- RReLU<br>\n",
    "在一定程度上能起到正则效果。<br>\n",
    "- ELU<br>\n",
    "ELU减少了正常梯度与单位自然梯度之间的差距，从而加快了学习。在负的限制条件下能够更有鲁棒性。<br>\n",
    "- Maxout<br>\n",
    "maxout网络能够近似任意连续函数，且当w2,b2,…,wn,bn为0时，退化为ReLU。Maxout能够缓解梯度消失，同时又规避了ReLU神经元死亡的缺点，但增加了参数和计算量。<br>\n",
    "- Softmax<br>\n",
    "函数也是一种sigmoid函数，但它在处理分类问题时很方便。sigmoid函数只能处理两个类。softmax函数最好在分类器的输出层使用。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 . 请简要说明CNN网络的框架结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1. 卷积神经网络结构\n",
    "\n",
    "卷积神经网络是一个多层的神经网络，每层都是一个变换（映射），常用卷积convention变换和pooling池化变换，每种变换都是对输入数据的一种处理，是输入特征的另一种特征表达；每层由多个二维平面组成，每个平面为各层处理后的特征图（feature map）。\n",
    "\n",
    "常见结构：\n",
    "![](CNN1)\n",
    "\n",
    "输入层为训练数据，即原始数据，网络中的每一个特征提取层（C-层）都紧跟着一个二次提取的计算层（S-层），这种特有的两次特征提取结构使网络在识别时对输入样本有较高的畸变容忍能力。具体C层和S层的个数不确定，依据具体案例而定；最后一个S，即完成了对原始数据的特征提取后，把S层的特征数据进行向量化（vector），然后连接到相应分类器。\n",
    "\n",
    "一个具有7（输入层+c1+s2+c3+s4+c5+v）层网络结构的字母识别的CNN网络\n",
    "![](CNN2)\n",
    "2  卷积层Convolution作用：\n",
    "\n",
    "卷积操作：用一个滤波器（就是一个小特征矩阵，也称卷积核）在图像矩阵上游走，在对应位置元素相乘，再把相乘的结果相加，最后相加的结果形成新的图像矩阵，游走完成后即完成了对原始图像的卷积变换（映射变换），形成此滤波器下的特征提取。\n",
    "\n",
    "C层是一个特征提取层，为什么用卷积运算；卷积运算一个重要的特点就是，通过卷积运算，可以使原信号特征增强，并且降低噪音；例如用增强边缘的卷积去处理图像，处理后的图像边缘特征增强。\n",
    "\n",
    "3  S层作用：\n",
    "\n",
    "S-层可看作是模糊滤波器，起到二次特征提取的作用。S层又叫做subsample层，子采样层或者pooling（池化）层\n",
    "\n",
    "在通过卷积获得了特征 (features)之后，下一步我们希望利用这些特征去做分类。理论上讲，人们可以用所有提取得到的特征去训练分类器，例如 softmax分类器，但这样做面临计算量的挑战。例如：对于一个 96X96像素的图像，假设我们已经学习得到了400个定义在8X8输入上的特征，每一个特征和图像卷积都会得到一个 (96 − 8 + 1) * (96 − 8 + 1) = 7921 维的卷积特征，由于有 400个特征，所以每个样例 (example)都会得到一个 892 *400 = 3,168,400维的卷积特征向量。学习一\n",
    "\n",
    "个拥有超过 3百万特征输入的分类器十分不便，并且容易出现过拟合 (over-fitting)。\n",
    "\n",
    "为了解决这个问题，首先回忆一下，我们之所以决定使用卷积后的特征是因为图像具有一种“静态性”的属性，这也就意味着在一个图像区域有用的特征极有可能在另一个区域同样适用。因此，为了描述大的图像，一个很自然的想法就是对不同位置的特征进行聚合统计，例如，人们可以计算图像一个区域上的某个特定特征的平均值 (或最大值)。这些概要统计特征不仅具有低得多的维度 (相比使用所有提取得到的特征)，同时还会改善结果(不容易过拟合)。这种聚合的操作就叫做池化 (pooling)，有时也称为平均池化或者最大池化 (取决于计算池化的方法)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请简述应当从哪些方向上思考和解决深度学习中出现的的over fitting问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(1) 数据层面<br>\n",
    "- 获取更多的数据：从数据源头获取；根据当前数据集估计数据分布参数，使用分布产生；数据增强，通过一定规则获取数据，例如图像平移，翻转，缩放，切割等<br>\n",
    "- 考虑数据降维，例如PCA，SVD等，选取重要特征<br>\n",
    "- 重新清洗数据，增大数据的训练集<br>\n",
    "\n",
    "\n",
    "(2) 模型层面<br>\n",
    "\n",
    "\n",
    "- 使用合适的模型：过拟合的主要原因为，数据太少+模型太复杂。对于神经网络来讲，可以减少网络层数及神经元个数；<br>\n",
    "- 训练时间的把控，Early stopping；<br>\n",
    "- Dropout，这是一个很高效的方法，在训练时，每次随机（如50%）忽略隐层的某些节点，这样，我们相当于随机从2^H个模型中采样选择模型，类似于bagging，此外，不同模型之间权值共享，相当于一种权值正则方法，实际效果比L2更好。<br>\n",
    "- 限制权值，即正则化（regularization），L1或L2；<br>\n",
    "- 增加噪声，噪声随着网络传播，按照权值的平方放大，并传播到输出层，对误差cost产生影响。在输入中加高斯噪声，会达到与L2类似的效果；也可在权值和网络响应上加噪声。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 谈谈您对深度学习中的自适应学习率的了解\n",
    "\n",
    "- note:加入常用-几个算法的简要介绍会更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在模型的初期的时候，往往设置为较大的学习速率比较好，因为距离极值点比较远，较大的学习速率可以快速靠近极值点；而，后期，由于已经靠近极值点，模型快收敛了，此时，采用较小的学习速率较好，较大的学习速率，容易导致在真实极值点附近来回波动，就是无法抵达极值点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计40分)\n",
    "\n",
    "- note: 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### （1）load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os, struct, numpy as np\n",
    "\n",
    "# def load_mnist(path, kind='train'):\n",
    "#     '''Load MNIST data from \"path\" '''\n",
    "#     labels_path = os.path.join(path, '{}-labels.idx1-ubyte'.format(kind))\n",
    "#     images_path = os.path.join(path, '{}-images.idx3-ubyte'.format(kind))\n",
    "#     with open(labels_path, 'rb') as lbpath:\n",
    "#         magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "#         labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "#     with open(images_path, 'rb') as imgpath:\n",
    "#         magic, num, rows, cols = struct.unpack('>IIII', imgpath.read(16))\n",
    "#         images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "#     return images, labels\n",
    "\n",
    "# X_train, y_train = load_mnist('E:/AI/WorkSpace/machine_learning/08_Week/data/')\n",
    "# X_test, y_test = load_mnist('E:/AI/WorkSpace/machine_learning/08_Week/data/', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1338)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# X_test_orig = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2)可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f393ad3e470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    img = X_train[y_train == i][0].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "    \n",
    "# 去掉横纵坐标刻度\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "# 自动调整子图显示布局 \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1edc0f586a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=5, ncols=5, sharex=True, sharey=True)\n",
    "\n",
    "ax = ax.flatten()\n",
    "for i in range(25):\n",
    "    img = X_train[y_train == 8][i].reshape(28, 28)\n",
    "    ax[i].imshow(img, cmap='Greys', interpolation='nearest')\n",
    "\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "y_train = to_categorical(y_train, nb_classes)\n",
    "y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_model(dense_layer_sizes, filters, kernel_size, pool_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters, (kernel_size, kernel_size), padding='valid', input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(filters, (kernel_size, kernel_size)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    for layer_size in dense_layer_sizes:\n",
    "        model.add(Dense(layer_size))\n",
    "        model.add(Activation('relu'))\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_model([32], 8, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 8)         80        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 26, 26, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 24, 24, 8)         584       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                36896     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 37,890\n",
      "Trainable params: 37,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 434us/step - loss: 0.6664 - acc: 0.7749\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.3268 - acc: 0.8949\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 0.2768 - acc: 0.9109\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.2511 - acc: 0.9187\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 26s 434us/step - loss: 0.2346 - acc: 0.9250\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 0.2199 - acc: 0.9294\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 25s 423us/step - loss: 0.2204 - acc: 0.9297\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 25s 421us/step - loss: 0.2075 - acc: 0.9343\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 0.2047 - acc: 0.9347\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.1992 - acc: 0.9367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edc02f0748>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 150us/step\n",
      "layer_size=[32] \n",
      "batch_size=32 \n",
      "epochs=10 \n",
      "loss : 0.05478881113802272, acc : 0.9828\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[32] \\nbatch_size=32 \\nepochs=10 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 25s 414us/step - loss: 0.1932 - acc: 0.9385\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 24s 400us/step - loss: 0.1906 - acc: 0.9397\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 25s 414us/step - loss: 0.1848 - acc: 0.9399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edc1ae0cf8>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 151us/step\n",
      "layer_size=[32] \n",
      "batch_size=32 \n",
      "epochs=3 \n",
      "loss : 0.05240208784162823, acc : 0.9828\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[32] \\nbatch_size=32 \\nepochs=3 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.1905 - acc: 0.9394\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 0.1818 - acc: 0.9414\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.1823 - acc: 0.9422\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 25s 418us/step - loss: 0.1756 - acc: 0.9444\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 25s 416us/step - loss: 0.1770 - acc: 0.9424\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 25s 416us/step - loss: 0.1778 - acc: 0.9436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edc1af1908>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 150us/step\n",
      "layer_size=[32] \n",
      "batch_size=32 \n",
      "epochs=6 \n",
      "loss : 0.04335112978842808, acc : 0.9875\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[32] \\nbatch_size=32 \\nepochs=6 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## epochs 为10 和 3 的时候acc低于 epochs 为6的时候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_model([64], 8, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.4001 - acc: 0.8729\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 26s 426us/step - loss: 0.1908 - acc: 0.9422\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 0.1543 - acc: 0.9540\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.1375 - acc: 0.9582\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.1263 - acc: 0.9615\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.1167 - acc: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edd2062c50>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 165us/step\n",
      "layer_size=[64] \n",
      "batch_size=32 \n",
      "epochs=6 \n",
      "loss : 0.06360152727491222, acc : 0.9784\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[64] \\nbatch_size=32 \\nepochs=6 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当batch_size=32 & epochs=6 的时候， layer_size 由32 变为64 的时候，acc 下降0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.1083 - acc: 0.9671\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 26s 430us/step - loss: 0.1067 - acc: 0.9663\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.1034 - acc: 0.9690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edd20c62b0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 155us/step\n",
      "layer_size=[64] \n",
      "batch_size=32 \n",
      "epochs=3 \n",
      "loss : 0.04159635630205948, acc : 0.9868\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[64] \\nbatch_size=32 \\nepochs=3 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当layer_size=[64] & batch_size=32 的时候， epochs 由6改为3，acc 上升0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_model([32, 32], 8, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 0.5464 - acc: 0.8267\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 0.2250 - acc: 0.9381\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 0.1802 - acc: 0.9498\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 25s 423us/step - loss: 0.1551 - acc: 0.9571\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.1445 - acc: 0.9599\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.1342 - acc: 0.9617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbfd608d0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 163us/step\n",
      "layer_size=[32, 32] \n",
      "batch_size=32 \n",
      "epochs=6 \n",
      "loss : 0.056025798399326775, acc : 0.9846\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[32, 32] \\nbatch_size=32 \\nepochs=6 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当batch_size=32 & epochs=6 的时候，layer_size 由 32 改为 [32, 32]，acc 提升0.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 0.1231 - acc: 0.9642\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.1209 - acc: 0.9657\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 26s 429us/step - loss: 0.1144 - acc: 0.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbdcaf198>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 154us/step\n",
      "layer_size=[64] \n",
      "batch_size=32 \n",
      "epochs=3 \n",
      "loss : 0.05985837524168055, acc : 0.9843\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[32, 32] \\nbatch_size=32 \\nepochs=3 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当batch_size=32 & layer_size = [32, 32] 的时候，epochs 由6改为3 ，acc 下降0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = make_model([64, 64], 8, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.3781 - acc: 0.8843\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.1393 - acc: 0.9613\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.1065 - acc: 0.9717\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 26s 433us/step - loss: 0.0928 - acc: 0.9751\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 27s 452us/step - loss: 0.0821 - acc: 0.9779\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 27s 451us/step - loss: 0.0721 - acc: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbe1cd860>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 163us/step\n",
      "layer_size=[64, 64] \n",
      "batch_size=32 \n",
      "epochs=6 \n",
      "loss : 0.041097736657318, acc : 0.9877\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[64, 64] \\nbatch_size=32 \\nepochs=6 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当batch_size=32 & epochs=6 的时候，layer_size 由 [32, 32] 改为 [64, 64]，acc 提升0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0663 - acc: 0.9814\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0609 - acc: 0.9831\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0548 - acc: 0.9842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbfaccf98>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 156us/step\n",
      "layer_size=[64, 64] \n",
      "batch_size=32 \n",
      "epochs=3 \n",
      "loss : 0.042364489167797184, acc : 0.9885\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print('layer_size=[64, 64] \\nbatch_size=32 \\nepochs=3 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当batch_size=32 & layer_size = [64, 64] 的时候，epochs 由6改为3 ，acc 上升 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 25s 411us/step - loss: 0.0396 - acc: 0.9887\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 25s 418us/step - loss: 0.0372 - acc: 0.9893\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 25s 411us/step - loss: 0.0333 - acc: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbee0c6a0>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=48, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 135us/step\n",
      "layer_size=[64, 64] \n",
      "batch_size=48 \n",
      "epochs=3 \n",
      "loss : 0.036038959056374664, acc : 0.9909000032424927\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=48)\n",
    "print('layer_size=[64, 64] \\nbatch_size=48 \\nepochs=3 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer_size=[64, 64] & epochs=3 的时候，batch_size由32 改为48 的时候，acc 提高 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 0.0318 - acc: 0.9907\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 0.0322 - acc: 0.9907\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.0298 - acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1edbfa1ef28>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=52, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 181us/step\n",
      "layer_size=[64, 64] \n",
      "batch_size=54 \n",
      "epochs=3 \n",
      "loss : 0.0419316290483798, acc : 0.9897999975681305\n"
     ]
    }
   ],
   "source": [
    "loss, acc  = model.evaluate(X_test, y_test, batch_size=24)\n",
    "print('layer_size=[64, 64] \\nbatch_size=54 \\nepochs=3 \\nloss : {}, acc : {}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layer_size=[64, 64] & epochs=3 的时候，batch_size由48 改为52 的时候，acc 降低0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 16s 402us/step - loss: 0.8599 - acc: 0.7043\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 15s 384us/step - loss: 0.4217 - acc: 0.8617\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 15s 383us/step - loss: 0.3338 - acc: 0.8916\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.8289 - acc: 0.7179\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 15s 385us/step - loss: 0.3963 - acc: 0.8714\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 390us/step - loss: 0.3139 - acc: 0.8993\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.7108 - acc: 0.7635\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 404us/step - loss: 0.3264 - acc: 0.8953\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 406us/step - loss: 0.2767 - acc: 0.9111\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 16s 411us/step - loss: 0.8098 - acc: 0.7197\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 411us/step - loss: 0.4187 - acc: 0.8592\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 410us/step - loss: 0.3316 - acc: 0.8890\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 393us/step - loss: 0.2927 - acc: 0.9061\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 393us/step - loss: 0.2664 - acc: 0.9154\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 402us/step - loss: 0.2479 - acc: 0.9193\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 16s 395us/step - loss: 0.7553 - acc: 0.7442\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 15s 384us/step - loss: 0.3749 - acc: 0.8784\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 15s 385us/step - loss: 0.3080 - acc: 0.8999\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 15s 387us/step - loss: 0.2799 - acc: 0.9116\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 15s 382us/step - loss: 0.2569 - acc: 0.9162\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 15s 382us/step - loss: 0.2442 - acc: 0.9225\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 16s 402us/step - loss: 0.8203 - acc: 0.7240\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 390us/step - loss: 0.3777 - acc: 0.8789\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.3116 - acc: 0.8993\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.2787 - acc: 0.9098\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 390us/step - loss: 0.2512 - acc: 0.9188\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 390us/step - loss: 0.2408 - acc: 0.9231\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 16s 405us/step - loss: 0.5635 - acc: 0.8149\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 392us/step - loss: 0.2402 - acc: 0.9253\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 392us/step - loss: 0.1947 - acc: 0.9414\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 16s 410us/step - loss: 0.6147 - acc: 0.7981\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 394us/step - loss: 0.2867 - acc: 0.9119\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 392us/step - loss: 0.2173 - acc: 0.9338\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.5754 - acc: 0.8140\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 403us/step - loss: 0.2500 - acc: 0.9234\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 403us/step - loss: 0.2003 - acc: 0.9391\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 16s 403us/step - loss: 0.6229 - acc: 0.7976\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 388us/step - loss: 0.2758 - acc: 0.9153\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 389us/step - loss: 0.2002 - acc: 0.9398\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 388us/step - loss: 0.1675 - acc: 0.9490\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 15s 386us/step - loss: 0.1498 - acc: 0.9556\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 15s 387us/step - loss: 0.1351 - acc: 0.9599\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 16s 404us/step - loss: 0.6280 - acc: 0.7942\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 389us/step - loss: 0.3046 - acc: 0.9070\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.2421 - acc: 0.9263\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.2034 - acc: 0.9388\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 390us/step - loss: 0.1769 - acc: 0.9467\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 389us/step - loss: 0.1566 - acc: 0.9519\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 16s 394us/step - loss: 0.6096 - acc: 0.8016\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.2528 - acc: 0.9232\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 15s 380us/step - loss: 0.2031 - acc: 0.9378\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.1767 - acc: 0.9468\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.1651 - acc: 0.9510\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.1489 - acc: 0.9549\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 16s 395us/step - loss: 0.7454 - acc: 0.7501\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 15s 378us/step - loss: 0.3161 - acc: 0.9072\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 15s 377us/step - loss: 0.2401 - acc: 0.9301\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 16s 408us/step - loss: 0.7851 - acc: 0.7376\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.3283 - acc: 0.8994\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 390us/step - loss: 0.2472 - acc: 0.9267\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 16s 407us/step - loss: 0.7714 - acc: 0.7399\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 388us/step - loss: 0.2949 - acc: 0.9140\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 389us/step - loss: 0.2186 - acc: 0.9357\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.6791 - acc: 0.7787\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 396us/step - loss: 0.2668 - acc: 0.9218\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 397us/step - loss: 0.2014 - acc: 0.9423\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 396us/step - loss: 0.1711 - acc: 0.9505\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 396us/step - loss: 0.1586 - acc: 0.9546\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 396us/step - loss: 0.1467 - acc: 0.9585\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 16s 409us/step - loss: 0.7185 - acc: 0.7662\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 388us/step - loss: 0.3142 - acc: 0.9092\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.2469 - acc: 0.9301\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 389us/step - loss: 0.2066 - acc: 0.9408\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 388us/step - loss: 0.1810 - acc: 0.9470\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 15s 387us/step - loss: 0.1649 - acc: 0.9523\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.7619 - acc: 0.7494\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 388us/step - loss: 0.3161 - acc: 0.9047\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.2346 - acc: 0.9324\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 392us/step - loss: 0.1919 - acc: 0.9440\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 392us/step - loss: 0.1731 - acc: 0.9519\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 392us/step - loss: 0.1585 - acc: 0.9551\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.6168 - acc: 0.8000\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 395us/step - loss: 0.2054 - acc: 0.9419\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 400us/step - loss: 0.1571 - acc: 0.9556\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 17s 435us/step - loss: 0.5477 - acc: 0.8259\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 16s 400us/step - loss: 0.2012 - acc: 0.9441\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 16s 404us/step - loss: 0.1580 - acc: 0.9573\n",
      "Epoch 1/3\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.5271 - acc: 0.8344\n",
      "Epoch 2/3\n",
      "40000/40000 [==============================] - 15s 386us/step - loss: 0.1882 - acc: 0.9476\n",
      "Epoch 3/3\n",
      "40000/40000 [==============================] - 15s 387us/step - loss: 0.1393 - acc: 0.9614\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 17s 422us/step - loss: 0.5877 - acc: 0.8114\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 394us/step - loss: 0.2013 - acc: 0.9446\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 393us/step - loss: 0.1489 - acc: 0.9584\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 391us/step - loss: 0.1304 - acc: 0.9647\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 396us/step - loss: 0.1083 - acc: 0.9701\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 393us/step - loss: 0.0960 - acc: 0.9733\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 17s 436us/step - loss: 0.5549 - acc: 0.8216\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 401us/step - loss: 0.1739 - acc: 0.9523\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 399us/step - loss: 0.1331 - acc: 0.9628\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 397us/step - loss: 0.1125 - acc: 0.9688\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 395us/step - loss: 0.0978 - acc: 0.9722\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 399us/step - loss: 0.0870 - acc: 0.9753\n",
      "Epoch 1/6\n",
      "40000/40000 [==============================] - 17s 433us/step - loss: 0.5676 - acc: 0.8193\n",
      "Epoch 2/6\n",
      "40000/40000 [==============================] - 16s 405us/step - loss: 0.2174 - acc: 0.9397\n",
      "Epoch 3/6\n",
      "40000/40000 [==============================] - 16s 406us/step - loss: 0.1557 - acc: 0.9574\n",
      "Epoch 4/6\n",
      "40000/40000 [==============================] - 16s 405us/step - loss: 0.1227 - acc: 0.9664\n",
      "Epoch 5/6\n",
      "40000/40000 [==============================] - 16s 401us/step - loss: 0.1014 - acc: 0.9727\n",
      "Epoch 6/6\n",
      "40000/40000 [==============================] - 16s 394us/step - loss: 0.0957 - acc: 0.9733\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 25s 423us/step - loss: 0.4630 - acc: 0.8524\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 0.1468 - acc: 0.9593\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.1116 - acc: 0.9694\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 25s 418us/step - loss: 0.0915 - acc: 0.9745\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0794 - acc: 0.9787\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 25s 421us/step - loss: 0.0744 - acc: 0.9795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001EDBFA56BE0>,\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'dense_layer_sizes': [[32], [64], [32, 32], [64, 64]], 'epochs': [3, 6], 'filters': [8], 'kernel_size': [3], 'pool_size': [2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dense_size_candidates = [[32], [64], [32, 32], [64, 64]]\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "my_classifier = KerasClassifier(make_model, batch_size=48)\n",
    "validator = GridSearchCV(my_classifier,\n",
    "                         param_grid={'dense_layer_sizes': dense_size_candidates,\n",
    "                                     # nb_epoch is avail for tuning even when not\n",
    "                                     # an argument to model building function\n",
    "                                     'epochs': [3, 6],\n",
    "                                     'filters': [8],\n",
    "                                     'kernel_size': [3],\n",
    "                                     'pool_size': [2]},\n",
    "                         scoring='neg_log_loss',\n",
    "                         n_jobs=1)\n",
    "validator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parameters of the best model are: \n",
      "{'dense_layer_sizes': [64, 64], 'epochs': 6, 'filters': 8, 'kernel_size': 3, 'pool_size': 2}\n",
      "10000/10000 [==============================] - 2s 233us/step\n",
      "loss :  0.037631808155\n",
      "acc :  0.9884\n"
     ]
    }
   ],
   "source": [
    "print('The parameters of the best model are: ')\n",
    "print(validator.best_params_)\n",
    "\n",
    "best_model = validator.best_estimator_.model\n",
    "metric_names = best_model.metrics_names\n",
    "metric_values = best_model.evaluate(X_test, y_test)\n",
    "for metric, value in zip(metric_names, metric_values):\n",
    "    print(metric, ': ', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网格搜索里得到最好的组合是'dense_layer_sizes': [64, 64], 'epochs': 6, 'filters': 8, 'kernel_size': 3, 'pool_size': 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在学习keras过程中，觉得只有不断执行项目才能成长，将学习的东西掌握。<br>\n",
    "欠缺：任然需要时间熟悉理论与操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "暂无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
