{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第八周(深度学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月30日至4月1日期间完成，最晚提交时间本周日（4月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam8后，进行作答。例如wangwei-exam8\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/8/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>__胡振彪___</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简答题(共10题，1-8题每题5分，最后两题每题10分。共计60分)\n",
    "\n",
    "- note: 58分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.试写您对深度学习的理解，以及它与传统机器学习的关系，相同与不同之处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "深度学习是机器学习中的一个组成分支，是机器学习研究中的一个新的领域，采用层次化的概念体系来理解世界，层次化理念可以让计算机构件简单的概念学习复杂的概念，构成一幅很深的多层次的图，故称为深度学习。\n",
    "\n",
    "不同点：\n",
    "深度学习的概念源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。\n",
    "\n",
    "\n",
    "相同点：\n",
    "同机器学习方法一样，深度机器学习方法也有监督学习与无监督学习之分．不同的学习框架下建立的学习模型很是不同．例如，卷积神经网络就是一种深度的监督学习下的机器学习模型，而深度置信网就是一种无监督学习下的机器学习模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.简要介绍下您了解的keras框架? 以及进行一个任务的基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Keras是一个高层神经网络API，Keras由纯Python编写而成并基Tensorflow、Theano以及CNTK后端。Keras 为支持快速实验而生，能够把你的idea迅速转换为结果，\n",
    "\n",
    "基本流程：数据预处理，利用keras构建模型，编译模型，训练模型，在测试集上测试评估模型的结果，使用模型预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.工业界在训练深度学习模型时，采用训练方式多为SGD（mini-batch），请简述这种方式较其它方式的优点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 深度学习的损失函数是非凸函数，使用梯度下降算法优化，可能得到一个局部最优值。此外，梯度下降法每进行一次迭代都需要将所有的样本进行计算，当样本量十分大的时候，会非常消耗计算资源，收敛速度会很慢。尤其如果像ImageNet那样规模的数据，几乎是不可能完成的。同时由于每次计算都考虑了所有的训练数据，也容易造成过拟合。在某种程度上考虑的太多也会丧失随机性 。\n",
    "- Stochasitc Gradient Descent 简称SGD，基本思想是每一次迭代只计算一个样本的loss，然后再逐渐遍历所有的样本，完成一轮（epoch）的计算。虽然每次依据单个样本会产生较大的波动，但是从整体上来看，最终还是可以成功收敛。由于计算量大大减少，计算速度也可以极大地提升。\n",
    "mini-batch方式的SGD克服了使用单个样本的训练产生很大的波动的缺点，是训练更平稳，占用计算资源更少，速度更快，理论上可以得到一个全局最优值，实际应用效果也很好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  请简述神经风格中的BP模型的信号正向传播与误差反向传播的过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "BP算法的学习过程由信号的正向传播与误差的反向传播两个过程组成。\n",
    "- 正向传播：输入样本－>输入层－>各隐层（处理）－>输出层\n",
    "　　\n",
    "- 误差反向传播：输出误差（某种形式）－>隐层（逐层）－>输入层。\n",
    "其主要目的是通过将输出误差反传，将误差分摊给各层所有单元，从而获得各层单元的误差信号，进而修正各单元的权值（其过程，是一个权值调整的过程）。\n",
    "- BP算法的过程：　1）初始化 2）输入训练样本对，计算各层输出 3）计算网络输出误差 4）计算各层误差信号 5）调整各层权值  6）检查网络总误差是否达到精度要求，满足，则训练结束；不满足，则返回步骤2。\n",
    "　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  在什么情况下，会使用到早停法earyly stoping? 使用早停法可以防止什么情况发生？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "在模型训练过程中，在训练数据集上，代价函数会一直降低，但是训练出来的模型在测试集上的结果是先升高，在过了一定的训练轮数后，结果会在最高值附近波动甚至减低，这是因为模型学习到了训练数据集的一些独有特性，而这些特性是测试集不具有的，也就是说，这些特性不具有普遍性。 一般来说，训练数据集划分为训练基、验证集、测试集，在训练过程中，每经过一个epoch，就在验证集上进行测试，当测试结果经过几轮不再提高时，就停止训练。 \n",
    "\n",
    "可以防止过拟合的发生。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  训练多层神经网络时可以采用哪些方式防止过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "因为神经网络具有很多参数，而训练过程中，如果对这些参数不加以限制，它们很可能会在训练出的模型中含带有训练数据的特性。为了防止这样的情况发生，通常有以下几种方法：    \n",
    "1.early stop（及早停止）    \n",
    "在模型训练过程中，在训练数据集上，代价函数会一直降低，但是训练出来的模型在测试集上的结果是先升高，在过了一定的训练轮数后，结果会在最高值附近波动甚至减低，这是因为模型学习到了训练数据集的一些独有特性，而这些特性是测试集不具有的，也就是说，这些特性不具有普遍性。 \n",
    "一般来说，训练数据集划分为训练基、验证集、测试集，在训练过程中，每经过一个epoch，就在验证集上进行测试，当测试结果经过几轮不再提高时，就停止训练。     \n",
    "2.data expending（扩大训练数据）    \n",
    "在前面提到，过拟合是因为模型学习到了训练集的独有特性，那么如果我们的训练集能够涵盖所有样本空间，那么它就会学习到样本特征空间的普遍特性，而独特性将不复存在，因为测试集不会超出样本的特征空间，所以结果和训练集应该一致。    \n",
    "3.加入正则约束    \n",
    "在代价函数中加入一项正则项，如 L1正则约束、L2正则约束    \n",
    "drop out(随机丢弃)    \n",
    "有一个方法来增强分类器的适应能力，例如训练多个神经网络，然后选取预测结果出现次数最多的结果。例如我们训练得到5个神经网络，对于数字“8”，加入三个网络认为是8，而两个不是，那么我们将其分为“8”。    \n",
    "在网络训练更新的过程中，我们随机抑制一些隐层神经元的表达（比如随机抑制50%的神经元），在每一个batch的训练过程中，先根据删去后的网络预测结果，然后用BP算法更新网络参数。训练很多epochs后，相当于得到了非常多的神经网络（可以说无穷多个），所以drop out会非常有效防止过拟合。 另一种解释是，网络在丢失掉一些参数后仍然坚持朝着代价函数减小的方向移动，这样得到的模型更加健壮，所以结果更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  进行深度学习任务时，使用激活函数是为了解决什么问题？ 常用的激活函数有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "激活函数解决特征的非线性变换的问题， sigmoid函数，ReLU函数，Leaky ReLU,tanh函数等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 . 请简要说明CNN网络的框架结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "层级结构包括：数据输入层/  Input layer，卷积计算层 / CONV layer， ReLU 激励层 / ReLU layer，池化层 / Pooling layer，全连接层 / FC layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请简述应当从哪些方向上思考和解决深度学习中出现的的over fitting问题？\n",
    "\n",
    "- note: 除数据量这个方向外，还有其它的方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "增加训练数据集的量是减少overfitting的途径之一，减小神经网络的规模\n",
    "\n",
    "对于固定的神经网络和固定的训练集,可以通过以下两种方法减少overfitting\n",
    "1.可以通过Regularization减少overfitting　\n",
    "2.可以通过dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 谈谈您对深度学习中的自适应学习率的了解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "超参数（Hyper-Parameter)是困扰神经网络训练的问题之一，因为这些参数不可通过常规方法学习获得。学习率(Leraning Rate)是其中一个超参数。\n",
    "在模型的初期的时候，往往设置为较大的学习速率比较好，因为距离极值点比较远，较大的学习速率可以快速靠近极值点；而，后期，由于已经靠近极值点，模型快收敛了，此时，采用较小的学习速率较好，较大的学习速率，容易导致在真实极值点附近来回波动，就是无法抵达极值点。\n",
    "\n",
    "目前自适应学习率算法有：Adagrad，Adadelta，RMSprop，Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计40分)\n",
    "\n",
    "- note:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#参数设置\n",
    "batch_size =138\n",
    "epochs = 12\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions  \n",
    "img_rows, img_cols = 28, 28  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入数据集\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_orig = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':  \n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)  \n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)  \n",
    "    input_shape = (1, img_rows, img_cols)  \n",
    "else:  \n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)  \n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)  \n",
    "    input_shape = (img_rows, img_cols, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#构建模型\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3),\n",
    "                activation = 'relu',\n",
    "                input_shape = input_shape))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#编译模型\n",
    "model.compile(loss= 'categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 209s 3ms/step - loss: 0.1938 - acc: 0.9408 - val_loss: 0.0708 - val_acc: 0.9792\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.0497 - acc: 0.9843 - val_loss: 0.0372 - val_acc: 0.9882\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 212s 4ms/step - loss: 0.0323 - acc: 0.9902 - val_loss: 0.0303 - val_acc: 0.9896\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0239 - acc: 0.9922 - val_loss: 0.0350 - val_acc: 0.9892\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.0184 - acc: 0.9938 - val_loss: 0.0280 - val_acc: 0.9909\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0293 - val_acc: 0.9913\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0322 - val_acc: 0.9899\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0314 - val_acc: 0.9910\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0344 - val_acc: 0.9911\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0344 - val_acc: 0.9903\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0347 - val_acc: 0.9911\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0364 - val_acc: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14333f28>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = epochs, batch_size= batch_size,verbose=1,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0364057024246\n",
      "Test Accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "#评估准确率\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#做出预测,并绘制图形\n",
    "slice = 15\n",
    "predicted = model.predict(x_test[:slice]).argmax(-1)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "for i in range(slice):\n",
    "    plt.subplot(1, slice, i+1)\n",
    "    plt.imshow(x_test_orig[i], interpolation='nearest')\n",
    "    plt.text(0, 0, predicted[i], color='black', \n",
    "             bbox=dict(facecolor='white', alpha=1))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
