{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第八周(深度学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月30日至4月1日期间完成，最晚提交时间本周日（4月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam8后，进行作答。例如wangwei-exam8\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/8/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>农建华</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简答题(共10题，1-8题每题5分，最后两题每题10分。共计60分)\n",
    "\n",
    "- note:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.试写您对深度学习的理解，以及它与传统机器学习的关系，相同与不同之处。\n",
    "\n",
    "- note: 更？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 对于深度学习，它能够处理数据量很大的信息，更加依赖于硬件的计算能力。与传统的机器学习相比，他们都能对问题进行划分为分类和回归进行处理，都能够对大量的数据进行处理，它们的不同之处在于机器学习的数学逻辑更加的紧密，而对于深度学习，它更像个黑盒子，把数据吃进去以后，进行相应的运算，然后得出结果，我们更"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.简要介绍下您了解的keras框架? 以及进行一个任务的基本流程\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* keras是个很易用的深度学习框架，方面实现各式各样的神经网络，搭建神经网络就像搭积木一样简单，所以方面了我们队各种网络的实现，而不必考虑繁杂搭建网络过程。keras是一个站在巨人肩膀上的深度学习框架，其后端可以用不同的DL框架支撑，比如theano，比如Tensorflow，比如微软的CNTK。\n",
    "* 任务的基本流程：对于Keras框架搭建神经网络有两种方式Sequential/序贯模型和函数式模型；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1.Sequential实现方式：这个方式就像搭积木一样，实现的基本过程如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 引入库，初始化“模型架子”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 通过add来添加层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 例如\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "                    Dense(32, units=784),\n",
    "                    Activation('relu'),Dense(10),Activation('softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 通过compile来编译模型\n",
    "* 在这一层主要使用的参数有：优化器optimizer，损失函数loss，指标列表metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 例如\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 例如\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5 在测试集上评估效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 例如\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6 实际预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 例如\n",
    "classes = model.predict(x_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 总结：以上就是序贯模型的基本实现方式，通过以上步骤完成模型的训练和预测以后，再通过调参来提高模型的准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2.函数式模型实现方式：这个方式实现的过程更加的灵活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 例子：\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通过上面的例子可以看出，对于使用函数式实现步骤是先定义需要的网络层，最后使用Model(inputs=inputs, outputs=predictions)定义网络层的开始于结束。最后通过编译等步骤与序贯实现方式是差不多的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.工业界在训练深度学习模型时，采用训练方式多为SGD（mini-batch），请简述这种方式较其它方式的优点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 对于梯度下降法主要是为了解决梯度的计算，当样本量极大时，梯度计算就变得非常耗时。梯度下降法通常分为三种类型：\n",
    "* 批梯度下降法(GD)：这个方法会使用全量的数据进行训练；\n",
    "* 随机梯度下降法（SGD）:每次计算只使用一个样本，避免在类似样本上计算梯度造成的冗余计算，增加了跳出当前局部最小值的潜力，在逐步缩小学习率的情况下，有与批梯度下降法类似的效果；\n",
    "* 小批量随机梯度下降法(Mini Batch SGD)：每次提低计算使用一个小批量样本，计算比单样本更加稳定，可以很好利用现成的高度优化矩阵运算工具。\n",
    "* 当数据量极大时候，计算会变得非常的慢，使用全量的数据进行训练也可能会造成局部最优得不到最好的效果，所以使用小批量随机梯度下降法(Mini Batch SGD)能够很好的解决这类问题，达到更好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  请简述神经风格中的BP模型的信号正向传播与误差反向传播的过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* BP算法正向传播求损失，反向传播传回误差，根据误差信号修正每一层的权重。对于BP求损失，通过原先给定的参数，把输出的结果与目标进行对比求得误差，对于多层的神经网络，从头到结果事实是个复合函数一层套一层的，可通过每一层的的函数关系求得误差；对于反向传播，其实是对求得的误差进行求导后得到关于W的偏导函数，其实对于某个W的函数偏导求解是一个链式求导的法则，得到关于损失对W的偏导之后，根据一定的学习率通过公式进行参数W的更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  在什么情况下，会使用到早停法earyly stoping? 使用早停法可以防止什么情况发生？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 当模型的学习率、损失函数、优化器，还有各种参数都选对了，训练集的效果很好，导师测试集的效果不好，这时候会考虑模型是否发生了过拟合，这时候可以使用early stoping法对过拟合进行处理，防止模型过拟合。\n",
    "* Early stoping方法：提供一个验证集，盯着验证集的评估效果看，当验证集的评估效果没有发生变化，甚至效果更差了，这时候就使用Early stoping 法停止模型的训练，选取最好的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  训练多层神经网络时可以采用哪些方式防止过拟合？\n",
    "\n",
    "- note:剁成？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 在剁成神经网络中常用防止过拟合的方式有四种：early stopping（早停法）,Weight Decay(权重衰减)，Dropout(随机失活)，Netword Structure(调整网络结构)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  进行深度学习任务时，使用激活函数是为了解决什么问题？ 常用的激活函数有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 激活函数是为了解决非线性的变换，当没有激活函数的时候，它只能进行线性的变换，不过迭代多少轮。\n",
    "* 常用的激活函数：ReLU,Tanh（双曲正切）,Sigmoid, Leakly ReLU, ELU,Maxout 等"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 . 请简要说明CNN网络的框架结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* CNN网络的结果大多分为这几层：数据输入层，卷积计算层，激励层，池化层，全连接层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请简述应当从哪些方向上思考和解决深度学习中出现的的over fitting问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 1.从模型的结构上，模型是否太复杂，对模型进行一些调整；\n",
    "* 2.从数据的角度考虑，是否进行mini-batch的处理；\n",
    "* 3.从损失函数来看，是否符合场景的设置，进行自定义损失函数，来达到更好的效果；\n",
    "* 4.从学习率来看，要选择合适的学习率，避免在优化的过程中大幅度的抖动；\n",
    "* 5.数据是否有大量的噪音，对数据进行相应的处理；\n",
    "* 6.当学习率，损失函数，优化器等各种参数都选对以后，如果还是过拟合，可以使用early stopping（早停法）,Weight Decay(权重衰减)，Dropout(随机失活)，Netword Structure(调整网络结构)等方式对过拟合进行处理；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 谈谈您对深度学习中的自适应学习率的了解\n",
    "\n",
    "- note:常用的自适应学习率有？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* 学习率对于模型找到优化的方向后，然后按照这个方向走多大的步子往这个方向走，这个多大的步子就是学习率。对于学习率要选择合适的，不然会出现抖动，以至于达不到最好的效果；但也不能选择太小的学习率，这样会很慢的收敛，消耗大量的计算机资源。可以把损失函数优化的结果进行可视化，当看到图像抖动很厉害的时候，说明学习率太大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计40分)\n",
    "\n",
    "- note: 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （1）.CNN网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1数据处理部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# 幅度缩放\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# 对数据进行转换，因为在keras中训练等对数据的数量一般要用numpy.ndarray类型\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26c259cd940>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26c2583ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 查看一下数据\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(x_train[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 模型部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# 创建一个系灌模型\n",
    "model = Sequential()\n",
    "# 卷积层，3*3的卷积核，后面接激活函数，relu。32个神经元\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# 池化层\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 正则化\n",
    "model.add(Dropout(0.25))\n",
    "# 全连接层前面的shape要是n*1的，就是类似向量形式，所以沿展开\n",
    "model.add(Flatten())\n",
    "# 全连接\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# 全连接，直接连接到多少个类\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 编译\n",
    "* 告诉他用交叉熵的loss。指定优化器：optimizer=keras.optimizers.Adadelta()，评估的准则：accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.2492 - acc: 0.9233 - val_loss: 0.0629 - val_acc: 0.9790\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 248s 4ms/step - loss: 0.0832 - acc: 0.9748 - val_loss: 0.0379 - val_acc: 0.9879\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 244s 4ms/step - loss: 0.0628 - acc: 0.9815 - val_loss: 0.0417 - val_acc: 0.9861\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 245s 4ms/step - loss: 0.0514 - acc: 0.9849 - val_loss: 0.0292 - val_acc: 0.9898\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 246s 4ms/step - loss: 0.0451 - acc: 0.9862 - val_loss: 0.0316 - val_acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26c27d95400>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 通过以上的结果可以看出，通过CNN网络能够很好的对图像进行识别，准确率很高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0316181664116\n",
      "Test accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总结：通过CMN网络能够很好的识别手写图像，准确率很高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （2）.全连接方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Dropout\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the datasets(加载数据)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 搭建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对数据进行处理，切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "\n",
    "# Put everything on grayscale\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对数据进行切分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 查看一下数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f3860a8588>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwg8ERfiBoAg/EBThB4L6P/DgQCMym7EAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f3847bc6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 9s 198us/step - loss: 2.2101 - acc: 0.2601 - val_loss: 2.0789 - val_acc: 0.4550\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 9s 196us/step - loss: 1.9618 - acc: 0.5754 - val_loss: 1.8356 - val_acc: 0.6507\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 8s 189us/step - loss: 1.7154 - acc: 0.6892 - val_loss: 1.5855 - val_acc: 0.7156\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 8s 188us/step - loss: 1.4698 - acc: 0.7398 - val_loss: 1.3489 - val_acc: 0.7616\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 8s 168us/step - loss: 1.2500 - acc: 0.7776 - val_loss: 1.1486 - val_acc: 0.7913\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 7s 165us/step - loss: 1.0715 - acc: 0.8015 - val_loss: 0.9918 - val_acc: 0.8093\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 8s 169us/step - loss: 0.9342 - acc: 0.8176 - val_loss: 0.8728 - val_acc: 0.8263\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 7s 163us/step - loss: 0.8306 - acc: 0.8305 - val_loss: 0.7828 - val_acc: 0.8359\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 8s 171us/step - loss: 0.7515 - acc: 0.8397 - val_loss: 0.7136 - val_acc: 0.8442\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 8s 172us/step - loss: 0.6903 - acc: 0.8488 - val_loss: 0.6595 - val_acc: 0.8505\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 8s 182us/step - loss: 0.6419 - acc: 0.8549 - val_loss: 0.6161 - val_acc: 0.8578\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 8s 181us/step - loss: 0.6028 - acc: 0.8597 - val_loss: 0.5807 - val_acc: 0.8626\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 9s 189us/step - loss: 0.5706 - acc: 0.8646 - val_loss: 0.5516 - val_acc: 0.8677\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 9s 204us/step - loss: 0.5438 - acc: 0.8687 - val_loss: 0.5268 - val_acc: 0.8704\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 8s 188us/step - loss: 0.5210 - acc: 0.8720 - val_loss: 0.5056 - val_acc: 0.8747\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 9s 193us/step - loss: 0.5014 - acc: 0.8752 - val_loss: 0.4875 - val_acc: 0.8784\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 9s 191us/step - loss: 0.4843 - acc: 0.8783 - val_loss: 0.4717 - val_acc: 0.8813\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 9s 191us/step - loss: 0.4694 - acc: 0.8813 - val_loss: 0.4577 - val_acc: 0.8836\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 9s 191us/step - loss: 0.4561 - acc: 0.8834 - val_loss: 0.4453 - val_acc: 0.8855\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 9s 195us/step - loss: 0.4443 - acc: 0.8856 - val_loss: 0.4342 - val_acc: 0.8873\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "# epochs：表示训练的轮次\n",
    "network_history = model.fit(X_train, Y_train, batch_size=128, \n",
    "                            epochs=20, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小总结：通过上面的训练训练集的准确率达到了百分之80多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 修改以上的模型，再进行训练，看是否会有提高\n",
    "* 加入Dropout层，为了缓解过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 加入Dropout后，再次训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 12s 264us/step - loss: 2.2197 - acc: 0.2207 - val_loss: 2.0670 - val_acc: 0.5141\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 9s 211us/step - loss: 1.9859 - acc: 0.4755 - val_loss: 1.8290 - val_acc: 0.6564\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 1.7619 - acc: 0.6060 - val_loss: 1.5901 - val_acc: 0.7253\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 9s 209us/step - loss: 1.5383 - acc: 0.6748 - val_loss: 1.3632 - val_acc: 0.7634\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 9s 209us/step - loss: 1.3353 - acc: 0.7149 - val_loss: 1.1684 - val_acc: 0.7935\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 9s 210us/step - loss: 1.1674 - acc: 0.7451 - val_loss: 1.0122 - val_acc: 0.8133\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 10s 219us/step - loss: 1.0314 - acc: 0.7675 - val_loss: 0.8916 - val_acc: 0.8263\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 10s 219us/step - loss: 0.9278 - acc: 0.7851 - val_loss: 0.7989 - val_acc: 0.8367\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 10s 227us/step - loss: 0.8450 - acc: 0.7958 - val_loss: 0.7278 - val_acc: 0.8437\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 10s 227us/step - loss: 0.7815 - acc: 0.8065 - val_loss: 0.6718 - val_acc: 0.8509\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 10s 228us/step - loss: 0.7336 - acc: 0.8124 - val_loss: 0.6274 - val_acc: 0.8557\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 10s 227us/step - loss: 0.6899 - acc: 0.8213 - val_loss: 0.5912 - val_acc: 0.8595\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 10s 215us/step - loss: 0.6592 - acc: 0.8244 - val_loss: 0.5613 - val_acc: 0.8627\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 10s 223us/step - loss: 0.6287 - acc: 0.8331 - val_loss: 0.5365 - val_acc: 0.8665\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 11s 234us/step - loss: 0.6058 - acc: 0.8346 - val_loss: 0.5151 - val_acc: 0.8699\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 14s 319us/step - loss: 0.5825 - acc: 0.8396 - val_loss: 0.4968 - val_acc: 0.8735\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 14s 320us/step - loss: 0.5665 - acc: 0.8430 - val_loss: 0.4812 - val_acc: 0.8739\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 14s 315us/step - loss: 0.5524 - acc: 0.8454 - val_loss: 0.4669 - val_acc: 0.8775\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 14s 311us/step - loss: 0.5371 - acc: 0.8513 - val_loss: 0.4547 - val_acc: 0.87975394 -\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 11s 253us/step - loss: 0.5245 - acc: 0.8523 - val_loss: 0.4438 - val_acc: 0.8811\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "# epochs：表示训练的轮次\n",
    "network_history = model.fit(X_train, Y_train, batch_size=128, \n",
    "                            epochs=20, verbose=1, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 再进行修改参数，再训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 11s 237us/step - loss: 0.5145 - acc: 0.8550 - val_loss: 0.4340 - val_acc: 0.8833\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 10s 230us/step - loss: 0.5064 - acc: 0.8546 - val_loss: 0.4248 - val_acc: 0.8859\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 14s 320us/step - loss: 0.4933 - acc: 0.8592 - val_loss: 0.4169 - val_acc: 0.8871\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 14s 305us/step - loss: 0.4848 - acc: 0.8617 - val_loss: 0.4094 - val_acc: 0.8883\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 13s 279us/step - loss: 0.4762 - acc: 0.8640 - val_loss: 0.4025 - val_acc: 0.8899\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 10s 223us/step - loss: 0.4671 - acc: 0.8665 - val_loss: 0.3962 - val_acc: 0.8903\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 10s 216us/step - loss: 0.4649 - acc: 0.8653 - val_loss: 0.3904 - val_acc: 0.8913\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 10s 217us/step - loss: 0.4530 - acc: 0.8693 - val_loss: 0.3850 - val_acc: 0.8918\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 10s 222us/step - loss: 0.4483 - acc: 0.8702 - val_loss: 0.3797 - val_acc: 0.8939\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 10s 218us/step - loss: 0.4441 - acc: 0.8715 - val_loss: 0.3749 - val_acc: 0.8950\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 10s 226us/step - loss: 0.4378 - acc: 0.8733 - val_loss: 0.3703 - val_acc: 0.8956\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 10s 215us/step - loss: 0.4299 - acc: 0.8755 - val_loss: 0.3663 - val_acc: 0.8967\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 10s 232us/step - loss: 0.4288 - acc: 0.8769 - val_loss: 0.3623 - val_acc: 0.8968\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 13s 296us/step - loss: 0.4205 - acc: 0.8778 - val_loss: 0.3586 - val_acc: 0.8975\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 13s 292us/step - loss: 0.4164 - acc: 0.8795 - val_loss: 0.3551 - val_acc: 0.898559 - ac\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 13s 286us/step - loss: 0.4142 - acc: 0.8795 - val_loss: 0.3514 - val_acc: 0.8999oss: 0.4174  - ETA: 0s - loss: 0.4154 \n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 13s 286us/step - loss: 0.4079 - acc: 0.8821 - val_loss: 0.3481 - val_acc: 0.9004A: 3 - ETA: 1s - loss:\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 13s 292us/step - loss: 0.4052 - acc: 0.8827 - val_loss: 0.3451 - val_acc: 0.9013\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 13s 289us/step - loss: 0.4010 - acc: 0.8839 - val_loss: 0.3419 - val_acc: 0.9021\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 10s 216us/step - loss: 0.3998 - acc: 0.8842 - val_loss: 0.3390 - val_acc: 0.9031\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001), \n",
    "              metrics=['accuracy'])\n",
    "network_history = model.fit(X_train, Y_train, batch_size=128, \n",
    "                            epochs=20, verbose=1, validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 小总结：通过对模型加入Dropout后，准确率有所提高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结：通过以上两种方式对手写数字进行识别可以看出，通过CNN网络模型能够更加准确的，效果更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "不足：对深度学习优化的知识还不了解；不知道如何搭建更好的网络；对于深度学习执行的过程不是很了解；不知道如何运用别人训练好的网络。\n",
    "困惑：不知道怎么调参；不知道如何搭建更好的网络。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
