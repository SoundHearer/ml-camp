{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第八周(深度学习)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月30日至4月1日期间完成，最晚提交时间本周日（4月1日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam8后，进行作答。例如wangwei-exam8\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/8/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>于洋</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、简答题(共10题，1-8题每题5分，最后两题每题10分。共计60分)\n",
    "\n",
    "- note:60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.试写您对深度学习的理解，以及它与传统机器学习的关系，相同与不同之处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：\n",
    "- 深度学习的概念源于神经网络，由于现时代数据量越来越大，而传统机器学习算法如SVM的时间复杂度太高，导致很多机器学习算法不能完整的训练和预测，并且在现当今社会硬件设备越来越能够支撑大数据的发展，神经网络对于图像、语音的解决能力就越来越由于其他模型，深度学习是端到端的模型，它会利用BP-SGD等优化方法根据目标进行一个合理的表示。\n",
    "- 相同处与不同处：\n",
    "* 传统机器学习算法：有足够的数学理论进行论述、擅长分析维度较低，可解释性很强的任务。基本算法有决策树、逻辑回归、支持向量机、xgboost等，\n",
    "* 深度学习算法：可解释性比较弱，主要使用的算法理论为深度卷积网络、深度循环网络、递归网络等，擅长分析高维度的数据。比如图像、语音等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.简要介绍下您了解的keras框架? 以及进行一个任务的基本流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：Keras是一个高层神经网络API，Keras由纯Python编写而成并基Tensorflow、Theano以及CNTK后端，支持CNN和RNN或者二者结合，可以从CPU和GPU之间无缝的切换。并且试用版Keras进行模型训练和预测和之前机器学习的过程相一致，简单易用。\n",
    "- 进行一个任务的基本流程：\n",
    "- 1.构造数据：数据是机器学习和深度学习都必不可少的，在数据获取方面我们可能通过读取文件、数据库或者爬虫获得数据。然后对数据进行标准化或者对空值处理等动作。总之开始一个任务肯定是先准备好数据。\n",
    "- 2.构造模型：有了数据就要考虑用什么模型，怎么搭建模型，在深度学习中可供我们选择神经网络模型很多，我们使用不同的神经网络算法进行构造model，在Keras中通过add()将这些网络层堆叠起来。\n",
    "- 3.编译模型：构造完模型之后，我们需要使用model的compile对模型进行编译，在这里可以设置optimizer（优化器），loss（目标函数或损失函数），metrics（评估模型的指标） \n",
    "- 4.训练模型：传入要训练的数据和标签，并指定训练的一些参数，然后进行模型训练，fit方法我们在机器学习算法中也是一直用的一个方法，在深度学习中要特别说一下两个参数batch_size：指定进行梯度下降时每个batch包含的样本数；nb_epoch：整数，训练的轮数，训练数据将会被遍历nb_epoch次。\n",
    "- 5.测试数据：用测试数据测试已经训练好的模型，并可以获得测试结果，从而对模型进行评估，这里用的方法和机器学习中一样，也是predict。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.工业界在训练深度学习模型时，采用训练方式多为SGD（mini-batch），请简述这种方式较其它方式的优点？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：SGD只需要计算损失函数的一阶导数，计算代价小，非常适合训练数据非常大的应用。mini-batch每次迭代只利用部分训练集样本,当训练数据太多时，利用整个数据集更新往往时间上不显示。mini-batch的方法可以减少机器的压力，并且可以更快地收敛；当训练集有很多冗余时（类似的样本出现多次），mini-batch方法收敛更快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.  请简述神经风格中的BP模型的信号正向传播与误差反向传播的过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：基本BP算法包括信号的前向传播和误差的反向传播两个过程。即计算误差输出时按从输入到输出的方向进行，而调整权值和阈值则从输出到输入的方向进行。正向传播时，输入信号通过隐含层作用于输出节点，经过非线性变换，产生输出信号，若实际输出与期望输出不相符，则转入误差的反向传播过程。误差反传是将输出误差通过隐含层向输入层逐层反传，并将误差分摊给各层所有单元，以从各层获得的误差信号作为调整各单元权值的依据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.  在什么情况下，会使用到早停法earyly stoping? 使用早停法可以防止什么情况发生？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：earyly stoping是在训练集和验证集使损失函数的损失值根据学习的轮数而造成思维定式，不降反升而采取的一种方法。我们通常是使用验证集来对损失值进行监视，这种方法多用于由于学习论述过多而可能造成过拟合的时候使用。\n",
    "使用早停法earyly stoping可以防止过拟合的发生"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  训练多层神经网络时可以采用哪些方式防止过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：\n",
    "- 1.早停法：使用验证集监视损失函数，当损失值不降反升的时候，对训练进行叫停。\n",
    "- 2.正则化：使用正则化来对损失函数进行约束\n",
    "- 3.Dropout随机失活：随机关闭掉一些神经元的输入，就是到了某一步就不往下传了，这里边有一个比率的超参数可以用来调节关闭神经元的数量。\n",
    "- 4.对网络结构进行调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  进行深度学习任务时，使用激活函数是为了解决什么问题？ 常用的激活函数有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：以为如果不引入激活函数，网络的不断地叠加也是线性的，激活函数就是用来加入非线性因素的，因为线性模型的表达能力不够。激活函数可以引入非线性因素，解决线性模型所不能解决的问题。  \n",
    "常用的激活函数有sigmoid：当取值在函数的两段时会导致梯度趋近于0，从而导致模型学不动\n",
    "tanh：存在和sigmoid函数同样的问题\n",
    "ReLU：由两段射线组成，是非线性变换的函数，并且简单，可以避免了梯度消失与爆炸问题\n",
    "Leaky ReLU：对ReLU的变化，左侧不再是和横坐标重合的，而是有一定角度α。\n",
    "Maxout：两段或者多段射线组成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 . 请简要说明CNN网络的框架结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：卷积神经网络CNN是层级结构，主要的层次有数据输入层、卷积计算层、激励层、池化层和全连接层，这些层次穿插着组合在一起。<br>\n",
    "输入层为训练数据，即原始数据，网络中的每一个特征提取层（C-层）都紧跟着一个二次提取的计算层（S-层），这种特有的两次特征提取结构使网络在识别时对输入样本有较高的畸变容忍能力。具体C层和S层的个数不确定，依据具体案例而定；最后一个S，即完成了对原始数据的特征提取后，把S层的特征数据进行向量化（vector），然后连接到相应分类器。<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.请简述应当从哪些方向上思考和解决深度学习中出现的的over fitting问题？\n",
    "\n",
    "- note:你提醒得对，有时不光是过拟合的问题，也可能会出现欠拟合。这时就要从一开始出发，模型，数据与标签本身的相关性，调参等方面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：在深度学习中模型不够理想，可能不是过拟合了，可能是我们考虑问题的方向有问题，此时可能输入和输出之间就没有关系，我们应该从以下方面来考虑是否出现过拟合：\n",
    "- 1.choosing proper loss  找到一个合适的损失函数\n",
    "- 2.mini batch    确定训练时取的数据是否均衡等\n",
    "- 3.new activation function  激活函数\n",
    "- 4.apdative learning rate  学习率调整\n",
    "- 5.动量调整\n",
    "- 如果上述都考虑过了，但是模型还是学得不好，那就要考虑过拟合的问题了，过拟合的问题可以\n",
    "1.正则化项\n",
    "2.early stoping\n",
    "3.构造更多的数据数据\n",
    "4.Dropout\n",
    "等方法对过拟合进行处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. 谈谈您对深度学习中的自适应学习率的了解\n",
    "\n",
    "- note:常用的几个种自适应学习率如果加上会更好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "答：自适应学习率Adagrad是深度学习中的一种优化方法。\n",
    "学习率是一个重要的超参数，它控制着我们基于损失梯度调整神经网络权值的速度，大多数优化算法（如SGD、RMSprop、Adam）对它都有涉及。学习率越小，我们沿着损失梯度下降的速度越慢。从长远来看，这种谨慎慢行的选择可能还不错，因为可以避免错过任何局部最优解，但它也意味着我们要花更多时间来收敛，尤其是如果我们处于曲线的至高点。当学习率过大，就会使模型来回震荡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、实验题(共1题，共计40分)\n",
    "- note:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 请使用keras框架，构建CNN网络完成对MNIST数据集的训练，评估及预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#导入库\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           3,  18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154,\n",
       "         170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
       "         253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253,\n",
       "         253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253,\n",
       "         253, 205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154,\n",
       "         253,  90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139,\n",
       "         253, 190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11,\n",
       "         190, 253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          35, 241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          39, 148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
       "         221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253,\n",
       "         253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253,\n",
       "         253, 195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244,\n",
       "         133,  11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看一下数据\n",
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241,\n",
       "         198, 198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227,\n",
       "         254, 225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,\n",
       "          66,  14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           3, 203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          38, 254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31,\n",
       "         224, 254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133,\n",
       "         254, 254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242,\n",
       "         254, 254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254,\n",
       "         254, 219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254,\n",
       "         207,  18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据处理\n",
    "X_train = X_train.reshape(len(X_train), -1)\n",
    "X_test = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train = (X_train) / 255\n",
    "X_test = (X_test) / 255\n",
    "\n",
    "nb_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#搭建神经网络\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Dense(512, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.3138 - acc: 0.9080 - val_loss: 0.1363 - val_acc: 0.9573\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1390 - acc: 0.9586 - val_loss: 0.1058 - val_acc: 0.9672\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.1000 - acc: 0.9696 - val_loss: 0.0819 - val_acc: 0.9755\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s - loss: 0.0798 - acc: 0.9760 - val_loss: 0.0723 - val_acc: 0.9772\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s - loss: 0.0658 - acc: 0.9802 - val_loss: 0.0670 - val_acc: 0.9799\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 7s - loss: 0.0544 - acc: 0.9829 - val_loss: 0.0647 - val_acc: 0.9800\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 7s - loss: 0.0474 - acc: 0.9850 - val_loss: 0.0628 - val_acc: 0.9813\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 7s - loss: 0.0411 - acc: 0.9873 - val_loss: 0.0604 - val_acc: 0.9814\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 7s - loss: 0.0370 - acc: 0.9887 - val_loss: 0.0612 - val_acc: 0.9822\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 7s - loss: 0.0317 - acc: 0.9905 - val_loss: 0.0588 - val_acc: 0.9819\n",
      "Test loss: 0.05877349252686836\n",
      "Test accuracy: 0.9819\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总共进行了10轮的训练，可以看到损失函数的值从0.3138降低到0.0317,准确率从0.9080升到0.9905。说明效果很好，并且验证准确率达到了0.9819。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
