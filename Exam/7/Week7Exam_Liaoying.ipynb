{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第七周(机器学习-模型调优与融合)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月23日至3月25日期间完成，最晚提交时间本周日（3月25日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam7后，进行作答。例如wangwei-exam7\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/7/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>_廖莹____</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题(共6题，1，2题每题5分，后4题每题10分，共计50分)\n",
    "\n",
    "- note: 50   棒~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 机器学习任务中，通常会将给定数据切分为训练集，验证集，测试集，请回答这三类数据集各自的用途。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "训练集，学习样本数据集，通过匹配一些参数来建立分类器。目的是建立一种分类的方式，用来进行模型训练的。<br>\n",
    "\n",
    "验证集，对学习出来的模型，调整分类器的参数。验证集用来确定模型参数,目的是模型选择，做模型最终优化和确定的<br>\n",
    "\n",
    "测试集，主要用于测试训练好的模型的预测能力，分辨能力，分类能力，推广能力。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.如何将数据转换成xgboost内置用法的libsvm数据格式，以及该格式数据是如何解读的?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "从网上查询资料得知有个工具FormatDataLibsvm.xls可以轻松将数据转换成libsvm格式，\n",
    "例如\n",
    "如下格式的数据：\n",
    "7\t5\t3\t9\t1\n",
    "2\t4\t8\t1\t0\n",
    "1\t4\t7\t0\t1\n",
    "2\t7\t5\t2\t0\n",
    "使用该工具时，需要注意，最后一列是对应libsvm格式的label，然后运行该工具的宏命令，即可转换为libsvm数据格式\n",
    "1\t 1:7\t 2:5\t 3:3\t 4:9\n",
    "0\t 1:2\t 2:4\t 3:8\t 4:1\n",
    "1\t 1:1\t 2:4\t 3:7\t 4:0\n",
    "0\t 1:2\t 2:7\t 3:5\t 4:2\n",
    "然后ibsvm格式的数据再通过xgboost的DMatrix函数读入\n",
    "如data_train = xgb.DMatrix(x_train,label=y_train) \n",
    "                \n",
    "libsvm使用的训练数据和检验数据文件每一行的格式如下：\n",
    "\n",
    "[label] [index1]:[value1] [index2]:[value2] …\n",
    "        \n",
    "label 是训练数据集的目标值，对于分类，它是标识某类的整数(支持多个类)；对于回归，是任意实数\n",
    "\n",
    "index 是有顺序的索引，是以1开始的整数，可以是不连续的，通常是连续的整数。就是指特征编号，必须按照升序排列\n",
    "\n",
    "value 就是特征值，用来train的数据，通常是一堆实数组成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 对于自动特征选择，通常有哪三类方法？试写出每类方式的思想，以及在sklearn中的代码实现（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.过滤型:<br>\n",
    "对每一维的特征“打分”，即给每一维的特征赋予权重，这样的权重就代表着该维特征的重要性，然后依据权重排序。<br>\n",
    "代码实现：<br>\n",
    "sklearn.feature_selection.SelectKBest<br>\n",
    "X_train_new_feature = SelectKBest(k=2).fit_transform(X_train,y_train)<br>\n",
    "2.包裹型:<br>\n",
    "将子集的选择看作是一个搜索寻优问题，生成不同的组合，对组合进行评价，再与其他的组合进行比较。<br>\n",
    "这样就将子集的选择看作是一个是一个优化问题。<br>\n",
    "代码实现：<br>\n",
    "sklearn.feature_selection.RFE<br>\n",
    "rfe = RFE(estimator=rf, n_features_to_select=2)<br>\n",
    "X_train_new_feature = rfe.fit_transform(X_train,y_train)<br>\n",
    "3.嵌入型：<br>\n",
    "在模型既定的情况下学习出对提高模型准确性最好的属性。在确定模型的过程中，挑选出那些对模型的训练有重要意义的属性。<br>\n",
    "代码实现：<br>\n",
    "feature_selection.SelectFromModel<br>\n",
    "model_new = SelectFromModel(model, prefit=True)<br>\n",
    "X_train_new_feature = model_new.transform(X_train)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.网格搜索交叉验证的作用是什么，并简述网格搜索交叉验证是如何运行的？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "网格搜索交叉验证的作用是进行参数调优，给出一个模型中需要改动的所用的参数，程序会使用穷举法来将所用的参数都运行一遍，<br>\n",
    "并对每一个参数都进行交叉验证，通过调节每一个参数来跟踪评分结果，根据评分结果得出最佳参数<br>\n",
    "例如定义这样一组参数param_grid={'para：': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]<br>\n",
    "使用GridSearchCV进行网格搜索交叉验证的过程如下：<br>\n",
    "from sklearn.grid_search import GridSearchCV<br>\n",
    "grid = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')<br>\n",
    "grid.fit(X, y) <br>\n",
    "grid.grid-scores-<br>\n",
    "\n",
    "GridSearchCV中param_grid是给定的参数，这里的grid search针对每个参数进行了10次交叉验证，并且一共对10个参数进行相同过程的交叉验证，然后从grid.grid-scores- 输出结果中得出每个参数的评分结果，再由grid.best-params- 可以得出模型的最佳参数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.工业界上模型整合有三大类方式？试简述每类方式其思想？（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.投票器与bagging\n",
    "Voting\n",
    "投票制即为，投票多者为最终的结果。例如一个分类问题，多个模型投票（当然可以设置权重）。最终投票数最多的类为最终被预测的类。\n",
    "使用训练数据的不同随机子集来训练每个 Base Model，最后每个 Base Model 权重相同，分类问题进行投票，回归问题平均。\n",
    "Bagging\n",
    "就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。大概分为这样两步：\n",
    "随机森林就是基于Bagging算法的一个典型例子，采用的基分类器是决策树。\n",
    "\n",
    "2.stacking与blending\n",
    "\n",
    "Stacking\n",
    "基本思想是用一些基分类器进行分类，然后使用令一个分类器对结果进行整合。\n",
    "Stacking的模型可以在特征空间上获取更加多的信息，因为第二阶段模型是以第一阶段模型的预测值会作为特征\n",
    "\n",
    "Blending\n",
    "Blending与Stacking大致相同，只是Blending的主要区别在于训练集不是通过K-Fold的CV策略来获得预测值从而生成第二阶段模型的特征，而是建立一个Holdout集，例如说10%的训练数据，第二阶段的stacker模型就基于第一阶段模型对这10%训练数据的预测值进行拟合。说白了，就是把Stacking流程中的K-Fold CV 改成 HoldOut CV。\n",
    "\n",
    "3.boosting\n",
    "Boosting的思想是一种迭代的方法，每一次训练的时候都更加关心分类错误的样例，给这些分类错误的样例增加更大的权重，\n",
    "下一次迭代的目标就是能够更容易辨别出上一轮分类错误的样例。最终将这些弱分类器进行加权相加。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  我们可以将xgboost的中众多参数分类为哪三类？请写出哪些参数可以用什么方式用来控制过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "xgboost的中众多参数分类为这三类：  \n",
    "通用参数/General Parameters  \n",
    "集成(增强)参数/booster parameters  \n",
    "任务参数/task parameters  \n",
    "\n",
    "eta   \n",
    "为了防止过拟合，更新过程中用到的收缩步长。在每次提升计算之后，算法会直接获得新特征的权重。   \n",
    "eta通过缩减特征的权重使提升计算过程更加保守。缺省值为0.3，取值范围为：[0,1]  \n",
    "max_depth  \n",
    "缺省值为6， 树的最大深度，将其设置为合理的数值有助于防止过拟合  \n",
    "subsample   \n",
    "缺省值为1，表示观测的子样本的比率，将其设置为0.5意味着xgboost将随机抽取一半观测用于数的生长，这将有助于防止过拟合现象  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验题(共2题，每题25分，共计50分)\n",
    "\n",
    "- note:50,所有的点都get到，棒~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 使用XGBoost内置方式，导入iris数据完成分类问题（要求以不同参数设置xgboost运行并比对），最后给出实验总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''导入相关库'''\n",
    "import xgboost as xgb  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn import datasets  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "'''导入数据，并划分训练集和测试集'''\n",
    "iris=datasets.load_iris()  \n",
    "x=iris.data[:,:2]  \n",
    "y=iris.target  \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=3)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''设定xgb的训练集和测试集'''\n",
    "data_train = xgb.DMatrix(x_train,label=y_train)  \n",
    "data_test=xgb.DMatrix(x_test,label=y_test)  \n",
    "watchlist = [ (data_train,'train'), (data_test, 'test') ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次设定参数： {'num_class': 3, 'objective': 'multi:softmax', 'max_depth': 5, 'eta': 0.1} \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[2]\ttrain-merror:0.142857\ttest-merror:0.355556\n",
      "[3]\ttrain-merror:0.133333\ttest-merror:0.333333\n",
      "[4]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[5]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[6]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[7]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[8]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[9]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "classification  error=0.356\n"
     ]
    }
   ],
   "source": [
    "'''参数设定'''\n",
    "param = {}  \n",
    "param['objective'] = 'multi:softmax'  \n",
    "param['eta'] = 0.1  \n",
    "param['max_depth'] =5  \n",
    "param['num_class'] = 3  \n",
    "num_round = 10 #迭代10次，或者说选了10课树\n",
    "  \n",
    "print('第1次设定参数：',param,'\\n模型运行结果如下:')    \n",
    "bst = xgb.train(param, data_train, num_round, watchlist)\n",
    "pred = bst.predict(data_test)\n",
    "labels = data_test.get_label()\n",
    "print ('classification  error=%.3f' % ( sum(1 for i in range(len(pred)) if int(pred[i]>0.5)!=labels[i]) /float(len(pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下验证，基于在prama参数取默认值的情况下，迭代次数是否对模型效果有影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代第1次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "分类错误率 error=0.378\n",
      "迭代第2次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "迭代第3次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[2]\ttrain-merror:0.114286\ttest-merror:0.422222\n",
      "分类错误率 error=0.356\n",
      "迭代第4次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[2]\ttrain-merror:0.114286\ttest-merror:0.422222\n",
      "[3]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "迭代第5次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[2]\ttrain-merror:0.114286\ttest-merror:0.422222\n",
      "[3]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[4]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "迭代第6次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[2]\ttrain-merror:0.114286\ttest-merror:0.422222\n",
      "[3]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[4]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[5]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "迭代第7次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[2]\ttrain-merror:0.114286\ttest-merror:0.422222\n",
      "[3]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[4]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[5]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[6]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "迭代第8次的模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[2]\ttrain-merror:0.114286\ttest-merror:0.422222\n",
      "[3]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[4]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[5]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[6]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "[7]\ttrain-merror:0.104762\ttest-merror:0.422222\n",
      "分类错误率 error=0.356\n"
     ]
    }
   ],
   "source": [
    "param = {}  \n",
    "param['objective'] = 'multi:softmax'  \n",
    "param['eta'] = 0.3 #\n",
    "param['max_depth'] =6 \n",
    "param['num_class'] = 3  \n",
    "num_round =8#\n",
    "for i in range(1,num_round+1):\n",
    "        print('迭代第%i次的模型运行结果如下:'%(i))    \n",
    "        bst = xgb.train(param, data_train, i, watchlist)\n",
    "        pred = bst.predict(data_test)\n",
    "        labels = data_test.get_label()\n",
    "        print ('分类错误率 error=%.3f' % ( sum(1 for i in range(len(pred)) if int(pred[i]>0.5)!=labels[i]) /float(len(pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面结果可以看出，迭代次数对于模型效果是有影响的。当迭代到第3次的时候，模型的错误率不再下降了，分类错误率也不再下降，说明模型在学习到第2课树的时候，已经把样本学习完全，出现了过拟合。也就是迭代次数选择2次即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面验证树的深度，对模型结果的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当迭代次数num_round=2，max_depth=1 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.238095\ttest-merror:0.288889\n",
      "[1]\ttrain-merror:0.238095\ttest-merror:0.266667\n",
      "分类错误率 error=0.378\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=2 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=3 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.142857\ttest-merror:0.355556\n",
      "[1]\ttrain-merror:0.133333\ttest-merror:0.333333\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=4 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=5 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=6 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=7 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=8 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当迭代次数num_round=2，max_depth=9 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.133333\ttest-merror:0.4\n",
      "[1]\ttrain-merror:0.12381\ttest-merror:0.377778\n",
      "分类错误率 error=0.356\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,10):\n",
    "        param = {}  \n",
    "        param['objective'] = 'multi:softmax'  \n",
    "        param['eta'] = 0.3 #\n",
    "        param['max_depth'] =n\n",
    "        param['num_class'] =3\n",
    "        num_round =2 #\n",
    "        print('当迭代次数num_round=2，max_depth=%i'%n,'\\n模型运行结果如下:')    \n",
    "        bst = xgb.train(param, data_train, num_round, watchlist)\n",
    "        pred = bst.predict(data_test)\n",
    "        labels = data_test.get_label()\n",
    "        print ('分类错误率 error=%.3f' % ( sum(1 for i in range(len(pred)) if int(pred[i]>0.5)!=labels[i]) /float(len(pred))))\n",
    "        print('*'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面结果可以得出，当迭代次数为2，树的深度为2的时候，模型的效果最好，分类错误率为最小，0.333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下尝试修改eta参数，查看对模型效果的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当eta=0.10 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当eta=0.20 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当eta=0.30 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当eta=0.40 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当eta=0.50 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.244444\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当eta=0.60 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当eta=0.70 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "分类错误率 error=0.333\n",
      "******************************\n",
      "当eta=0.80 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.244444\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当eta=0.90 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.244444\n",
      "分类错误率 error=0.356\n",
      "******************************\n",
      "当eta=1.00 \n",
      "模型运行结果如下:\n",
      "[0]\ttrain-merror:0.180952\ttest-merror:0.222222\n",
      "[1]\ttrain-merror:0.180952\ttest-merror:0.244444\n",
      "分类错误率 error=0.356\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,11):\n",
    "    param = {}  \n",
    "    param['objective'] = 'multi:softmax'  \n",
    "    param['eta'] =n/10#\n",
    "    param['max_depth'] =2\n",
    "    param['num_class'] =3\n",
    "    num_round =2 #\n",
    "    print('当eta=%.2f'%(n/10),'\\n模型运行结果如下:')    \n",
    "    bst = xgb.train(param, data_train, num_round, watchlist)\n",
    "    pred = bst.predict(data_test)\n",
    "    labels = data_test.get_label()\n",
    "    print ('分类错误率 error=%.3f' % ( sum(1 for i in range(len(pred)) if int(pred[i]>0.5)!=labels[i]) /float(len(pred))))\n",
    "    print('*'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上输出可以看到，当eta取值大于0.8的时候，模型预测效果下降，说明模型eta取值最好是小于0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用XGBoost的sklearn接口，对KaggleCredit2数据完成信用卡欺诈项目的建模及分析（要求以不同参数设置xgboost运行并比对），最后给出实验总结\n",
    "\n",
    "- KaggleCredit2数据文件 位于/home/sxy-s3/0.Teacher/Exam/KaggleCredit2.csv.zip，请勿复制或移动该文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0                 1                              0.766127  45.0   \n",
       "1                 0                              0.957151  40.0   \n",
       "2                 0                              0.658180  38.0   \n",
       "3                 0                              0.233810  30.0   \n",
       "4                 0                              0.907239  49.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                   2.0   0.802982         9120.0   \n",
       "1                                   0.0   0.121876         2600.0   \n",
       "2                                   1.0   0.085113         3042.0   \n",
       "3                                   0.0   0.036050         3300.0   \n",
       "4                                   1.0   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                             13.0                      0.0   \n",
       "1                              4.0                      0.0   \n",
       "2                              2.0                      1.0   \n",
       "3                              5.0                      0.0   \n",
       "4                              7.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           6.0                                   0.0   \n",
       "1                           0.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           1.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''导入数据'''\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import zipfile\n",
    "with zipfile.ZipFile('/home/sxy-s3/0.Teacher/Exam/KaggleCredit2.csv.zip', 'r') as z:\n",
    "    f = z.open('KaggleCredit2.csv')\n",
    "    data = pd.read_csv(f, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(108648, 11)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)#去掉带有空值的样本\n",
    "data.shapey = data['SeriousDlqin2yrs']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['SeriousDlqin2yrs']# 获得样本label\n",
    "X = data.drop('SeriousDlqin2yrs', axis=1)# 获得其特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''划分训练集和测试集'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=3, learning_rate=0.01,n_estimators=10\n",
      "模型得分：0.935235\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(max_depth=3, learning_rate=0.01,n_estimators=10, objective='multi:softmax',num_class=3)\n",
    "xgb_model.fit(X_train,y_train)\n",
    "xgb_model.predict(X_test)\n",
    "print('max_depth=3, learning_rate=0.01,n_estimators=10')\n",
    "print('模型得分：%.6f'%xgb_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1\n",
      "模型得分：0.932873\n",
      "max_depth=2\n",
      "模型得分：0.935021\n",
      "max_depth=3\n",
      "模型得分：0.935910\n",
      "max_depth=4\n",
      "模型得分：0.936187\n",
      "max_depth=5\n",
      "模型得分：0.935880\n",
      "max_depth=6\n",
      "模型得分：0.935788\n",
      "max_depth=7\n",
      "模型得分：0.935420\n",
      "max_depth=8\n",
      "模型得分：0.934837\n",
      "max_depth=9\n",
      "模型得分：0.934376\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    xgb_model = xgb.XGBClassifier(max_depth=i, learning_rate=0.1,n_estimators=10, objective='multi:softmax',num_class=3)\n",
    "    xgb_model.fit(X_train,y_train)\n",
    "    xgb_model.predict(X_test)\n",
    "    print('max_depth=%i'%i)\n",
    "    print('模型得分：%.6f'%xgb_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1 learning_rate=0.1\n",
      "模型得分：0.932873\n",
      "max_depth=2 learning_rate=0.1\n",
      "模型得分：0.935021\n",
      "max_depth=3 learning_rate=0.1\n",
      "模型得分：0.935910\n",
      "max_depth=4 learning_rate=0.1\n",
      "模型得分：0.936187\n",
      "max_depth=5 learning_rate=0.1\n",
      "模型得分：0.935880\n",
      "max_depth=6 learning_rate=0.1\n",
      "模型得分：0.935788\n",
      "max_depth=7 learning_rate=0.1\n",
      "模型得分：0.935420\n",
      "max_depth=8 learning_rate=0.1\n",
      "模型得分：0.934837\n",
      "max_depth=9 learning_rate=0.1\n",
      "模型得分：0.934376\n",
      "max_depth=1 learning_rate=0.2\n",
      "模型得分：0.932873\n",
      "max_depth=2 learning_rate=0.2\n",
      "模型得分：0.935021\n",
      "max_depth=3 learning_rate=0.2\n",
      "模型得分：0.935450\n",
      "max_depth=4 learning_rate=0.2\n",
      "模型得分：0.936156\n",
      "max_depth=5 learning_rate=0.2\n",
      "模型得分：0.936432\n",
      "max_depth=6 learning_rate=0.2\n",
      "模型得分：0.936616\n",
      "max_depth=7 learning_rate=0.2\n",
      "模型得分：0.935235\n",
      "max_depth=8 learning_rate=0.2\n",
      "模型得分：0.935665\n",
      "max_depth=9 learning_rate=0.2\n",
      "模型得分：0.934867\n",
      "max_depth=1 learning_rate=0.3\n",
      "模型得分：0.932873\n",
      "max_depth=2 learning_rate=0.3\n",
      "模型得分：0.935082\n",
      "max_depth=3 learning_rate=0.3\n",
      "模型得分：0.936064\n",
      "max_depth=4 learning_rate=0.3\n",
      "模型得分：0.936064\n",
      "max_depth=5 learning_rate=0.3\n",
      "模型得分：0.936033\n",
      "max_depth=6 learning_rate=0.3\n",
      "模型得分：0.935910\n",
      "max_depth=7 learning_rate=0.3\n",
      "模型得分：0.935512\n",
      "max_depth=8 learning_rate=0.3\n",
      "模型得分：0.934683\n",
      "max_depth=9 learning_rate=0.3\n",
      "模型得分：0.934591\n",
      "max_depth=1 learning_rate=0.4\n",
      "模型得分：0.934745\n",
      "max_depth=2 learning_rate=0.4\n",
      "模型得分：0.935328\n",
      "max_depth=3 learning_rate=0.4\n",
      "模型得分：0.935481\n",
      "max_depth=4 learning_rate=0.4\n",
      "模型得分：0.936585\n",
      "max_depth=5 learning_rate=0.4\n",
      "模型得分：0.936033\n",
      "max_depth=6 learning_rate=0.4\n",
      "模型得分：0.935573\n",
      "max_depth=7 learning_rate=0.4\n",
      "模型得分：0.935143\n",
      "max_depth=8 learning_rate=0.4\n",
      "模型得分：0.934745\n",
      "max_depth=9 learning_rate=0.4\n",
      "模型得分：0.934837\n",
      "max_depth=1 learning_rate=0.5\n",
      "模型得分：0.935604\n",
      "max_depth=2 learning_rate=0.5\n",
      "模型得分：0.935910\n",
      "max_depth=3 learning_rate=0.5\n",
      "模型得分：0.936187\n",
      "max_depth=4 learning_rate=0.5\n",
      "模型得分：0.935542\n",
      "max_depth=5 learning_rate=0.5\n",
      "模型得分：0.935757\n",
      "max_depth=6 learning_rate=0.5\n",
      "模型得分：0.934867\n",
      "max_depth=7 learning_rate=0.5\n",
      "模型得分：0.934898\n",
      "max_depth=8 learning_rate=0.5\n",
      "模型得分：0.933364\n",
      "max_depth=9 learning_rate=0.5\n",
      "模型得分：0.934100\n",
      "max_depth=1 learning_rate=0.6\n",
      "模型得分：0.935941\n",
      "max_depth=2 learning_rate=0.6\n",
      "模型得分：0.935757\n",
      "max_depth=3 learning_rate=0.6\n",
      "模型得分：0.936064\n",
      "max_depth=4 learning_rate=0.6\n",
      "模型得分：0.935818\n",
      "max_depth=5 learning_rate=0.6\n",
      "模型得分：0.935051\n",
      "max_depth=6 learning_rate=0.6\n",
      "模型得分：0.934990\n",
      "max_depth=7 learning_rate=0.6\n",
      "模型得分：0.935051\n",
      "max_depth=8 learning_rate=0.6\n",
      "模型得分：0.934223\n",
      "max_depth=9 learning_rate=0.6\n",
      "模型得分：0.932750\n",
      "max_depth=1 learning_rate=0.7\n",
      "模型得分：0.935849\n",
      "max_depth=2 learning_rate=0.7\n",
      "模型得分：0.935726\n",
      "max_depth=3 learning_rate=0.7\n",
      "模型得分：0.935665\n",
      "max_depth=4 learning_rate=0.7\n",
      "模型得分：0.935665\n",
      "max_depth=5 learning_rate=0.7\n",
      "模型得分：0.935082\n",
      "max_depth=6 learning_rate=0.7\n",
      "模型得分：0.934438\n",
      "max_depth=7 learning_rate=0.7\n",
      "模型得分：0.934530\n",
      "max_depth=8 learning_rate=0.7\n",
      "模型得分：0.933333\n",
      "max_depth=9 learning_rate=0.7\n",
      "模型得分：0.932658\n",
      "max_depth=1 learning_rate=0.8\n",
      "模型得分：0.935726\n",
      "max_depth=2 learning_rate=0.8\n",
      "模型得分：0.935880\n",
      "max_depth=3 learning_rate=0.8\n",
      "模型得分：0.934530\n",
      "max_depth=4 learning_rate=0.8\n",
      "模型得分：0.935512\n",
      "max_depth=5 learning_rate=0.8\n",
      "模型得分：0.934530\n",
      "max_depth=6 learning_rate=0.8\n",
      "模型得分：0.934008\n",
      "max_depth=7 learning_rate=0.8\n",
      "模型得分：0.933088\n",
      "max_depth=8 learning_rate=0.8\n",
      "模型得分：0.933272\n",
      "max_depth=9 learning_rate=0.8\n",
      "模型得分：0.931523\n",
      "max_depth=1 learning_rate=0.9\n",
      "模型得分：0.935205\n",
      "max_depth=2 learning_rate=0.9\n",
      "模型得分：0.935634\n",
      "max_depth=3 learning_rate=0.9\n",
      "模型得分：0.935941\n",
      "max_depth=4 learning_rate=0.9\n",
      "模型得分：0.934499\n",
      "max_depth=5 learning_rate=0.9\n",
      "模型得分：0.934192\n",
      "max_depth=6 learning_rate=0.9\n",
      "模型得分：0.933395\n",
      "max_depth=7 learning_rate=0.9\n",
      "模型得分：0.932689\n",
      "max_depth=8 learning_rate=0.9\n",
      "模型得分：0.932168\n",
      "max_depth=9 learning_rate=0.9\n",
      "模型得分：0.930664\n",
      "max_depth=1 learning_rate=1.0\n",
      "模型得分：0.935235\n",
      "max_depth=2 learning_rate=1.0\n",
      "模型得分：0.936555\n",
      "max_depth=3 learning_rate=1.0\n",
      "模型得分：0.934591\n",
      "max_depth=4 learning_rate=1.0\n",
      "模型得分：0.934254\n",
      "max_depth=5 learning_rate=1.0\n",
      "模型得分：0.934162\n",
      "max_depth=6 learning_rate=1.0\n",
      "模型得分：0.932842\n",
      "max_depth=7 learning_rate=1.0\n",
      "模型得分：0.931677\n",
      "max_depth=8 learning_rate=1.0\n",
      "模型得分：0.930449\n",
      "max_depth=9 learning_rate=1.0\n",
      "模型得分：0.931370\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    for n in range(1,10):\n",
    "        xgb_model = xgb.XGBClassifier(max_depth=n, learning_rate=i/10,n_estimators=10, objective='multi:softmax',num_class=3)\n",
    "        xgb_model.fit(X_train,y_train)\n",
    "        xgb_model.predict(X_test)\n",
    "        print('max_depth=%i'%n,'learning_rate=%.1f'%(i/10))\n",
    "        print('模型得分：%.6f'%xgb_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上可以得出，当max_depth=6 learning_rate=0.2，其他均为默认参数的情况下，模型的得分最高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "这周关于模型融合、xgboost的学习还有很多不明白的地方，这周考试做得不够好，最后一道信用卡题目没有完整地做好，很多欠缺的地方，有很多知识点还没掌握，整个数据分析，模型分析的能力很欠缺，以后会多挤时间补上的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "寒老师讲课很好，知识点讲得很明白，只是自己欠熟练掌握。\n",
    "有个希望，线下课程还是给开远程直播吧，路远的人儿伤不起，从早上赶车出发，现场听课结束后再赶回家一共耗掉12个小时。\n",
    "尤其还是上班的人儿。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
