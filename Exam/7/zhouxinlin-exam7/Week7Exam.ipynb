{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第七周(机器学习-模型调优与融合)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月23日至3月25日期间完成，最晚提交时间本周日（3月25日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam7后，进行作答。例如wangwei-exam7\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/7/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>___周新林__</u>  \n",
    "- 批改人： David\n",
    "- 最终得分:73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题(共6题，1，2题每题5分，后4题每题10分，共计50分)\n",
    "\n",
    "- note:48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 机器学习任务中，通常会将给定数据切分为训练集，验证集，测试集，请回答这三类数据集各自的用途。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "训练集：训练模型\n",
    "验证集：用训练好模型，处理交叉验证数据集，统计误差，取误差最小的模型为最终模型\n",
    "测试集：用测试数据集测试其准确性，即测试模型效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.如何将数据转换成xgboost内置用法的libsvm数据格式，以及该格式数据是如何解读的?\n",
    "\n",
    "- note: 题目是问libsvm的这种格式的含义，怎么解读。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "可以用xgb.DMatrix()将数据转换成xgboost内置用法的libsvm数据格式；\n",
    "通过watch_list解读数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 对于自动特征选择，通常有哪三类方法？试写出每类方式的思想，以及在sklearn中的代码实现（面试题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1. 过滤式：这种方法的关键就是找到一种能度量特征重要性的方法，比如pearson相关系数，信息论理论中的互信息等。\n",
    "2. 包裹式：这类方法的核心思想在于给定了某种模型及预测效果评价的方法，然后针对特征空间中的不同子集，计算每个子集的预测效果，效果最好的\n",
    "           作为最终被挑选出来的特征子集。\n",
    "3. 嵌入式：嵌入式方法将特征选择融合在模型训练的过程中，例如决策树在分枝的过程中，就是使用的嵌入式特征选择方法，\n",
    "           其内在还是根据某个度量指标对特征进行排序。\n",
    "实例代码：\n",
    "1.选择特征中最好的k个\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape\n",
    "(150, 4)\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "X_new.shape\n",
    "(150, 2)\n",
    "\n",
    "2. REF\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.datasets import load_digits  \n",
    "from sklearn.feature_selection import RFE  \n",
    "# Load the digits dataset  \n",
    "digits = load_digits()  \n",
    "X = digits.images.reshape((len(digits.images), -1))  \n",
    "y = digits.target  \n",
    "  \n",
    "# Create the RFE object and rank each pixel  \n",
    "svc = SVC(kernel=\"linear\", C=1)  \n",
    "rfe = RFE(estimator=svc, n_features_to_select=50, step=1)  \n",
    "rfe.fit(X, y)  \n",
    "x=rfe.fit_transform(X,y)  \n",
    "x.shape\n",
    "(1797L, 50L)\n",
    "\n",
    "3.SelectFromModel--以L1为基的特征选择\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "sklearn.feature_selection import SelectFromModel\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X.shape\n",
    "(150, 4)\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(X, y)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = model.transform(X)\n",
    " X_new.shape\n",
    "(150, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.网格搜索交叉验证的作用是什么，并简述网格搜索交叉验证是如何运行的？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "网格搜索: 如果我们手动的给出一个模型中想要改动的所用的参数，程序自动的帮你使用穷举法来将所用的参数都运行一遍\n",
    "交叉验证：是为了对于使用当前超参数进行训练的模型的好坏的评估\n",
    "\n",
    "网格搜索运行方法:遍历搜寻网格中的每一对超参数（这个就是网格搜索法，也叫做暴力搜寻），对于每一对超参数进行评估，得到评估分数指标，\n",
    "                 将各对超参数的评估指标进行比对，得到最优超参数对，选出来用于模型训练。\n",
    "交叉验证运行方法：将数据集分割为训练集和测试集，验证集在交叉验证中没有用。将分割后得训练集进行k个子集的分割，每一次将一个子集取为验证集，\n",
    "                  其余子集为训练集，共得到k种情况下的训练数据集分割；在当前的超参数条件下，使用k种情况的数据集对于模型进行训练，得到k个\n",
    "                  模型，使用相应验证集对于这k个模型进行预测结果分析得到k个正确率指标，将这k个正确率指标进行平均作为当前超参数条件下的对应分数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.工业界上模型整合有三大类方式？试简述每类方式其思想？（面试题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1.Boosting方法，方式其思想：Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率\n",
    "                            表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差\n",
    "                            率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2；\n",
    "                            如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，\n",
    "                            得到最终的强学习器。 \n",
    "2. bagging，方式其思想：采用的是自助采样法（Bootstap sampling）,即对于m个样本的原始训练集，我们每次先随机采集一个样本放入采样集，\n",
    "                        接着把该样本放回，也就是说下次采样时该样本仍有可能被采集到，这样采集m次，最终可以得到m个样本的采样集，\n",
    "                        由于是随机采样，这样每次的采样集是和原始训练集不同的，和其他采样集也是不同的，这样得到多个不同的弱学习器。\n",
    "                    \n",
    "3.随机森林，方式其思想：是对bagging算法的改进。改进一：基本学习器限定为决策树，改进二：除了bagging的在样本上加上扰动，\n",
    "                        同时在属性上也加上扰动，即是在决策树学习的过程中引入了随机属性选择，对基决策树的每个结点，\n",
    "                        先从该结点的属性集合中随机选择一个包含k个属性的子集，然后再从这个子集中选择一个最优属性用于划分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  我们可以将xgboost的中众多参数分类为哪三类？请写出哪些参数可以用什么方式用来控制过拟合？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "三类：general parameters，booster parameters和task parameters\n",
    "\n",
    "eta: 为了防止过拟合，更新过程中用到的收缩步长。在每次提升计算之后，算法会直接获得新特征的权重。 \n",
    "     eta通过缩减特征的权重使提升计算过程更加保守。\n",
    "        \n",
    "subsample: 用于训练模型的子样本占整个样本集合的比例。如果设置为0.5则意味着XGBoost将随机的冲整个样本集合中随机的抽取出50%的子样本建立\n",
    "           树模型，这能够防止过拟合。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验题(共2题，每题25分，共计50分)\n",
    "\n",
    "- note: 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 使用XGBoost内置方式，导入iris数据完成分类问题（要求以不同参数设置xgboost运行并比对），最后给出实验总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[1]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[2]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[3]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[4]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[5]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[6]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[7]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[8]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[9]\teval-merror:0.266667\ttrain-merror:0.016667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2., 1., 2., 2., 1., 1., 2., 1., 2., 2., 2., 1., 1., 2., 2.,\n",
       "       2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "X[:3,:]\n",
    "Y[:3]\n",
    "d_train = xgb.DMatrix(data=X[:120,:], label=Y[:120])\n",
    "d_test = xgb.DMatrix(data=X[120:,:], label=Y[120:])\n",
    "watch_list = [(d_test,'eval'), (d_train,'train')]\n",
    "#参数设定1\n",
    "param1 = {'max_depth':3, 'eta':0.01, 'objective':'multi:softmax', 'num_class':3}\n",
    "\n",
    "num_round = 10\n",
    "bst1 = xgb.train(param1, d_train, num_round, watch_list)\n",
    "bst1.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.266667\ttrain-merror:0.016667\n",
      "[1]\teval-merror:0.266667\ttrain-merror:0.025\n",
      "[2]\teval-merror:0.1\ttrain-merror:0.033333\n",
      "[3]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[4]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[5]\teval-merror:0.1\ttrain-merror:0.025\n",
      "[6]\teval-merror:0.1\ttrain-merror:0.033333\n",
      "[7]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[8]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[9]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[10]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[11]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[12]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[13]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[14]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[15]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[16]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[17]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[18]\teval-merror:0.233333\ttrain-merror:0.025\n",
      "[19]\teval-merror:0.233333\ttrain-merror:0.025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 1., 2., 2., 1., 1., 2., 1., 2., 2., 2., 1., 1., 2., 2.,\n",
       "       2., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "X[:3,:]\n",
    "Y[:3]\n",
    "d_train = xgb.DMatrix(data=X[:120,:], label=Y[:120])\n",
    "d_test = xgb.DMatrix(data=X[120:,:], label=Y[120:])\n",
    "watch_list = [(d_test,'eval'), (d_train,'train')]\n",
    "#参数设定2\n",
    "param2 = {'max_depth':10, 'eta':0.09, 'objective':'multi:softmax', 'num_class':10}\n",
    "num_round = 20\n",
    "bst2 = xgb.train(param2, d_train, num_round, watch_list)\n",
    "bst2.predict(d_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "由于篇幅限制，上面仅做出一些示例给出不同参数选择下模型最后的结果\n",
    "总结：对于eta参数，通过减少每一步的权重，可以提高模型的鲁棒性，\n",
    "      通过设置max_depth，可以用来避免过拟合。max_depth越大，模型会学到更具体更局部的样本。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用XGBoost的sklearn接口，对KaggleCredit2数据完成信用卡欺诈项目的建模及分析（要求以不同参数设置xgboost运行并比对），最后给出实验总结\n",
    "\n",
    "- KaggleCredit2数据文件 位于/home/sxy-s3/0.Teacher/Exam/KaggleCredit2.csv.zip，请勿复制或移动该文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(max_depth=3, learning_rate=0.01, \\\n",
    "                          n_estimators=10, objective='multi:softmax')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
