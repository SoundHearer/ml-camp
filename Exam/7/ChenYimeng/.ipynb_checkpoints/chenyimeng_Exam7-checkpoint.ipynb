{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七月在线机器学习实训营三期第七周(机器学习-模型调优与融合)考试\n",
    "#### 考试说明:\n",
    "- 起止时间：请同学在2018年3月23日至3月25日期间完成，最晚提交时间本周日（3月25日24时之前）结束，<b>逾期不接受补考,该考试分数计入平时成绩</b>\n",
    "- 考试方式：请同学<font color=red><b>拷贝</b></font>该试卷至自己姓名的目录后，将文件更名为同学姓名拼音-exam7后，进行作答。例如wangwei-exam7\n",
    "- 提交格式：请同学新建自己姓名全拼的文件夹，将该试卷，数据文件，zip文件等相关考试文件，放置此目录下。将该目录<b>移动</b>至/0.Teacher/Exam/7/目录下\n",
    "- 注意事项：为确保同学们真正了解自身对本周课程的掌握程度，<font color=red><b>请勿翻阅，移动，更改</b></font>其它同学试卷。如发现按0分处理\n",
    "- 请同学在下方同学姓名处填写自己的姓名，批改人和最终得分不用填写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 同学姓名:<u>__陈益梦__</u>  \n",
    "- 批改人： David\n",
    "- 最终得分: 93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>####答卷开始####</h1></center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简答题(共6题，1，2题每题5分，后4题每题10分，共计50分)\n",
    "\n",
    "- note:43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 机器学习任务中，通常会将给定数据切分为训练集，验证集，测试集，请回答这三类数据集各自的用途。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 训练集 (training set):数据集的子集，用于训练模型。\n",
    "\n",
    "- 验证集 (validation set):数据集的一个子集，从训练集分离而来，用于调整超参数。\n",
    "\n",
    "- 测试集 (test set):数据集的子集，用于在模型经由验证集的初步验证之后测试模型，评估模型的泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.如何将数据转换成xgboost内置用法的libsvm数据格式，以及该格式数据是如何解读的?\n",
    "\n",
    "- note:libsvm格式解读没有？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- 使用xgboost内置的DMatrix方法可以加载libsvm数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 输入文件 --> 第一列需要时 label，得到libsvm 格式的数据文件\n",
    "def transform_txt_to_libsvm(input_file, output_file, separator):\n",
    "    # transform data.txt to libsvm type data, get libsvm.txt  \n",
    "    \n",
    "    #read data file  \n",
    "    with open(input_file, 'r') as readin:\n",
    "        #write data file  \n",
    "        with open(output_file, 'w') as output:\n",
    "            try:  \n",
    "                the_line = readin.readline()  \n",
    "                while the_line:  \n",
    "                    # delete the \\n  \n",
    "                    the_line = the_line.strip('\\n')  \n",
    "                    index = 0;  \n",
    "                    output_line = ''  \n",
    "                    for sub_line in the_line.split(separator):  \n",
    "                        #the label col  \n",
    "                        if index == 0:  \n",
    "                            output_line = sub_line  \n",
    "                        #the features cols  \n",
    "                        if sub_line != 'NULL' and index != 0:  \n",
    "                            the_text = ' ' + str(index) + ':' + sub_line  \n",
    "                            output_line = output_line + the_text  \n",
    "                        index = index + 1  \n",
    "                    output_line = output_line + '\\n'  \n",
    "                    output.write(output_line)  \n",
    "                    the_line = readin.readline()  \n",
    "            finally:  \n",
    "                readin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform_txt_to_libsvm('data.txt', 'libsvm.txt',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txtFile:data.txt ========================================start=======================\n",
      "0,aa,bb,cc,dd\n",
      "\n",
      "1,ab,cd,ef,gh\n",
      "\n",
      "8,ef,gh,ij,kl\n",
      "\n",
      "0,a,b,c,d\n",
      "\n",
      "3,e,f,g,h\n",
      "\n",
      "1,i,j,k,l\n",
      "\n",
      "3,,f,,\n",
      "\n",
      "3,,,,\n",
      "\n",
      "1,,h,t,\n",
      "\n",
      "1,,,,g\n",
      "\n",
      "1,NULL,NULL,NULL,F\n",
      "\n",
      "\n",
      "txtFile:libsvm.txt  ========================================start=======================\n",
      "0 1:aa 2:bb 3:cc 4:dd\n",
      "\n",
      "1 1:ab 2:cd 3:ef 4:gh\n",
      "\n",
      "8 1:ef 2:gh 3:ij 4:kl\n",
      "\n",
      "0 1:a 2:b 3:c 4:d\n",
      "\n",
      "3 1:e 2:f 3:g 4:h\n",
      "\n",
      "1 1:i 2:j 3:k 4:l\n",
      "\n",
      "3 1: 2:f 3: 4:\n",
      "\n",
      "3 1: 2: 3: 4:\n",
      "\n",
      "1 1: 2:h 3:t 4:\n",
      "\n",
      "1 1: 2: 3: 4:g\n",
      "\n",
      "1 4:F\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data.txt', 'r') as readin:\n",
    "    print('txtFile:data.txt ========================================start=======================')\n",
    "    for line in readin:\n",
    "        print(line)\n",
    "    print('\\n')\n",
    "with open('libsvm.txt', 'r') as readin:\n",
    "    print('txtFile:libsvm.txt  ========================================start=======================')\n",
    "    for line in readin:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#上面打印的libsvm.txt 文件内容就是libsvm 数据格式，第一列为类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#使用xgboost读取数据\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix('libsvm.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.num_col()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.num_row()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 对于自动特征选择，通常有哪三类方法？试写出每类方式的思想，以及在sklearn中的代码实现（面试题）\n",
    "\n",
    "- note: 思想 ？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 自动特征选择：\n",
    "- 过滤式（Filter） sklearn.feature_selection import SelectKBest\n",
    "- 包裹式（Wrapper） sklearn.feature_selection import RFE\n",
    "- 嵌入式（Embedded） sklearn.ensemble import ExtraTreesClassifie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,SelectPercentile\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# SelectKBest：选择排名前k个的特征\n",
    "model_select_best = SelectKBest(k=3).fit(X,y)\n",
    "X_select_best = model_select_best.transform(X)\n",
    "# SelectPercentile：选择排名在前k%的特征\n",
    "model_select_percentile = SelectPercentile(percentile=80).fit(X,y)\n",
    "X_select_percentile = model_select_percentile.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_select_best.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_select_best.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_select_percentile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_select_percentile.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置一个方差阈值，没有达到这个方差阈值的特征都会被丢弃\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "model_v = VarianceThreshold(threshold=0.5).fit(X,y)\n",
    "X_select_v = model_v.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_select_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_v.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 指定一个学习算法，通过算法计算所有子集的error，选择error最小的子集作为选取的特征\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rfe = RFE(estimator=rf, n_features_to_select=3)\n",
    "X_rfe = rfe.fit_transform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_rfe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LinearSVC选取特征\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 参数C控制特征系数稀疏度，C的值越小，选择的特征数越少\n",
    "lsvc = LinearSVC(C=0.01, penalty='l1', dual=False).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SelectFromModel(lsvc, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_select_from_lsvc = model.transform(X)\n",
    "X_select_from_lsvc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.21678422, -0.28726535,  0.        ],\n",
       "       [ 0.        , -0.09186784,  0.        ,  0.        ],\n",
       "       [-0.0348547 , -0.17041784,  0.13476597,  0.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False], dtype=bool)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_support()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 通过对比，filter 里面的方差选择法和相关系数法 和 Wrapper的随机森林迭代包裹删除法 删除的是第二个特征；Embedded LinearSVC选取特征 删除的是第四个特征\n",
    "##### Embedded 方法加了正则化。。。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.网格搜索交叉验证的作用是什么，并简述网格搜索交叉验证是如何运行的？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- **作用：** 网格搜索交叉验证是遍历给定的参数组合，然后进行交叉验证，找出使交叉验证精确度最高的参数组合，来优化模型表现。\n",
    "\n",
    "\n",
    "\n",
    "- **运行：**\n",
    "以决策树为例，给定一组参数 {'max_depth': [1,2,3,4,5]}，3折交叉验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for d in max_depth:\n",
    "#   for i in rang(3):\n",
    "#     计算深度为 d 时候，3折交叉验证的第i次运算，得到结果 p\n",
    "#   深度为d 的运算结果为sum(p)/3\n",
    "# 得到深度为 1,2,3,4,5 的时候的5个结果，选取分数最高的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.工业界上模型整合有三大类方式？试简述每类方式其思想？（面试题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 模型整合：Bagging，Boosting，Stacking\n",
    "\n",
    "##### Bagging\n",
    "Bagging就是采用有放回的方式进行抽样，用抽样的样本建立子模型,对子模型进行训练，这个过程重复多次，最后进行融合。<br>\n",
    "大概分为这样两步：<br>\n",
    "1、重复K次<br>\n",
    "有放回地重复抽样建模<br>\n",
    "训练子模型<br>\n",
    "2.模型融合<br>\n",
    "分类问题：voting<br>\n",
    "回归问题：average<br>\n",
    "可以是异质模型，并行处理。<br>\n",
    "##### Boosting\n",
    "Boosting的思想是一种迭代的方法，每一次训练的时候都更加关心分类错误的样例，给这些分类错误的样例增加更大的权重，下一次迭代的目标就是能够更容易辨别出上一轮分类错误的样例。最终将这些弱分类器进行加权相加。<br>\n",
    "在boosting中，总是试图添加新模型以纠正先前模型的弱点。因此它是顺序串行的。<br>\n",
    "##### Stacking\n",
    "Stacking模型本质上是一种分层的结构，使用多个模型对训练集和测试集进行训练和预测，将得到的结果作为测试集，原本的标签作为训练集，输入到新的模型中训练，用整个训练集训练的模型反过来去预测训练集的标签，会产生过拟合，加入K折交叉验证得到最终结果。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.  我们可以将xgboost的中众多参数分类为哪三类？请写出哪些参数可以用什么方式用来控制过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**三类参数**：通用参数/general parameters, 集成(增强)参数/booster parameters 和 任务参数/task parameters\n",
    "- eta [default=0.3, 可以视作学习率]<br>\n",
    "为了防止过拟合，更新过程中用到的收缩步长。在每次提升计算之后，算法会直接获得新特征的权重。 eta通过缩减特征的权重使提升计算过程更加保守。缺省值为0.3  取值范围为：[0,1]\n",
    "- max_depth [default=6]<br>\n",
    "用于设置树的最大深度!越大越容易过拟合！\n",
    "- min_child_weight [default=1]<br>\n",
    "表示子树观测权重之和的最小值，如果树的生长时的某一步所生成的叶子结点，其观测权重之和小于min_child_weight，那么可以放弃该步生长，在线性回归模式中，这仅仅与每个结点所需的最小观测数相对应。该值越大，算法越保守，最小的孩子集合，小于这个数，不进行接下来的切分!越小越容易过拟合。\n",
    "- subsample [default=1]<br>\n",
    "表示观测的子样本的比率，将其设置为0.5意味着xgboost将随机抽取一半观测用于树的生长，这将有助于防止过拟合现象\n",
    "- colsample_bytree [default=1]<br>\n",
    "表示用于构造每棵树时变量的列采样比率!\n",
    "- scale_pos_weight, [default=1]<br>\n",
    "在各类别样本十分不平衡时，把这个参数设定为一个正值，可以使算法更快收敛!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验题(共2题，每题25分，共计50分)\n",
    "\n",
    "- note:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 使用XGBoost内置方式，导入iris数据完成分类问题（要求以不同参数设置xgboost运行并比对），最后给出实验总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入使用库和样本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切分数据集并查看数据集形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBOOST 初始化数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(data=X_train, label=y_train)\n",
    "d_test = xgb.DMatrix(data=X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_list = [(d_test, 'eval'), (d_train, 'train')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一组参数测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[1]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[2]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[3]\teval-merror:0.088889\ttrain-merror:0.028571\n",
      "[4]\teval-merror:0.044444\ttrain-merror:0.028571\n",
      "[5]\teval-merror:0.022222\ttrain-merror:0.028571\n",
      "[6]\teval-merror:0.022222\ttrain-merror:0.028571\n",
      "[7]\teval-merror:0.022222\ttrain-merror:0.047619\n",
      "[8]\teval-merror:0.022222\ttrain-merror:0.047619\n",
      "[9]\teval-merror:0.022222\ttrain-merror:0.028571\n"
     ]
    }
   ],
   "source": [
    "param1 = {\n",
    "    'eta': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'gamma':0.1,\n",
    "    'min_child_weight': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.5,\n",
    "#     'lambda':2,\n",
    "#     'scale_pos_weight': 1,    #此处没有效果\n",
    "    'objectice': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'seed': 1000\n",
    "#     'eval_metric': 'auc'    # 使用这个会报错 \n",
    "}\n",
    "num_round1 = 10\n",
    "bst1 = xgb.train(param1, d_train, num_round1, watch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f0': 12, 'f1': 4, 'f2': 26, 'f3': 19}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Importance type can be defined as:\n",
    "        'weight' - the number of times a feature is used to split the data across all trees.\n",
    "        'gain' - the average gain of the feature when it is used in trees\n",
    "        'cover' - the average coverage of the feature when it is used in trees\n",
    "        \n",
    "bst1.get_fscore()  # Get feature importance of each feature.\n",
    "'''\n",
    "bst1.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.020203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0          0.066666         0.026937           0.042857          0.020203\n",
       "1          0.057143         0.023329           0.033333          0.006734\n",
       "2          0.066666         0.026937           0.028571          0.000000\n",
       "3          0.066666         0.026937           0.038095          0.013469\n",
       "4          0.076190         0.013468           0.038095          0.013469\n",
       "5          0.066666         0.026937           0.033333          0.006734\n",
       "6          0.076190         0.013468           0.033333          0.006734\n",
       "7          0.076190         0.013468           0.028571          0.000000\n",
       "8          0.066666         0.026937           0.028571          0.000000\n",
       "9          0.066666         0.026937           0.028571          0.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst1_cross_v = xgb.cv(param1, d_train, num_round1,nfold=3)\n",
    "bst1_cross_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test-merror-mean     0.068571\n",
       "test-merror-std      0.022536\n",
       "train-merror-mean    0.033333\n",
       "train-merror-std     0.006734\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "bst1_cross_v.agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 第二组参数测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[1]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[2]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[3]\teval-merror:0.088889\ttrain-merror:0.028571\n",
      "[4]\teval-merror:0.044444\ttrain-merror:0.028571\n",
      "[5]\teval-merror:0.022222\ttrain-merror:0.028571\n",
      "[6]\teval-merror:0.022222\ttrain-merror:0.028571\n",
      "[7]\teval-merror:0.022222\ttrain-merror:0.047619\n",
      "[8]\teval-merror:0.022222\ttrain-merror:0.047619\n",
      "[9]\teval-merror:0.022222\ttrain-merror:0.028571\n"
     ]
    }
   ],
   "source": [
    "param2 = {\n",
    "    'eta': 0.01,   #（增大学习率到0.1会增加交叉验证的0.004 的误差）\n",
    "    'max_depth': 3,\n",
    "    'gamma':0.1,\n",
    "    'min_child_weight': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.5,  #（由 0.5 增加为0.9  会增大交叉验证的0.002 的误差）\n",
    "    'lambda':2,  #增加正则  （会减小交叉验证的0.007误差）\n",
    "    'objectice': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'seed': 100   #此处做修改，由 1000 减小为100\n",
    "}\n",
    "num_round2 = 10\n",
    "bst2 = xgb.train(param1, d_train, num_round2, watch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.017817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.011664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.023329</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0          0.047619         0.026937           0.038095          0.006734\n",
       "1          0.047619         0.026937           0.033333          0.006734\n",
       "2          0.066667         0.013468           0.023809          0.006734\n",
       "3          0.057143         0.023329           0.033333          0.017817\n",
       "4          0.057143         0.023329           0.028571          0.011664\n",
       "5          0.066667         0.013468           0.028571          0.000000\n",
       "6          0.066667         0.013468           0.023809          0.006734\n",
       "7          0.066667         0.013468           0.028571          0.000000\n",
       "8          0.057143         0.023329           0.033333          0.006734\n",
       "9          0.057143         0.023329           0.033333          0.006734"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst2_cross_v = xgb.cv(param2, d_train, num_round2,nfold=3)\n",
    "bst2_cross_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test-merror-mean     0.059047\n",
       "test-merror-std      0.020106\n",
       "train-merror-mean    0.030476\n",
       "train-merror-std     0.006989\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "bst2_cross_v.agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三组参数测试结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[1]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[2]\teval-merror:0.088889\ttrain-merror:0.038095\n",
      "[3]\teval-merror:0.088889\ttrain-merror:0.028571\n",
      "[4]\teval-merror:0.044444\ttrain-merror:0.028571\n",
      "[5]\teval-merror:0.022222\ttrain-merror:0.028571\n",
      "[6]\teval-merror:0.022222\ttrain-merror:0.028571\n",
      "[7]\teval-merror:0.022222\ttrain-merror:0.047619\n",
      "[8]\teval-merror:0.022222\ttrain-merror:0.047619\n",
      "[9]\teval-merror:0.022222\ttrain-merror:0.028571\n"
     ]
    }
   ],
   "source": [
    "param3 = {\n",
    "    'eta': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'gamma':0.1,\n",
    "    'min_child_weight': 5,   # 增大每棵树最小节点数会增大交叉验证误差0.02\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'lambda':1,\n",
    "    'objectice': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'seed': 100 \n",
    "}\n",
    "num_round3 = 10\n",
    "bst3 = xgb.train(param1, d_train, num_round3, watch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.090476</td>\n",
       "      <td>0.024281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.067344</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.023329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.017817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.061722</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.017817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.013469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.058709</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.017817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.011664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.069986</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.006734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.048562</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.011664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.048562</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.011664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-merror-mean  test-merror-std  train-merror-mean  train-merror-std\n",
       "0          0.095238         0.053875           0.090476          0.024281\n",
       "1          0.076190         0.067344           0.071429          0.023329\n",
       "2          0.095238         0.053875           0.066667          0.017817\n",
       "3          0.085714         0.061722           0.066667          0.017817\n",
       "4          0.085714         0.069986           0.052381          0.013469\n",
       "5          0.095238         0.058709           0.066667          0.017817\n",
       "6          0.085714         0.069986           0.057143          0.011664\n",
       "7          0.085714         0.069986           0.052381          0.006734\n",
       "8          0.066667         0.048562           0.057143          0.011664\n",
       "9          0.066667         0.048562           0.057143          0.011664"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst3_cross_v = xgb.cv(param3, d_train, num_round3,nfold=3)\n",
    "bst3_cross_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test-merror-mean     0.083810\n",
       "test-merror-std      0.060261\n",
       "train-merror-mean    0.063810\n",
       "train-merror-std     0.015626\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "bst3_cross_v.agg(np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, num_class=3, objectice='multi:softmax',\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [100, 200, 500, 1000], 'learning_rate': [0.1, 0.01, 0.0001], 'max_depth': [2, 3, 4, 5], 'gamma': [0.01, 0.1, 1], 'min_child_weight': [2, 3, 4], 'subsample': [0.5, 0.7], 'colsample_bytree': [0.5, 0.7], 'seed': [100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param4 = {\n",
    "    'n_estimators':[100,200,500,1000],\n",
    "    'learning_rate':[0.1, 0.01,0.0001],\n",
    "    'max_depth': [2,3,4,5],\n",
    "    'gamma':[0.01,0.1,1],\n",
    "    'min_child_weight': [2,3,4],\n",
    "    'subsample': [0.5,0.7],\n",
    "    'colsample_bytree': [0.5,0.7],\n",
    "    'seed': [100,1000]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(xgb.XGBClassifier(objectice='multi:softmax', num_class=3), param_grid=param4, cv=3)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.5, 'gamma': 0.01, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 500, 'seed': 1000, 'subsample': 0.7}\n",
      "Accuracy : 0.9778\n",
      "r2_score : 0.9622\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(clf.best_params_)\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred)) \n",
    "print(\"r2_score : %.4g\" % metrics.r2_score(y_true, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0.01,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 2,\n",
       " 'n_estimators': 500,\n",
       " 'seed': 1000,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用网格搜索得到网格中最佳参数：'colsample_bytree': 0.5, 'gamma': 0.01, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 500, 'seed': 1000, 'subsample': 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 使用XGBoost的sklearn接口，对KaggleCredit2数据完成信用卡欺诈项目的建模及分析（要求以不同参数设置xgboost运行并比对），最后给出实验总结\n",
    "\n",
    "- KaggleCredit2数据文件 位于/home/sxy-s3/0.Teacher/Exam/KaggleCredit2.csv.zip，请勿复制或移动该文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines   age  \\\n",
       "0                 1                              0.766127  45.0   \n",
       "1                 0                              0.957151  40.0   \n",
       "2                 0                              0.658180  38.0   \n",
       "3                 0                              0.233810  30.0   \n",
       "4                 0                              0.907239  49.0   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "0                                   2.0   0.802982         9120.0   \n",
       "1                                   0.0   0.121876         2600.0   \n",
       "2                                   1.0   0.085113         3042.0   \n",
       "3                                   0.0   0.036050         3300.0   \n",
       "4                                   1.0   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "0                             13.0                      0.0   \n",
       "1                              4.0                      0.0   \n",
       "2                              2.0                      1.0   \n",
       "3                              5.0                      0.0   \n",
       "4                              7.0                      0.0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "0                           6.0                                   0.0   \n",
       "1                           0.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           1.0                                   0.0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "0                 2.0  \n",
       "1                 1.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "# with zipfile.ZipFile('/home/sxy-s3/0.Teacher/Exam/KaggleCredit2.csv.zip', 'r') as z:  \n",
    "with zipfile.ZipFile('KaggleCredit2.csv.zip', 'r') as z:  \n",
    "    f = z.open('KaggleCredit2.csv')  \n",
    "    data = pd.read_csv(f, index_col=0)  \n",
    "data.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    105299\n",
       "1      7616\n",
       "Name: SeriousDlqin2yrs, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SeriousDlqin2yrs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 样本不均衡会造成的影响\n",
    "# X_train_Credit, X_test_Credit, y_train_Credit, y_test_Credit = train_test_split(data.iloc[:,1:], data['SeriousDlqin2yrs'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分层随机拆分\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "#此处必须用numpy 否则会报错\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=0)\n",
    "X = np.array(data.iloc[:,1:])\n",
    "y = np.array(data['SeriousDlqin2yrs'])\n",
    "\n",
    "sss.get_n_splits(X,y)\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79040,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33875,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一组参数测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param1 = {\n",
    "    'max_depth': 4,\n",
    "    'n_estimators':100,\n",
    "    'learning_rate':0.01,\n",
    "    'gamma':0.1,\n",
    "    'min_child_weight': 4,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'seed': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9348\n",
      "r2_score : -0.0362\n",
      "auc : 0.5284\n"
     ]
    }
   ],
   "source": [
    "xgbclassifiter1 = xgb.XGBClassifier(**param1)\n",
    "model1 = xgbclassifiter1.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, model1.predict(X_test)\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred)) \n",
    "print(\"r2_score : %.4g\" % metrics.r2_score(y_true, y_pred)) \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "print(\"auc : %.4g\" % metrics.auc(fpr, tpr)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二组参数测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param2 = {\n",
    "    'max_depth': 5,   #修改树深度 4 ->5\n",
    "    'n_estimators':300, #修改最大树个数  100 -> 300  增加到500的时候会提高 acc 0.01，但是auc 会降低0.02\n",
    "    'learning_rate':0.2, # 学习率 0.01 -> 0.1 没有变化，  提高到0.2 的时候，acc提高0.02，auc 下降0.012\n",
    "    'gamma':0.1,   # 0.1 -> 0.2 降低auc 0.003\n",
    "    'min_child_weight': 50,  #如果减小最小个数，10 -> 2，准确率降低0.01   越小越容易过拟合\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 100,  #100 -> 1000 降低acc 0.003, 提升auc 0.004  改为500 的时候降低acc 0.005，降低auc0.01\n",
    "    'eval_metric': 'auc',   #增加这个参数准确度提高0.01\n",
    "    'reg_lambda': 2,   #使用正则2比1准确度提升0.0008，auc提高0.002\n",
    "    'scale_pos_weight': 10    #1 -> 10 导致准确率较低 0.08， auc 上升0.14   更高的时候会降低auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.8543\n",
      "r2_score : -1.316\n",
      "auc : 0.7524\n"
     ]
    }
   ],
   "source": [
    "xgbclassifiter2 = xgb.XGBClassifier(**param2)\n",
    "model2 = xgbclassifiter2.fit(X_train, y_train)\n",
    "\n",
    "y_true, y_pred = y_test, model2.predict(X_test)\n",
    "print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_true, y_pred)) \n",
    "print(\"r2_score : %.4g\" % metrics.r2_score(y_true, y_pred)) \n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred, pos_label=1)\n",
    "print(\"auc : %.4g\" % metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过增加树深度和最大树个数到一定的值，数据量大的时候学习率不能太小，正负样本比例差别很大的时候，需要配置scale_pos_weight 很重要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param3 = {\n",
    "    'max_depth': [4,6],\n",
    "    'n_estimators':[300,500],\n",
    "    'learning_rate':[0.1, 0.01],\n",
    "    'gamma':[0.1,0.2],\n",
    "    'min_child_weight': [50,100,20],\n",
    "    'subsample': [0.5,0.8],\n",
    "    'colsample_bytree': [0.5,0.8],\n",
    "    'seed': [100,500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(xgb.XGBClassifier(scale_pos_weight=1, subsample=0.8,), param_grid=param3, cv=3)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本阶段课程意见反馈题(非必答，不送分)\n",
    "#### 请同学围绕以下两点进行回答：\n",
    "- 自身总结：请您对您自己在本周课程的学习，收获，技能掌握等方面进行一次总结 ，也包括有哪些方面存在哪些不足，欠缺，困惑。作为将来回顾学习路径时的依据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "学习：针对寒老师将的案例，对整个项目有了一定的了解，建立了整个学习过程的框架，学习了数据处理大致流程，针对特征的处理对模型的结果又很大影响。<br>\n",
    "** 缺点：时间紧，任务重，基础差。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 课程反馈：请就知识点，进度，难易度，教学方式，考试方式及难易度等方面向我们反馈，督促我们进行更有效的改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "暂无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<center><h1>####答卷结束####</h1></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
